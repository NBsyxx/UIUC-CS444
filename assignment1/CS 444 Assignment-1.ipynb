{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunxi\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_process import get_FASHION_data, get_MUSHROOM_data\n",
    "from scipy.spatial import distance\n",
    "from models import Perceptron, SVM, Softmax, Logistic\n",
    "from kaggle_submission import output_submission_csv\n",
    "%matplotlib inline\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we determine the number of images for each split and load the images.\n",
    "<br /> \n",
    "TRAIN_IMAGES + VAL_IMAGES = (0, 60000]\n",
    ", TEST_IMAGES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change these numbers for experimentation\n",
    "# For submission we will use the default values \n",
    "TRAIN_IMAGES = 50000\n",
    "VAL_IMAGES = 10000\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_FASHION_data(TRAIN_IMAGES, VAL_IMAGES, normalize=normalize)\n",
    "X_train_fashion, y_train_fashion = data['X_train'], data['y_train']\n",
    "X_val_fashion, y_val_fashion = data['X_val'], data['y_val']\n",
    "X_test_fashion, y_test_fashion = data['X_test'], data['y_test']\n",
    "n_class_fashion = len(np.unique(y_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Mushroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells we determine the splitting of the mushroom dataset.\n",
    "<br /> TRAINING + VALIDATION = 0.8, TESTING = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING = 0.6 indicates 60% of the data is used as the training dataset.\n",
    "VALIDATION = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  4874\n",
      "Number of val samples:  1625\n",
      "Number of test samples:  1625\n"
     ]
    }
   ],
   "source": [
    "data = get_MUSHROOM_data(VALIDATION)\n",
    "X_train_MR, y_train_MR = data['X_train'], data['y_train']\n",
    "X_val_MR, y_val_MR = data['X_val'], data['y_val']\n",
    "X_test_MR, y_test_MR = data['X_test'], data['y_test']\n",
    "n_class_MR = len(np.unique(y_test_MR))\n",
    "\n",
    "print(\"Number of train samples: \", X_train_MR.shape[0])\n",
    "print(\"Number of val samples: \", X_val_MR.shape[0])\n",
    "print(\"Number of test samples: \", X_test_MR.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4874, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_MR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes how well your model performs using accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test == pred) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according to the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Perceptron classifier in the **models/perceptron.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Perceptron classifier class \n",
    "- The train function of the Perceptron class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perceptron code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-332-eedc3fa57255>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \"\"\"Initialize a new classifier.\n",
      "\u001b[1;32m<ipython-input-332-eedc3fa57255>\u001b[0m in \u001b[0;36mPerceptron\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \"\"\"Train the classifier.\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# multiclass perceptron\n",
    "\n",
    "\"\"\"Perceptron model.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, n_class: int, lr: float, epochs: int):\n",
    "        \"\"\"Initialize a new classifier.\n",
    "\n",
    "        Parameters:\n",
    "            n_class: the number of classes\n",
    "            lr: the learning rate\n",
    "            epochs: the number of epochs to train for\n",
    "        \"\"\"\n",
    "        self.w = None  # TODO: change this W\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.n_class = n_class\n",
    "\n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray, X_val=X_train , y_val=y_train):\n",
    "        \"\"\"Train the classifier.\n",
    "\n",
    "        Use the perceptron update rule as introduced in the Lecture.\n",
    "\n",
    "        Parameters:\n",
    "            X_train: a number array of shape (N, D) containing training data;\n",
    "                N examples with D dimensions\n",
    "            y_train: a numpy array of shape (N,) containing training labels\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: implement me\n",
    "        N,D = X_train.shape\n",
    "        random.seed(5)\n",
    "        upper_b = np.min(X_train)\n",
    "        lower_b = np.max(X_train)\n",
    "        self.w = np.array([[random.uniform(lower_b,upper_b) for j in range(X_train.shape[1])] for i in range(self.n_class)])\n",
    "\n",
    "        \n",
    "        pred_svm_t = self.predict(X_train)\n",
    "        t_acc = self.get_acc(pred_svm_t, y_train)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            # for each of the training data\n",
    "            for i in range(X_train.shape[0]):\n",
    "                for c in range(len(self.w)):\n",
    "                    if np.dot(self.w[c],X_train[i]) > np.dot(self.w[y_train[i]],X_train[i]):\n",
    "                        self.w[y_train[i]] = self.w[y_train[i]] + self.lr*X_train[i]\n",
    "                        self.w[c] = self.w[c] - self.lr*X_train[i]\n",
    "                if i%100 == 0:\n",
    "                    ret = self.predict(X_train)\n",
    "                    t_cur_acc = self.get_acc(ret, y_train)\n",
    "                    pred_svm_v = self.predict(X_val)\n",
    "                    cur_v_acc = self.get_acc(pred_svm_v, y_val)\n",
    "\n",
    "                    print(\"\\tBatch\",i,\"of\",N,\"training acc\",t_cur_acc,\"val acc\",cur_v_acc)\n",
    "                    # early stop\n",
    "                    if cur_v_acc >= 83: # found 83\n",
    "                            return\n",
    "\n",
    "        \n",
    "    def get_acc(self, pred, y_test):\n",
    "        return np.sum(y_test == pred) / len(y_test) * 100\n",
    "    \n",
    "                        \n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use the trained weights to predict labels for test data points.\n",
    "\n",
    "        Parameters:\n",
    "            X_test: a numpy array of shape (N, D) containing testing data;\n",
    "                N examples with D dimensions\n",
    "\n",
    "        Returns:\n",
    "            predicted labels for the data in X_test; a 1-dimensional array of\n",
    "                length N, where each element is an integer giving the predicted\n",
    "                class.\n",
    "        \"\"\"\n",
    "        ret = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            scores = np.dot(self.w, X_test[i])\n",
    "            max_score = float(\"-inf\")\n",
    "            max_class = -1\n",
    "            for i in range(len(scores)):\n",
    "                if scores[i] > max_score:\n",
    "                    max_score = scores[i]\n",
    "                    max_class = i\n",
    "            ret.append(max_class)\n",
    "        return np.array(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 0 of 50000 training acc 16.724 val acc 16.38\n",
      "\tBatch 100 of 50000 training acc 55.198 val acc 55.60000000000001\n",
      "\tBatch 200 of 50000 training acc 65.446 val acc 65.71000000000001\n",
      "\tBatch 300 of 50000 training acc 62.73 val acc 61.8\n",
      "\tBatch 400 of 50000 training acc 62.138000000000005 val acc 61.9\n",
      "\tBatch 500 of 50000 training acc 62.024 val acc 62.36000000000001\n",
      "\tBatch 600 of 50000 training acc 68.714 val acc 68.14\n",
      "\tBatch 700 of 50000 training acc 67.048 val acc 67.72\n",
      "\tBatch 800 of 50000 training acc 70.35 val acc 69.91000000000001\n",
      "\tBatch 900 of 50000 training acc 73.882 val acc 73.52\n",
      "\tBatch 1000 of 50000 training acc 68.58999999999999 val acc 68.33\n",
      "\tBatch 1100 of 50000 training acc 64.25999999999999 val acc 64.4\n",
      "\tBatch 1200 of 50000 training acc 68.76400000000001 val acc 68.21000000000001\n",
      "\tBatch 1300 of 50000 training acc 72.244 val acc 71.94\n",
      "\tBatch 1400 of 50000 training acc 72.87 val acc 71.88\n",
      "\tBatch 1500 of 50000 training acc 73.68 val acc 73.72999999999999\n",
      "\tBatch 1600 of 50000 training acc 75.286 val acc 74.97\n",
      "\tBatch 1700 of 50000 training acc 70.848 val acc 70.33\n",
      "\tBatch 1800 of 50000 training acc 74.998 val acc 74.86\n",
      "\tBatch 1900 of 50000 training acc 71.26400000000001 val acc 70.28999999999999\n",
      "\tBatch 2000 of 50000 training acc 72.942 val acc 72.47\n",
      "\tBatch 2100 of 50000 training acc 75.0 val acc 74.41\n",
      "\tBatch 2200 of 50000 training acc 73.934 val acc 73.56\n",
      "\tBatch 2300 of 50000 training acc 72.908 val acc 72.56\n",
      "\tBatch 2400 of 50000 training acc 67.926 val acc 66.95\n",
      "\tBatch 2500 of 50000 training acc 68.62 val acc 68.47999999999999\n",
      "\tBatch 2600 of 50000 training acc 72.222 val acc 71.06\n",
      "\tBatch 2700 of 50000 training acc 69.702 val acc 69.3\n",
      "\tBatch 2800 of 50000 training acc 71.14200000000001 val acc 70.38\n",
      "\tBatch 2900 of 50000 training acc 73.98 val acc 72.92999999999999\n",
      "\tBatch 3000 of 50000 training acc 66.026 val acc 65.38000000000001\n",
      "\tBatch 3100 of 50000 training acc 69.626 val acc 69.06\n",
      "\tBatch 3200 of 50000 training acc 75.78 val acc 75.12\n",
      "\tBatch 3300 of 50000 training acc 70.09 val acc 68.97999999999999\n",
      "\tBatch 3400 of 50000 training acc 73.92999999999999 val acc 73.36\n",
      "\tBatch 3500 of 50000 training acc 74.17 val acc 74.05000000000001\n",
      "\tBatch 3600 of 50000 training acc 68.132 val acc 67.33\n",
      "\tBatch 3700 of 50000 training acc 75.09599999999999 val acc 74.47\n",
      "\tBatch 3800 of 50000 training acc 74.618 val acc 73.88\n",
      "\tBatch 3900 of 50000 training acc 74.734 val acc 73.94\n",
      "\tBatch 4000 of 50000 training acc 71.532 val acc 71.33\n",
      "\tBatch 4100 of 50000 training acc 63.844 val acc 63.160000000000004\n",
      "\tBatch 4200 of 50000 training acc 76.86 val acc 76.36\n",
      "\tBatch 4300 of 50000 training acc 74.188 val acc 73.78\n",
      "\tBatch 4400 of 50000 training acc 72.408 val acc 71.92\n",
      "\tBatch 4500 of 50000 training acc 75.638 val acc 75.44\n",
      "\tBatch 4600 of 50000 training acc 78.75 val acc 78.53999999999999\n",
      "\tBatch 4700 of 50000 training acc 79.792 val acc 79.09\n",
      "\tBatch 4800 of 50000 training acc 77.198 val acc 76.83\n",
      "\tBatch 4900 of 50000 training acc 77.116 val acc 76.64999999999999\n",
      "\tBatch 5000 of 50000 training acc 76.644 val acc 75.94999999999999\n",
      "\tBatch 5100 of 50000 training acc 74.83999999999999 val acc 74.03\n",
      "\tBatch 5200 of 50000 training acc 74.644 val acc 74.32\n",
      "\tBatch 5300 of 50000 training acc 75.298 val acc 74.82\n",
      "\tBatch 5400 of 50000 training acc 70.164 val acc 69.75\n",
      "\tBatch 5500 of 50000 training acc 77.102 val acc 75.98\n",
      "\tBatch 5600 of 50000 training acc 71.194 val acc 70.3\n",
      "\tBatch 5700 of 50000 training acc 71.04599999999999 val acc 70.25\n",
      "\tBatch 5800 of 50000 training acc 74.21799999999999 val acc 73.50999999999999\n",
      "\tBatch 5900 of 50000 training acc 77.924 val acc 76.69\n",
      "\tBatch 6000 of 50000 training acc 78.768 val acc 77.69\n",
      "\tBatch 6100 of 50000 training acc 69.53399999999999 val acc 68.72\n",
      "\tBatch 6200 of 50000 training acc 75.236 val acc 74.55000000000001\n",
      "\tBatch 6300 of 50000 training acc 77.29 val acc 76.09\n",
      "\tBatch 6400 of 50000 training acc 78.976 val acc 77.73\n",
      "\tBatch 6500 of 50000 training acc 73.182 val acc 72.84\n",
      "\tBatch 6600 of 50000 training acc 73.866 val acc 73.53\n",
      "\tBatch 6700 of 50000 training acc 79.288 val acc 78.42\n",
      "\tBatch 6800 of 50000 training acc 78.11399999999999 val acc 77.35\n",
      "\tBatch 6900 of 50000 training acc 77.534 val acc 77.18\n",
      "\tBatch 7000 of 50000 training acc 71.27799999999999 val acc 70.56\n",
      "\tBatch 7100 of 50000 training acc 74.636 val acc 74.13\n",
      "\tBatch 7200 of 50000 training acc 78.924 val acc 78.22\n",
      "\tBatch 7300 of 50000 training acc 73.868 val acc 73.14\n",
      "\tBatch 7400 of 50000 training acc 76.63799999999999 val acc 75.91\n",
      "\tBatch 7500 of 50000 training acc 75.316 val acc 74.96000000000001\n",
      "\tBatch 7600 of 50000 training acc 76.902 val acc 75.92999999999999\n",
      "\tBatch 7700 of 50000 training acc 71.544 val acc 71.38\n",
      "\tBatch 7800 of 50000 training acc 73.136 val acc 72.85000000000001\n",
      "\tBatch 7900 of 50000 training acc 74.532 val acc 73.82\n",
      "\tBatch 8000 of 50000 training acc 76.64800000000001 val acc 75.69\n",
      "\tBatch 8100 of 50000 training acc 78.206 val acc 77.99000000000001\n",
      "\tBatch 8200 of 50000 training acc 78.342 val acc 78.08\n",
      "\tBatch 8300 of 50000 training acc 75.40599999999999 val acc 75.26\n",
      "\tBatch 8400 of 50000 training acc 77.17399999999999 val acc 76.73\n",
      "\tBatch 8500 of 50000 training acc 76.666 val acc 75.76\n",
      "\tBatch 8600 of 50000 training acc 76.454 val acc 75.73\n",
      "\tBatch 8700 of 50000 training acc 75.78399999999999 val acc 75.53\n",
      "\tBatch 8800 of 50000 training acc 75.168 val acc 74.57000000000001\n",
      "\tBatch 8900 of 50000 training acc 75.70400000000001 val acc 74.83\n",
      "\tBatch 9000 of 50000 training acc 78.18 val acc 77.46\n",
      "\tBatch 9100 of 50000 training acc 76.94 val acc 75.99000000000001\n",
      "\tBatch 9200 of 50000 training acc 78.16199999999999 val acc 77.83\n",
      "\tBatch 9300 of 50000 training acc 77.752 val acc 76.83\n",
      "\tBatch 9400 of 50000 training acc 79.116 val acc 78.49000000000001\n",
      "\tBatch 9500 of 50000 training acc 71.224 val acc 69.54\n",
      "\tBatch 9600 of 50000 training acc 76.19399999999999 val acc 75.42999999999999\n",
      "\tBatch 9700 of 50000 training acc 75.64 val acc 75.06\n",
      "\tBatch 9800 of 50000 training acc 75.75 val acc 75.72\n",
      "\tBatch 9900 of 50000 training acc 77.4 val acc 76.74\n",
      "\tBatch 10000 of 50000 training acc 76.962 val acc 76.61\n",
      "\tBatch 10100 of 50000 training acc 70.53 val acc 69.93\n",
      "\tBatch 10200 of 50000 training acc 77.986 val acc 77.74\n",
      "\tBatch 10300 of 50000 training acc 78.14 val acc 77.45\n",
      "\tBatch 10400 of 50000 training acc 78.968 val acc 78.64\n",
      "\tBatch 10500 of 50000 training acc 75.17200000000001 val acc 74.31\n",
      "\tBatch 10600 of 50000 training acc 79.128 val acc 78.64999999999999\n",
      "\tBatch 10700 of 50000 training acc 78.318 val acc 77.8\n",
      "\tBatch 10800 of 50000 training acc 79.066 val acc 78.0\n",
      "\tBatch 10900 of 50000 training acc 80.158 val acc 79.51\n",
      "\tBatch 11000 of 50000 training acc 77.708 val acc 77.33\n",
      "\tBatch 11100 of 50000 training acc 75.742 val acc 75.35\n",
      "\tBatch 11200 of 50000 training acc 76.738 val acc 76.42\n",
      "\tBatch 11300 of 50000 training acc 77.932 val acc 77.64\n",
      "\tBatch 11400 of 50000 training acc 74.136 val acc 73.6\n",
      "\tBatch 11500 of 50000 training acc 76.588 val acc 75.82\n",
      "\tBatch 11600 of 50000 training acc 75.876 val acc 75.52\n",
      "\tBatch 11700 of 50000 training acc 75.018 val acc 74.25\n",
      "\tBatch 11800 of 50000 training acc 77.022 val acc 76.71\n",
      "\tBatch 11900 of 50000 training acc 70.352 val acc 69.5\n",
      "\tBatch 12000 of 50000 training acc 75.592 val acc 74.65\n",
      "\tBatch 12100 of 50000 training acc 70.99 val acc 69.36\n",
      "\tBatch 12200 of 50000 training acc 74.19 val acc 73.81\n",
      "\tBatch 12300 of 50000 training acc 75.51 val acc 74.82\n",
      "\tBatch 12400 of 50000 training acc 77.31 val acc 76.69\n",
      "\tBatch 12500 of 50000 training acc 78.412 val acc 77.35\n",
      "\tBatch 12600 of 50000 training acc 79.042 val acc 78.06\n",
      "\tBatch 12700 of 50000 training acc 78.99199999999999 val acc 78.69\n",
      "\tBatch 12800 of 50000 training acc 69.43599999999999 val acc 68.31\n",
      "\tBatch 12900 of 50000 training acc 77.84 val acc 77.66\n",
      "\tBatch 13000 of 50000 training acc 79.784 val acc 79.36999999999999\n",
      "\tBatch 13100 of 50000 training acc 81.134 val acc 80.38\n",
      "\tBatch 13200 of 50000 training acc 77.46600000000001 val acc 77.16\n",
      "\tBatch 13300 of 50000 training acc 79.094 val acc 78.84\n",
      "\tBatch 13400 of 50000 training acc 74.842 val acc 74.47\n",
      "\tBatch 13500 of 50000 training acc 79.02799999999999 val acc 78.28\n",
      "\tBatch 13600 of 50000 training acc 78.25999999999999 val acc 77.44\n",
      "\tBatch 13700 of 50000 training acc 77.998 val acc 76.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 13800 of 50000 training acc 76.67399999999999 val acc 75.99000000000001\n",
      "\tBatch 13900 of 50000 training acc 77.73400000000001 val acc 76.94\n",
      "\tBatch 14000 of 50000 training acc 78.316 val acc 78.12\n",
      "\tBatch 14100 of 50000 training acc 78.846 val acc 78.06\n",
      "\tBatch 14200 of 50000 training acc 76.03999999999999 val acc 75.42\n",
      "\tBatch 14300 of 50000 training acc 75.89200000000001 val acc 75.79\n",
      "\tBatch 14400 of 50000 training acc 78.098 val acc 77.79\n",
      "\tBatch 14500 of 50000 training acc 78.708 val acc 78.62\n",
      "\tBatch 14600 of 50000 training acc 76.16000000000001 val acc 76.11\n",
      "\tBatch 14700 of 50000 training acc 81.21199999999999 val acc 80.71000000000001\n",
      "\tBatch 14800 of 50000 training acc 79.31200000000001 val acc 79.01\n",
      "\tBatch 14900 of 50000 training acc 79.684 val acc 79.10000000000001\n",
      "\tBatch 15000 of 50000 training acc 80.502 val acc 80.08999999999999\n",
      "\tBatch 15100 of 50000 training acc 75.128 val acc 74.47\n",
      "\tBatch 15200 of 50000 training acc 76.298 val acc 75.78\n",
      "\tBatch 15300 of 50000 training acc 78.604 val acc 77.03999999999999\n",
      "\tBatch 15400 of 50000 training acc 77.05199999999999 val acc 76.17\n",
      "\tBatch 15500 of 50000 training acc 76.70400000000001 val acc 76.25999999999999\n",
      "\tBatch 15600 of 50000 training acc 79.622 val acc 78.7\n",
      "\tBatch 15700 of 50000 training acc 80.836 val acc 80.24\n",
      "\tBatch 15800 of 50000 training acc 77.498 val acc 76.92999999999999\n",
      "\tBatch 15900 of 50000 training acc 78.842 val acc 78.25\n",
      "\tBatch 16000 of 50000 training acc 78.768 val acc 78.45\n",
      "\tBatch 16100 of 50000 training acc 77.30799999999999 val acc 77.14999999999999\n",
      "\tBatch 16200 of 50000 training acc 78.716 val acc 78.14\n",
      "\tBatch 16300 of 50000 training acc 72.698 val acc 71.83\n",
      "\tBatch 16400 of 50000 training acc 75.24 val acc 74.76\n",
      "\tBatch 16500 of 50000 training acc 80.278 val acc 79.75\n",
      "\tBatch 16600 of 50000 training acc 76.12400000000001 val acc 75.83\n",
      "\tBatch 16700 of 50000 training acc 78.12 val acc 77.14\n",
      "\tBatch 16800 of 50000 training acc 75.89 val acc 75.22\n",
      "\tBatch 16900 of 50000 training acc 78.732 val acc 77.92999999999999\n",
      "\tBatch 17000 of 50000 training acc 76.266 val acc 75.96000000000001\n",
      "\tBatch 17100 of 50000 training acc 77.768 val acc 76.98\n",
      "\tBatch 17200 of 50000 training acc 79.242 val acc 78.24\n",
      "\tBatch 17300 of 50000 training acc 78.74799999999999 val acc 78.14\n",
      "\tBatch 17400 of 50000 training acc 78.62 val acc 78.09\n",
      "\tBatch 17500 of 50000 training acc 76.884 val acc 76.03\n",
      "\tBatch 17600 of 50000 training acc 74.274 val acc 72.89999999999999\n",
      "\tBatch 17700 of 50000 training acc 73.772 val acc 73.5\n",
      "\tBatch 17800 of 50000 training acc 78.774 val acc 78.25999999999999\n",
      "\tBatch 17900 of 50000 training acc 76.69200000000001 val acc 76.67\n",
      "\tBatch 18000 of 50000 training acc 77.28399999999999 val acc 76.79\n",
      "\tBatch 18100 of 50000 training acc 77.94 val acc 77.33\n",
      "\tBatch 18200 of 50000 training acc 74.792 val acc 73.89\n",
      "\tBatch 18300 of 50000 training acc 77.972 val acc 77.37\n",
      "\tBatch 18400 of 50000 training acc 66.572 val acc 66.12\n",
      "\tBatch 18500 of 50000 training acc 76.02799999999999 val acc 75.27000000000001\n",
      "\tBatch 18600 of 50000 training acc 75.954 val acc 75.11\n",
      "\tBatch 18700 of 50000 training acc 80.452 val acc 79.91\n",
      "\tBatch 18800 of 50000 training acc 76.084 val acc 75.5\n",
      "\tBatch 18900 of 50000 training acc 78.508 val acc 77.85\n",
      "\tBatch 19000 of 50000 training acc 80.774 val acc 79.61\n",
      "\tBatch 19100 of 50000 training acc 76.35 val acc 75.58\n",
      "\tBatch 19200 of 50000 training acc 75.7 val acc 75.72\n",
      "\tBatch 19300 of 50000 training acc 76.266 val acc 76.01\n",
      "\tBatch 19400 of 50000 training acc 74.79 val acc 74.24\n",
      "\tBatch 19500 of 50000 training acc 79.384 val acc 78.9\n",
      "\tBatch 19600 of 50000 training acc 80.99 val acc 79.92\n",
      "\tBatch 19700 of 50000 training acc 79.168 val acc 78.38000000000001\n",
      "\tBatch 19800 of 50000 training acc 77.134 val acc 76.38000000000001\n",
      "\tBatch 19900 of 50000 training acc 79.59 val acc 78.86\n",
      "\tBatch 20000 of 50000 training acc 79.474 val acc 78.7\n",
      "\tBatch 20100 of 50000 training acc 79.66 val acc 78.64\n",
      "\tBatch 20200 of 50000 training acc 75.72 val acc 74.48\n",
      "\tBatch 20300 of 50000 training acc 78.802 val acc 77.86999999999999\n",
      "\tBatch 20400 of 50000 training acc 77.736 val acc 77.59\n",
      "\tBatch 20500 of 50000 training acc 77.66 val acc 76.44\n",
      "\tBatch 20600 of 50000 training acc 77.91799999999999 val acc 77.29\n",
      "\tBatch 20700 of 50000 training acc 76.556 val acc 75.66000000000001\n",
      "\tBatch 20800 of 50000 training acc 75.362 val acc 74.56\n",
      "\tBatch 20900 of 50000 training acc 79.026 val acc 78.74\n",
      "\tBatch 21000 of 50000 training acc 76.594 val acc 76.29\n",
      "\tBatch 21100 of 50000 training acc 78.562 val acc 77.29\n",
      "\tBatch 21200 of 50000 training acc 79.23400000000001 val acc 78.25999999999999\n",
      "\tBatch 21300 of 50000 training acc 73.854 val acc 72.58\n",
      "\tBatch 21400 of 50000 training acc 73.92 val acc 72.97\n",
      "\tBatch 21500 of 50000 training acc 79.158 val acc 77.88000000000001\n",
      "\tBatch 21600 of 50000 training acc 78.74799999999999 val acc 78.0\n",
      "\tBatch 21700 of 50000 training acc 81.33 val acc 80.11\n",
      "\tBatch 21800 of 50000 training acc 77.63600000000001 val acc 76.36\n",
      "\tBatch 21900 of 50000 training acc 79.69000000000001 val acc 78.19\n",
      "\tBatch 22000 of 50000 training acc 81.186 val acc 80.49\n",
      "\tBatch 22100 of 50000 training acc 77.13 val acc 75.98\n",
      "\tBatch 22200 of 50000 training acc 74.72999999999999 val acc 73.72999999999999\n",
      "\tBatch 22300 of 50000 training acc 75.41 val acc 74.62\n",
      "\tBatch 22400 of 50000 training acc 77.306 val acc 76.72\n",
      "\tBatch 22500 of 50000 training acc 80.19800000000001 val acc 79.38\n",
      "\tBatch 22600 of 50000 training acc 77.68 val acc 76.19\n",
      "\tBatch 22700 of 50000 training acc 78.93 val acc 78.03999999999999\n",
      "\tBatch 22800 of 50000 training acc 80.086 val acc 79.22\n",
      "\tBatch 22900 of 50000 training acc 79.932 val acc 79.08\n",
      "\tBatch 23000 of 50000 training acc 73.642 val acc 72.26\n",
      "\tBatch 23100 of 50000 training acc 79.95400000000001 val acc 79.14\n",
      "\tBatch 23200 of 50000 training acc 79.434 val acc 78.44\n",
      "\tBatch 23300 of 50000 training acc 80.44 val acc 79.54\n",
      "\tBatch 23400 of 50000 training acc 78.312 val acc 77.55\n",
      "\tBatch 23500 of 50000 training acc 75.78 val acc 75.28\n",
      "\tBatch 23600 of 50000 training acc 79.162 val acc 78.35\n",
      "\tBatch 23700 of 50000 training acc 77.292 val acc 76.46\n",
      "\tBatch 23800 of 50000 training acc 81.758 val acc 80.65\n",
      "\tBatch 23900 of 50000 training acc 78.194 val acc 77.14\n",
      "\tBatch 24000 of 50000 training acc 76.126 val acc 74.99\n",
      "\tBatch 24100 of 50000 training acc 75.168 val acc 74.15\n",
      "\tBatch 24200 of 50000 training acc 75.032 val acc 74.17\n",
      "\tBatch 24300 of 50000 training acc 77.518 val acc 76.88000000000001\n",
      "\tBatch 24400 of 50000 training acc 80.56 val acc 79.69000000000001\n",
      "\tBatch 24500 of 50000 training acc 79.14999999999999 val acc 78.56\n",
      "\tBatch 24600 of 50000 training acc 79.12400000000001 val acc 78.97999999999999\n",
      "\tBatch 24700 of 50000 training acc 80.036 val acc 79.34\n",
      "\tBatch 24800 of 50000 training acc 77.664 val acc 76.59\n",
      "\tBatch 24900 of 50000 training acc 78.982 val acc 78.19\n",
      "\tBatch 25000 of 50000 training acc 79.91 val acc 78.99000000000001\n",
      "\tBatch 25100 of 50000 training acc 79.452 val acc 78.93\n",
      "\tBatch 25200 of 50000 training acc 81.128 val acc 80.36\n",
      "\tBatch 25300 of 50000 training acc 81.294 val acc 80.53\n",
      "\tBatch 25400 of 50000 training acc 76.182 val acc 75.2\n",
      "\tBatch 25500 of 50000 training acc 80.71199999999999 val acc 79.88\n",
      "\tBatch 25600 of 50000 training acc 74.94800000000001 val acc 73.67\n",
      "\tBatch 25700 of 50000 training acc 77.322 val acc 76.37\n",
      "\tBatch 25800 of 50000 training acc 74.914 val acc 74.69\n",
      "\tBatch 25900 of 50000 training acc 73.006 val acc 71.88\n",
      "\tBatch 26000 of 50000 training acc 79.63 val acc 78.7\n",
      "\tBatch 26100 of 50000 training acc 79.512 val acc 78.66\n",
      "\tBatch 26200 of 50000 training acc 78.684 val acc 77.72\n",
      "\tBatch 26300 of 50000 training acc 78.096 val acc 77.13\n",
      "\tBatch 26400 of 50000 training acc 80.206 val acc 79.3\n",
      "\tBatch 26500 of 50000 training acc 78.846 val acc 77.86\n",
      "\tBatch 26600 of 50000 training acc 77.83 val acc 76.22\n",
      "\tBatch 26700 of 50000 training acc 77.792 val acc 76.52\n",
      "\tBatch 26800 of 50000 training acc 79.766 val acc 78.78\n",
      "\tBatch 26900 of 50000 training acc 79.658 val acc 78.43\n",
      "\tBatch 27000 of 50000 training acc 80.784 val acc 79.86\n",
      "\tBatch 27100 of 50000 training acc 81.086 val acc 80.05\n",
      "\tBatch 27200 of 50000 training acc 78.8 val acc 77.73\n",
      "\tBatch 27300 of 50000 training acc 80.306 val acc 78.82000000000001\n",
      "\tBatch 27400 of 50000 training acc 78.96 val acc 77.99000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 27500 of 50000 training acc 80.08999999999999 val acc 79.05\n",
      "\tBatch 27600 of 50000 training acc 75.49 val acc 74.9\n",
      "\tBatch 27700 of 50000 training acc 72.456 val acc 71.21\n",
      "\tBatch 27800 of 50000 training acc 78.104 val acc 76.98\n",
      "\tBatch 27900 of 50000 training acc 77.578 val acc 76.99000000000001\n",
      "\tBatch 28000 of 50000 training acc 76.218 val acc 75.77000000000001\n",
      "\tBatch 28100 of 50000 training acc 80.46600000000001 val acc 79.78\n",
      "\tBatch 28200 of 50000 training acc 77.422 val acc 76.66\n",
      "\tBatch 28300 of 50000 training acc 79.166 val acc 77.89\n",
      "\tBatch 28400 of 50000 training acc 75.244 val acc 74.25\n",
      "\tBatch 28500 of 50000 training acc 75.588 val acc 74.5\n",
      "\tBatch 28600 of 50000 training acc 76.94800000000001 val acc 75.71\n",
      "\tBatch 28700 of 50000 training acc 80.054 val acc 79.42\n",
      "\tBatch 28800 of 50000 training acc 74.968 val acc 73.50999999999999\n",
      "\tBatch 28900 of 50000 training acc 79.008 val acc 78.21000000000001\n",
      "\tBatch 29000 of 50000 training acc 76.358 val acc 75.22\n",
      "\tBatch 29100 of 50000 training acc 77.816 val acc 77.23\n",
      "\tBatch 29200 of 50000 training acc 77.08 val acc 76.75\n",
      "\tBatch 29300 of 50000 training acc 76.97800000000001 val acc 76.5\n",
      "\tBatch 29400 of 50000 training acc 78.006 val acc 77.47\n",
      "\tBatch 29500 of 50000 training acc 79.62599999999999 val acc 79.01\n",
      "\tBatch 29600 of 50000 training acc 77.31400000000001 val acc 76.66\n",
      "\tBatch 29700 of 50000 training acc 76.956 val acc 76.52\n",
      "\tBatch 29800 of 50000 training acc 78.916 val acc 77.98\n",
      "\tBatch 29900 of 50000 training acc 78.618 val acc 77.47\n",
      "\tBatch 30000 of 50000 training acc 82.0 val acc 81.27\n",
      "\tBatch 30100 of 50000 training acc 76.156 val acc 75.31\n",
      "\tBatch 30200 of 50000 training acc 78.518 val acc 77.49000000000001\n",
      "\tBatch 30300 of 50000 training acc 78.128 val acc 77.44\n",
      "\tBatch 30400 of 50000 training acc 80.04599999999999 val acc 80.06\n",
      "\tBatch 30500 of 50000 training acc 72.718 val acc 72.00999999999999\n",
      "\tBatch 30600 of 50000 training acc 80.918 val acc 80.33\n",
      "\tBatch 30700 of 50000 training acc 80.474 val acc 79.71000000000001\n",
      "\tBatch 30800 of 50000 training acc 79.982 val acc 79.0\n",
      "\tBatch 30900 of 50000 training acc 77.34 val acc 76.55\n",
      "\tBatch 31000 of 50000 training acc 71.194 val acc 69.89999999999999\n",
      "\tBatch 31100 of 50000 training acc 75.388 val acc 74.56\n",
      "\tBatch 31200 of 50000 training acc 79.64 val acc 78.94\n",
      "\tBatch 31300 of 50000 training acc 78.41799999999999 val acc 77.37\n",
      "\tBatch 31400 of 50000 training acc 81.61 val acc 80.93\n",
      "\tBatch 31500 of 50000 training acc 79.592 val acc 78.29\n",
      "\tBatch 31600 of 50000 training acc 78.43 val acc 77.56\n",
      "\tBatch 31700 of 50000 training acc 78.28399999999999 val acc 77.37\n",
      "\tBatch 31800 of 50000 training acc 75.05 val acc 74.09\n",
      "\tBatch 31900 of 50000 training acc 80.266 val acc 79.47999999999999\n",
      "\tBatch 32000 of 50000 training acc 81.218 val acc 80.28999999999999\n",
      "\tBatch 32100 of 50000 training acc 74.20400000000001 val acc 73.0\n",
      "\tBatch 32200 of 50000 training acc 74.712 val acc 73.34\n",
      "\tBatch 32300 of 50000 training acc 77.446 val acc 76.75\n",
      "\tBatch 32400 of 50000 training acc 79.106 val acc 78.79\n",
      "\tBatch 32500 of 50000 training acc 77.486 val acc 75.82\n",
      "\tBatch 32600 of 50000 training acc 81.134 val acc 80.88\n",
      "\tBatch 32700 of 50000 training acc 81.3 val acc 81.03\n",
      "\tBatch 32800 of 50000 training acc 76.55999999999999 val acc 75.77000000000001\n",
      "\tBatch 32900 of 50000 training acc 78.55 val acc 77.74\n",
      "\tBatch 33000 of 50000 training acc 79.238 val acc 78.13\n",
      "\tBatch 33100 of 50000 training acc 79.906 val acc 79.14999999999999\n",
      "\tBatch 33200 of 50000 training acc 76.328 val acc 75.92\n",
      "\tBatch 33300 of 50000 training acc 77.78 val acc 77.64999999999999\n",
      "\tBatch 33400 of 50000 training acc 79.886 val acc 79.61\n",
      "\tBatch 33500 of 50000 training acc 77.534 val acc 76.84\n",
      "\tBatch 33600 of 50000 training acc 78.468 val acc 77.74\n",
      "\tBatch 33700 of 50000 training acc 79.642 val acc 79.10000000000001\n",
      "\tBatch 33800 of 50000 training acc 74.19200000000001 val acc 73.5\n",
      "\tBatch 33900 of 50000 training acc 77.434 val acc 76.84\n",
      "\tBatch 34000 of 50000 training acc 73.374 val acc 72.7\n",
      "\tBatch 34100 of 50000 training acc 73.018 val acc 72.02\n",
      "\tBatch 34200 of 50000 training acc 77.548 val acc 76.81\n",
      "\tBatch 34300 of 50000 training acc 76.518 val acc 76.03999999999999\n",
      "\tBatch 34400 of 50000 training acc 75.52600000000001 val acc 74.76\n",
      "\tBatch 34500 of 50000 training acc 79.05799999999999 val acc 79.11\n",
      "\tBatch 34600 of 50000 training acc 80.652 val acc 80.01\n",
      "\tBatch 34700 of 50000 training acc 81.748 val acc 81.35\n",
      "\tBatch 34800 of 50000 training acc 75.536 val acc 75.19\n",
      "\tBatch 34900 of 50000 training acc 81.098 val acc 80.63\n",
      "\tBatch 35000 of 50000 training acc 75.18599999999999 val acc 74.65\n",
      "\tBatch 35100 of 50000 training acc 80.502 val acc 79.85\n",
      "\tBatch 35200 of 50000 training acc 78.716 val acc 77.64\n",
      "\tBatch 35300 of 50000 training acc 78.014 val acc 77.16\n",
      "\tBatch 35400 of 50000 training acc 79.416 val acc 78.64\n",
      "\tBatch 35500 of 50000 training acc 77.84400000000001 val acc 76.38000000000001\n",
      "\tBatch 35600 of 50000 training acc 80.02 val acc 78.92\n",
      "\tBatch 35700 of 50000 training acc 78.16199999999999 val acc 77.03999999999999\n",
      "\tBatch 35800 of 50000 training acc 77.49000000000001 val acc 76.74\n",
      "\tBatch 35900 of 50000 training acc 76.044 val acc 75.09\n",
      "\tBatch 36000 of 50000 training acc 76.702 val acc 75.59\n",
      "\tBatch 36100 of 50000 training acc 72.92999999999999 val acc 72.54\n",
      "\tBatch 36200 of 50000 training acc 73.03 val acc 71.46000000000001\n",
      "\tBatch 36300 of 50000 training acc 81.44200000000001 val acc 80.34\n",
      "\tBatch 36400 of 50000 training acc 77.19200000000001 val acc 76.14999999999999\n",
      "\tBatch 36500 of 50000 training acc 79.404 val acc 78.84\n",
      "\tBatch 36600 of 50000 training acc 78.91 val acc 77.96\n",
      "\tBatch 36700 of 50000 training acc 79.742 val acc 79.17\n",
      "\tBatch 36800 of 50000 training acc 73.962 val acc 73.48\n",
      "\tBatch 36900 of 50000 training acc 77.42 val acc 76.29\n",
      "\tBatch 37000 of 50000 training acc 76.51400000000001 val acc 75.36\n",
      "\tBatch 37100 of 50000 training acc 79.59 val acc 78.93\n",
      "\tBatch 37200 of 50000 training acc 80.568 val acc 79.5\n",
      "\tBatch 37300 of 50000 training acc 76.88000000000001 val acc 76.64999999999999\n",
      "\tBatch 37400 of 50000 training acc 78.802 val acc 77.75\n",
      "\tBatch 37500 of 50000 training acc 79.608 val acc 78.66\n",
      "\tBatch 37600 of 50000 training acc 77.322 val acc 76.57000000000001\n",
      "\tBatch 37700 of 50000 training acc 74.17 val acc 73.38\n",
      "\tBatch 37800 of 50000 training acc 79.444 val acc 78.53999999999999\n",
      "\tBatch 37900 of 50000 training acc 77.824 val acc 77.41\n",
      "\tBatch 38000 of 50000 training acc 80.77600000000001 val acc 79.86\n",
      "\tBatch 38100 of 50000 training acc 78.958 val acc 77.92999999999999\n",
      "\tBatch 38200 of 50000 training acc 75.334 val acc 74.4\n",
      "\tBatch 38300 of 50000 training acc 75.144 val acc 74.92\n",
      "\tBatch 38400 of 50000 training acc 80.99199999999999 val acc 80.71000000000001\n",
      "\tBatch 38500 of 50000 training acc 80.77600000000001 val acc 80.24\n",
      "\tBatch 38600 of 50000 training acc 76.464 val acc 75.55\n",
      "\tBatch 38700 of 50000 training acc 75.398 val acc 74.17\n",
      "\tBatch 38800 of 50000 training acc 80.604 val acc 80.0\n",
      "\tBatch 38900 of 50000 training acc 79.318 val acc 78.48\n",
      "\tBatch 39000 of 50000 training acc 78.274 val acc 77.66\n",
      "\tBatch 39100 of 50000 training acc 77.41799999999999 val acc 76.6\n",
      "\tBatch 39200 of 50000 training acc 74.78200000000001 val acc 73.75\n",
      "\tBatch 39300 of 50000 training acc 77.414 val acc 76.36\n",
      "\tBatch 39400 of 50000 training acc 77.654 val acc 77.14999999999999\n",
      "\tBatch 39500 of 50000 training acc 78.932 val acc 78.46\n",
      "\tBatch 39600 of 50000 training acc 74.878 val acc 74.42999999999999\n",
      "\tBatch 39700 of 50000 training acc 80.00399999999999 val acc 79.59\n",
      "\tBatch 39800 of 50000 training acc 74.91799999999999 val acc 74.45\n",
      "\tBatch 39900 of 50000 training acc 79.79 val acc 78.69\n",
      "\tBatch 40000 of 50000 training acc 78.866 val acc 77.91\n",
      "\tBatch 40100 of 50000 training acc 81.056 val acc 80.25999999999999\n",
      "\tBatch 40200 of 50000 training acc 75.408 val acc 74.1\n",
      "\tBatch 40300 of 50000 training acc 80.134 val acc 78.97\n",
      "\tBatch 40400 of 50000 training acc 76.81400000000001 val acc 75.7\n",
      "\tBatch 40500 of 50000 training acc 72.706 val acc 72.04\n",
      "\tBatch 40600 of 50000 training acc 76.874 val acc 75.66000000000001\n",
      "\tBatch 40700 of 50000 training acc 80.814 val acc 79.83\n",
      "\tBatch 40800 of 50000 training acc 80.082 val acc 78.96\n",
      "\tBatch 40900 of 50000 training acc 80.55600000000001 val acc 79.25999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 41000 of 50000 training acc 79.24 val acc 78.21000000000001\n",
      "\tBatch 41100 of 50000 training acc 78.056 val acc 77.46\n",
      "\tBatch 41200 of 50000 training acc 76.51400000000001 val acc 75.69\n",
      "\tBatch 41300 of 50000 training acc 77.446 val acc 75.97\n",
      "\tBatch 41400 of 50000 training acc 74.75 val acc 73.39\n",
      "\tBatch 41500 of 50000 training acc 82.242 val acc 81.27\n",
      "\tBatch 41600 of 50000 training acc 81.27600000000001 val acc 80.33\n",
      "\tBatch 41700 of 50000 training acc 80.916 val acc 79.94\n",
      "\tBatch 41800 of 50000 training acc 79.188 val acc 77.7\n",
      "\tBatch 41900 of 50000 training acc 74.616 val acc 73.41\n",
      "\tBatch 42000 of 50000 training acc 77.68599999999999 val acc 76.36\n",
      "\tBatch 42100 of 50000 training acc 78.28399999999999 val acc 77.19\n",
      "\tBatch 42200 of 50000 training acc 78.572 val acc 77.72\n",
      "\tBatch 42300 of 50000 training acc 78.988 val acc 77.61\n",
      "\tBatch 42400 of 50000 training acc 78.818 val acc 77.66999999999999\n",
      "\tBatch 42500 of 50000 training acc 78.444 val acc 77.57\n",
      "\tBatch 42600 of 50000 training acc 79.308 val acc 78.25\n",
      "\tBatch 42700 of 50000 training acc 77.738 val acc 76.44999999999999\n",
      "\tBatch 42800 of 50000 training acc 81.176 val acc 79.73\n",
      "\tBatch 42900 of 50000 training acc 74.958 val acc 73.59\n",
      "\tBatch 43000 of 50000 training acc 80.152 val acc 78.49000000000001\n",
      "\tBatch 43100 of 50000 training acc 81.852 val acc 80.13\n",
      "\tBatch 43200 of 50000 training acc 79.276 val acc 77.38000000000001\n",
      "\tBatch 43300 of 50000 training acc 73.554 val acc 72.44\n",
      "\tBatch 43400 of 50000 training acc 77.968 val acc 76.38000000000001\n",
      "\tBatch 43500 of 50000 training acc 78.97999999999999 val acc 77.88000000000001\n",
      "\tBatch 43600 of 50000 training acc 82.482 val acc 80.97999999999999\n",
      "\tBatch 43700 of 50000 training acc 79.7 val acc 78.17\n",
      "\tBatch 43800 of 50000 training acc 77.444 val acc 75.64\n",
      "\tBatch 43900 of 50000 training acc 79.662 val acc 78.63\n",
      "\tBatch 44000 of 50000 training acc 76.66199999999999 val acc 75.58\n",
      "\tBatch 44100 of 50000 training acc 79.584 val acc 78.64999999999999\n",
      "\tBatch 44200 of 50000 training acc 79.62 val acc 78.36999999999999\n",
      "\tBatch 44300 of 50000 training acc 79.89 val acc 78.09\n",
      "\tBatch 44400 of 50000 training acc 75.588 val acc 74.65\n",
      "\tBatch 44500 of 50000 training acc 79.73400000000001 val acc 78.38000000000001\n",
      "\tBatch 44600 of 50000 training acc 79.31 val acc 77.45\n",
      "\tBatch 44700 of 50000 training acc 81.754 val acc 80.34\n",
      "\tBatch 44800 of 50000 training acc 74.798 val acc 73.54\n",
      "\tBatch 44900 of 50000 training acc 80.10000000000001 val acc 79.01\n",
      "\tBatch 45000 of 50000 training acc 79.59 val acc 78.73\n",
      "\tBatch 45100 of 50000 training acc 78.066 val acc 76.64999999999999\n",
      "\tBatch 45200 of 50000 training acc 80.488 val acc 78.82000000000001\n",
      "\tBatch 45300 of 50000 training acc 79.24799999999999 val acc 78.16\n",
      "\tBatch 45400 of 50000 training acc 77.044 val acc 75.83\n",
      "\tBatch 45500 of 50000 training acc 80.44 val acc 79.41\n",
      "\tBatch 45600 of 50000 training acc 76.506 val acc 75.06\n",
      "\tBatch 45700 of 50000 training acc 76.842 val acc 76.5\n",
      "\tBatch 45800 of 50000 training acc 72.31400000000001 val acc 71.67\n",
      "\tBatch 45900 of 50000 training acc 80.56400000000001 val acc 79.47\n",
      "\tBatch 46000 of 50000 training acc 79.77199999999999 val acc 77.53\n",
      "\tBatch 46100 of 50000 training acc 79.134 val acc 77.99000000000001\n",
      "\tBatch 46200 of 50000 training acc 78.462 val acc 77.28\n",
      "\tBatch 46300 of 50000 training acc 77.968 val acc 76.78\n",
      "\tBatch 46400 of 50000 training acc 79.286 val acc 77.66\n",
      "\tBatch 46500 of 50000 training acc 79.756 val acc 78.35\n",
      "\tBatch 46600 of 50000 training acc 78.62 val acc 77.38000000000001\n",
      "\tBatch 46700 of 50000 training acc 78.186 val acc 77.17\n",
      "\tBatch 46800 of 50000 training acc 79.47999999999999 val acc 78.16\n",
      "\tBatch 46900 of 50000 training acc 79.952 val acc 78.72\n",
      "\tBatch 47000 of 50000 training acc 79.94200000000001 val acc 79.03999999999999\n",
      "\tBatch 47100 of 50000 training acc 77.14800000000001 val acc 76.62\n",
      "\tBatch 47200 of 50000 training acc 76.356 val acc 75.24\n",
      "\tBatch 47300 of 50000 training acc 80.174 val acc 79.52\n",
      "\tBatch 47400 of 50000 training acc 78.216 val acc 77.24\n",
      "\tBatch 47500 of 50000 training acc 80.284 val acc 79.28\n",
      "\tBatch 47600 of 50000 training acc 80.238 val acc 78.81\n",
      "\tBatch 47700 of 50000 training acc 76.212 val acc 74.98\n",
      "\tBatch 47800 of 50000 training acc 81.26 val acc 79.93\n",
      "\tBatch 47900 of 50000 training acc 78.63 val acc 77.39\n",
      "\tBatch 48000 of 50000 training acc 80.122 val acc 79.16\n",
      "\tBatch 48100 of 50000 training acc 81.65599999999999 val acc 80.74\n",
      "\tBatch 48200 of 50000 training acc 76.3 val acc 75.71\n",
      "\tBatch 48300 of 50000 training acc 77.664 val acc 76.75999999999999\n",
      "\tBatch 48400 of 50000 training acc 81.25 val acc 79.95\n",
      "\tBatch 48500 of 50000 training acc 78.93 val acc 77.9\n",
      "\tBatch 48600 of 50000 training acc 81.27600000000001 val acc 80.30000000000001\n",
      "\tBatch 48700 of 50000 training acc 81.574 val acc 80.35\n",
      "\tBatch 48800 of 50000 training acc 79.628 val acc 78.46\n",
      "\tBatch 48900 of 50000 training acc 80.538 val acc 79.2\n",
      "\tBatch 49000 of 50000 training acc 80.01 val acc 78.73\n",
      "\tBatch 49100 of 50000 training acc 78.732 val acc 77.2\n",
      "\tBatch 49200 of 50000 training acc 77.872 val acc 76.5\n",
      "\tBatch 49300 of 50000 training acc 80.392 val acc 79.14\n",
      "\tBatch 49400 of 50000 training acc 78.728 val acc 77.38000000000001\n",
      "\tBatch 49500 of 50000 training acc 76.68199999999999 val acc 75.57000000000001\n",
      "\tBatch 49600 of 50000 training acc 78.334 val acc 77.44\n",
      "\tBatch 49700 of 50000 training acc 77.84 val acc 76.29\n",
      "\tBatch 49800 of 50000 training acc 77.312 val acc 75.64\n",
      "\tBatch 49900 of 50000 training acc 75.016 val acc 73.83999999999999\n",
      "\tBatch 0 of 50000 training acc 80.17999999999999 val acc 78.73\n",
      "\tBatch 100 of 50000 training acc 78.854 val acc 77.94\n",
      "\tBatch 200 of 50000 training acc 80.738 val acc 79.81\n",
      "\tBatch 300 of 50000 training acc 78.494 val acc 77.77\n",
      "\tBatch 400 of 50000 training acc 78.532 val acc 77.64\n",
      "\tBatch 500 of 50000 training acc 80.744 val acc 80.28999999999999\n",
      "\tBatch 600 of 50000 training acc 80.88 val acc 79.67999999999999\n",
      "\tBatch 700 of 50000 training acc 75.376 val acc 74.65\n",
      "\tBatch 800 of 50000 training acc 79.88199999999999 val acc 79.28\n",
      "\tBatch 900 of 50000 training acc 78.28399999999999 val acc 77.39\n",
      "\tBatch 1000 of 50000 training acc 77.278 val acc 76.55999999999999\n",
      "\tBatch 1100 of 50000 training acc 77.596 val acc 76.44999999999999\n",
      "\tBatch 1200 of 50000 training acc 76.40599999999999 val acc 75.36\n",
      "\tBatch 1300 of 50000 training acc 78.03999999999999 val acc 76.88000000000001\n",
      "\tBatch 1400 of 50000 training acc 78.44 val acc 77.37\n",
      "\tBatch 1500 of 50000 training acc 77.29599999999999 val acc 76.38000000000001\n",
      "\tBatch 1600 of 50000 training acc 79.84599999999999 val acc 78.75\n",
      "\tBatch 1700 of 50000 training acc 78.184 val acc 77.36\n",
      "\tBatch 1800 of 50000 training acc 81.128 val acc 79.64\n",
      "\tBatch 1900 of 50000 training acc 76.466 val acc 75.35\n",
      "\tBatch 2000 of 50000 training acc 79.362 val acc 78.16\n",
      "\tBatch 2100 of 50000 training acc 77.256 val acc 76.8\n",
      "\tBatch 2200 of 50000 training acc 80.19800000000001 val acc 79.01\n",
      "\tBatch 2300 of 50000 training acc 80.71199999999999 val acc 79.96\n",
      "\tBatch 2400 of 50000 training acc 78.56 val acc 77.64999999999999\n",
      "\tBatch 2500 of 50000 training acc 78.106 val acc 77.38000000000001\n",
      "\tBatch 2600 of 50000 training acc 76.134 val acc 74.97\n",
      "\tBatch 2700 of 50000 training acc 76.508 val acc 75.83\n",
      "\tBatch 2800 of 50000 training acc 78.336 val acc 77.08\n",
      "\tBatch 2900 of 50000 training acc 80.398 val acc 79.16\n",
      "\tBatch 3000 of 50000 training acc 76.61200000000001 val acc 75.59\n",
      "\tBatch 3100 of 50000 training acc 80.744 val acc 79.64\n",
      "\tBatch 3200 of 50000 training acc 80.44 val acc 79.81\n",
      "\tBatch 3300 of 50000 training acc 78.542 val acc 76.72\n",
      "\tBatch 3400 of 50000 training acc 80.432 val acc 79.01\n",
      "\tBatch 3500 of 50000 training acc 79.096 val acc 78.36999999999999\n",
      "\tBatch 3600 of 50000 training acc 76.372 val acc 75.02\n",
      "\tBatch 3700 of 50000 training acc 77.12 val acc 76.39\n",
      "\tBatch 3800 of 50000 training acc 79.972 val acc 78.99000000000001\n",
      "\tBatch 3900 of 50000 training acc 77.968 val acc 76.9\n",
      "\tBatch 4000 of 50000 training acc 77.712 val acc 76.83\n",
      "\tBatch 4100 of 50000 training acc 74.48 val acc 73.00999999999999\n",
      "\tBatch 4200 of 50000 training acc 79.164 val acc 77.83\n",
      "\tBatch 4300 of 50000 training acc 79.418 val acc 78.59\n",
      "\tBatch 4400 of 50000 training acc 77.61200000000001 val acc 76.91\n",
      "\tBatch 4500 of 50000 training acc 79.456 val acc 77.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 4600 of 50000 training acc 80.142 val acc 79.25\n",
      "\tBatch 4700 of 50000 training acc 79.918 val acc 78.64\n",
      "\tBatch 4800 of 50000 training acc 81.256 val acc 79.85\n",
      "\tBatch 4900 of 50000 training acc 80.852 val acc 80.21000000000001\n",
      "\tBatch 5000 of 50000 training acc 82.518 val acc 81.2\n",
      "\tBatch 5100 of 50000 training acc 78.72200000000001 val acc 76.99000000000001\n",
      "\tBatch 5200 of 50000 training acc 79.606 val acc 77.94\n",
      "\tBatch 5300 of 50000 training acc 80.69800000000001 val acc 79.83\n",
      "\tBatch 5400 of 50000 training acc 78.348 val acc 77.56\n",
      "\tBatch 5500 of 50000 training acc 79.972 val acc 78.75999999999999\n",
      "\tBatch 5600 of 50000 training acc 77.91 val acc 76.03999999999999\n",
      "\tBatch 5700 of 50000 training acc 75.47 val acc 74.08\n",
      "\tBatch 5800 of 50000 training acc 81.23599999999999 val acc 80.54\n",
      "\tBatch 5900 of 50000 training acc 78.59 val acc 77.91\n",
      "\tBatch 6000 of 50000 training acc 80.542 val acc 79.43\n",
      "\tBatch 6100 of 50000 training acc 72.586 val acc 71.41\n",
      "\tBatch 6200 of 50000 training acc 76.854 val acc 76.03999999999999\n",
      "\tBatch 6300 of 50000 training acc 79.508 val acc 78.33\n",
      "\tBatch 6400 of 50000 training acc 80.618 val acc 78.68\n",
      "\tBatch 6500 of 50000 training acc 79.33 val acc 78.02\n",
      "\tBatch 6600 of 50000 training acc 79.386 val acc 78.25\n",
      "\tBatch 6700 of 50000 training acc 80.86 val acc 79.11\n",
      "\tBatch 6800 of 50000 training acc 80.938 val acc 79.41\n",
      "\tBatch 6900 of 50000 training acc 78.88 val acc 77.83\n",
      "\tBatch 7000 of 50000 training acc 78.078 val acc 77.41\n",
      "\tBatch 7100 of 50000 training acc 80.10199999999999 val acc 79.07\n",
      "\tBatch 7200 of 50000 training acc 78.61 val acc 77.29\n",
      "\tBatch 7300 of 50000 training acc 78.634 val acc 77.47\n",
      "\tBatch 7400 of 50000 training acc 77.488 val acc 75.89\n",
      "\tBatch 7500 of 50000 training acc 77.68599999999999 val acc 76.18\n",
      "\tBatch 7600 of 50000 training acc 79.56 val acc 78.12\n",
      "\tBatch 7700 of 50000 training acc 76.778 val acc 75.83\n",
      "\tBatch 7800 of 50000 training acc 78.10000000000001 val acc 77.28\n",
      "\tBatch 7900 of 50000 training acc 80.97800000000001 val acc 79.53\n",
      "\tBatch 8000 of 50000 training acc 74.224 val acc 72.94\n",
      "\tBatch 8100 of 50000 training acc 81.842 val acc 80.47999999999999\n",
      "\tBatch 8200 of 50000 training acc 80.208 val acc 78.97\n",
      "\tBatch 8300 of 50000 training acc 79.77 val acc 78.46\n",
      "\tBatch 8400 of 50000 training acc 78.25999999999999 val acc 77.25999999999999\n",
      "\tBatch 8500 of 50000 training acc 81.182 val acc 80.13\n",
      "\tBatch 8600 of 50000 training acc 81.21199999999999 val acc 79.97\n",
      "\tBatch 8700 of 50000 training acc 77.80799999999999 val acc 77.10000000000001\n",
      "\tBatch 8800 of 50000 training acc 81.528 val acc 80.62\n",
      "\tBatch 8900 of 50000 training acc 77.75 val acc 76.3\n",
      "\tBatch 9000 of 50000 training acc 80.822 val acc 79.72\n",
      "\tBatch 9100 of 50000 training acc 79.182 val acc 77.86\n",
      "\tBatch 9200 of 50000 training acc 79.574 val acc 78.11\n",
      "\tBatch 9300 of 50000 training acc 81.888 val acc 80.97999999999999\n",
      "\tBatch 9400 of 50000 training acc 81.662 val acc 80.28999999999999\n",
      "\tBatch 9500 of 50000 training acc 74.606 val acc 73.18\n",
      "\tBatch 9600 of 50000 training acc 79.542 val acc 78.4\n",
      "\tBatch 9700 of 50000 training acc 80.476 val acc 79.16\n",
      "\tBatch 9800 of 50000 training acc 80.598 val acc 79.67\n",
      "\tBatch 9900 of 50000 training acc 82.30199999999999 val acc 81.38\n",
      "\tBatch 10000 of 50000 training acc 80.842 val acc 79.65\n",
      "\tBatch 10100 of 50000 training acc 73.256 val acc 71.74000000000001\n",
      "\tBatch 10200 of 50000 training acc 81.75200000000001 val acc 80.82000000000001\n",
      "\tBatch 10300 of 50000 training acc 81.272 val acc 80.36\n",
      "\tBatch 10400 of 50000 training acc 81.134 val acc 80.36\n",
      "\tBatch 10500 of 50000 training acc 81.234 val acc 79.92\n",
      "\tBatch 10600 of 50000 training acc 78.384 val acc 77.45\n",
      "\tBatch 10700 of 50000 training acc 81.39999999999999 val acc 80.31\n",
      "\tBatch 10800 of 50000 training acc 79.604 val acc 78.46\n",
      "\tBatch 10900 of 50000 training acc 80.522 val acc 79.34\n",
      "\tBatch 11000 of 50000 training acc 81.348 val acc 80.44\n",
      "\tBatch 11100 of 50000 training acc 78.542 val acc 77.51\n",
      "\tBatch 11200 of 50000 training acc 76.346 val acc 75.74\n",
      "\tBatch 11300 of 50000 training acc 82.07799999999999 val acc 80.97999999999999\n",
      "\tBatch 11400 of 50000 training acc 77.77 val acc 76.44\n",
      "\tBatch 11500 of 50000 training acc 77.792 val acc 76.83\n",
      "\tBatch 11600 of 50000 training acc 76.952 val acc 76.05\n",
      "\tBatch 11700 of 50000 training acc 77.556 val acc 76.53999999999999\n",
      "\tBatch 11800 of 50000 training acc 81.092 val acc 80.17\n",
      "\tBatch 11900 of 50000 training acc 73.38799999999999 val acc 72.39\n",
      "\tBatch 12000 of 50000 training acc 77.484 val acc 76.71\n",
      "\tBatch 12100 of 50000 training acc 72.672 val acc 71.28\n",
      "\tBatch 12200 of 50000 training acc 77.846 val acc 77.25\n",
      "\tBatch 12300 of 50000 training acc 74.75 val acc 73.68\n",
      "\tBatch 12400 of 50000 training acc 80.696 val acc 79.66\n",
      "\tBatch 12500 of 50000 training acc 80.226 val acc 79.14\n",
      "\tBatch 12600 of 50000 training acc 81.95 val acc 80.83\n",
      "\tBatch 12700 of 50000 training acc 80.312 val acc 79.28\n",
      "\tBatch 12800 of 50000 training acc 77.79599999999999 val acc 76.66\n",
      "\tBatch 12900 of 50000 training acc 81.042 val acc 80.15\n",
      "\tBatch 13000 of 50000 training acc 80.23599999999999 val acc 79.13\n",
      "\tBatch 13100 of 50000 training acc 80.77 val acc 79.80000000000001\n",
      "\tBatch 13200 of 50000 training acc 78.644 val acc 77.72\n",
      "\tBatch 13300 of 50000 training acc 80.658 val acc 79.59\n",
      "\tBatch 13400 of 50000 training acc 76.774 val acc 75.63\n",
      "\tBatch 13500 of 50000 training acc 80.732 val acc 79.71000000000001\n",
      "\tBatch 13600 of 50000 training acc 79.266 val acc 78.18\n",
      "\tBatch 13700 of 50000 training acc 79.64 val acc 78.91\n",
      "\tBatch 13800 of 50000 training acc 79.464 val acc 78.01\n",
      "\tBatch 13900 of 50000 training acc 81.408 val acc 80.22\n",
      "\tBatch 14000 of 50000 training acc 80.946 val acc 79.86999999999999\n",
      "\tBatch 14100 of 50000 training acc 80.268 val acc 78.89\n",
      "\tBatch 14200 of 50000 training acc 79.92399999999999 val acc 79.14999999999999\n",
      "\tBatch 14300 of 50000 training acc 77.518 val acc 77.05\n",
      "\tBatch 14400 of 50000 training acc 79.918 val acc 78.99000000000001\n",
      "\tBatch 14500 of 50000 training acc 79.796 val acc 79.36\n",
      "\tBatch 14600 of 50000 training acc 75.29599999999999 val acc 74.03999999999999\n",
      "\tBatch 14700 of 50000 training acc 81.806 val acc 81.11\n",
      "\tBatch 14800 of 50000 training acc 81.174 val acc 80.22\n",
      "\tBatch 14900 of 50000 training acc 81.57799999999999 val acc 80.2\n",
      "\tBatch 15000 of 50000 training acc 79.192 val acc 77.86\n",
      "\tBatch 15100 of 50000 training acc 78.544 val acc 77.12\n",
      "\tBatch 15200 of 50000 training acc 80.95599999999999 val acc 80.15\n",
      "\tBatch 15300 of 50000 training acc 79.65 val acc 78.27\n",
      "\tBatch 15400 of 50000 training acc 80.184 val acc 79.10000000000001\n",
      "\tBatch 15500 of 50000 training acc 79.77 val acc 78.79\n",
      "\tBatch 15600 of 50000 training acc 81.992 val acc 81.27\n",
      "\tBatch 15700 of 50000 training acc 82.796 val acc 81.96\n"
     ]
    }
   ],
   "source": [
    "lr = 0.2\n",
    "n_epochs = 10\n",
    "\n",
    "percept_fashion = Perceptron(n_class_fashion, lr, n_epochs)\n",
    "percept_fashion.train(X_train_fashion, y_train_fashion, X_val_fashion, y_val_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 82.796000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 81.960000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 80.840000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy, output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/perceptron_submission_fashion.csv', percept_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Perceptron on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of models.perceptron failed: Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\yunxi\\Desktop\\CS444Vision\\assignment1\\models\\perceptron.py\", line 10, in <module>\n",
      "    class Perceptron:\n",
      "  File \"C:\\Users\\yunxi\\Desktop\\CS444Vision\\assignment1\\models\\perceptron.py\", line 24, in Perceptron\n",
      "    def train(self, X_train: np.ndarray, y_train: np.ndarray, X_val=X_train , y_val=y_train):\n",
      "NameError: name 'X_train' is not defined\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 0 of 4874 training acc 48.317603610997125 val acc 49.16923076923077\n",
      "\tBatch 100 of 4874 training acc 72.28149363972098 val acc 72.18461538461538\n",
      "\tBatch 200 of 4874 training acc 83.72999589659418 val acc 81.78461538461539\n",
      "\tBatch 300 of 4874 training acc 48.11243331965531 val acc 48.55384615384615\n",
      "\tBatch 400 of 4874 training acc 63.52072219942553 val acc 63.44615384615384\n",
      "\tBatch 500 of 4874 training acc 87.85391875256462 val acc 87.56923076923077\n",
      "\tBatch 600 of 4874 training acc 72.11735740664751 val acc 69.96923076923078\n",
      "\tBatch 700 of 4874 training acc 75.89249076733688 val acc 76.36923076923077\n",
      "\tBatch 800 of 4874 training acc 50.84119819450144 val acc 51.44615384615384\n",
      "\tBatch 900 of 4874 training acc 88.83873615100534 val acc 87.44615384615385\n",
      "\tBatch 1000 of 4874 training acc 70.51702913418137 val acc 70.21538461538461\n",
      "\tBatch 1100 of 4874 training acc 78.47763643824375 val acc 75.6923076923077\n",
      "\tBatch 1200 of 4874 training acc 83.032416906032 val acc 82.33846153846154\n",
      "\tBatch 1300 of 4874 training acc 86.3561756257694 val acc 85.29230769230769\n",
      "\tBatch 1400 of 4874 training acc 88.40787853918752 val acc 86.95384615384616\n",
      "\tBatch 1500 of 4874 training acc 82.2732868280673 val acc 80.3076923076923\n",
      "\tBatch 1600 of 4874 training acc 78.72384078785392 val acc 78.03076923076922\n",
      "\tBatch 1700 of 4874 training acc 88.34632745178497 val acc 87.13846153846154\n",
      "\tBatch 1800 of 4874 training acc 90.29544521953221 val acc 90.15384615384615\n",
      "\tBatch 1900 of 4874 training acc 79.31883463274518 val acc 78.03076923076922\n",
      "\tBatch 2000 of 4874 training acc 81.61674189577349 val acc 81.2923076923077\n",
      "\tBatch 2100 of 4874 training acc 74.59991793188347 val acc 75.01538461538462\n",
      "\tBatch 2200 of 4874 training acc 67.25482150184654 val acc 65.60000000000001\n",
      "\tBatch 2300 of 4874 training acc 88.90028723840788 val acc 88.12307692307692\n",
      "\tBatch 2400 of 4874 training acc 75.78990562166598 val acc 73.41538461538461\n",
      "\tBatch 2500 of 4874 training acc 87.54616331555191 val acc 87.56923076923077\n",
      "\tBatch 2600 of 4874 training acc 89.02338941321297 val acc 87.50769230769231\n",
      "\tBatch 2700 of 4874 training acc 82.68362741075093 val acc 82.64615384615385\n",
      "\tBatch 2800 of 4874 training acc 89.92613869511695 val acc 89.23076923076924\n",
      "\tBatch 2900 of 4874 training acc 89.84407057858023 val acc 89.1076923076923\n",
      "\tBatch 3000 of 4874 training acc 89.78251949117768 val acc 88.73846153846155\n",
      "\tBatch 3100 of 4874 training acc 80.67295855560116 val acc 78.03076923076922\n",
      "\tBatch 3200 of 4874 training acc 89.37217890849405 val acc 87.81538461538462\n",
      "\tBatch 3300 of 4874 training acc 76.75420599097251 val acc 75.93846153846154\n",
      "\tBatch 3400 of 4874 training acc 89.24907673368895 val acc 88.98461538461538\n",
      "\tBatch 3500 of 4874 training acc 88.38736151005334 val acc 87.81538461538462\n",
      "\tBatch 3600 of 4874 training acc 90.27492819039803 val acc 89.90769230769232\n",
      "\tBatch 3700 of 4874 training acc 61.325400082068114 val acc 61.41538461538462\n",
      "\tBatch 3800 of 4874 training acc 78.9700451374641 val acc 77.29230769230769\n",
      "\tBatch 3900 of 4874 training acc 78.25194911776775 val acc 76.61538461538461\n",
      "\tBatch 4000 of 4874 training acc 88.79770209273697 val acc 89.1076923076923\n",
      "\tBatch 4100 of 4874 training acc 90.99302421009438 val acc 89.84615384615384\n",
      "\tBatch 4200 of 4874 training acc 91.79318834632745 val acc 90.58461538461539\n",
      "\tBatch 4300 of 4874 training acc 83.8120640131309 val acc 82.46153846153847\n",
      "\tBatch 4400 of 4874 training acc 82.51949117767748 val acc 81.41538461538461\n",
      "\tBatch 4500 of 4874 training acc 92.20352892901109 val acc 91.38461538461539\n",
      "\tBatch 4600 of 4874 training acc 92.59335248256052 val acc 92.0\n",
      "\tBatch 4700 of 4874 training acc 92.73697168649979 val acc 92.06153846153846\n",
      "\tBatch 4800 of 4874 training acc 92.57283545342634 val acc 91.6923076923077\n",
      "\tBatch 0 of 4874 training acc 90.66475174394748 val acc 90.4\n",
      "\tBatch 100 of 4874 training acc 89.94665572425113 val acc 88.24615384615385\n",
      "\tBatch 200 of 4874 training acc 79.97537956503898 val acc 76.73846153846154\n",
      "\tBatch 300 of 4874 training acc 66.47517439474764 val acc 67.26153846153846\n",
      "\tBatch 400 of 4874 training acc 88.8797702092737 val acc 87.6923076923077\n",
      "\tBatch 500 of 4874 training acc 81.55519080837095 val acc 79.32307692307691\n",
      "\tBatch 600 of 4874 training acc 90.48009848173984 val acc 90.33846153846153\n",
      "\tBatch 700 of 4874 training acc 91.46491588018056 val acc 91.07692307692308\n",
      "\tBatch 800 of 4874 training acc 84.26343865408289 val acc 84.18461538461538\n",
      "\tBatch 900 of 4874 training acc 88.92080426754207 val acc 87.56923076923077\n",
      "\tBatch 1000 of 4874 training acc 91.97784160853509 val acc 91.50769230769231\n",
      "\tBatch 1100 of 4874 training acc 74.02544111612639 val acc 71.93846153846154\n",
      "\tBatch 1200 of 4874 training acc 90.97250718096019 val acc 89.72307692307693\n",
      "\tBatch 1300 of 4874 training acc 92.5112843660238 val acc 91.2\n",
      "\tBatch 1400 of 4874 training acc 93.12679524004925 val acc 92.49230769230769\n",
      "\tBatch 1500 of 4874 training acc 88.16167418957734 val acc 86.76923076923076\n",
      "\tBatch 1600 of 4874 training acc 86.47927780057447 val acc 85.47692307692307\n",
      "\tBatch 1700 of 4874 training acc 89.49528108329913 val acc 88.55384615384615\n",
      "\tBatch 1800 of 4874 training acc 90.29544521953221 val acc 89.29230769230769\n",
      "\tBatch 1900 of 4874 training acc 74.96922445629873 val acc 72.92307692307692\n",
      "\tBatch 2000 of 4874 training acc 92.10094378334017 val acc 91.81538461538462\n",
      "\tBatch 2100 of 4874 training acc 60.258514567090685 val acc 61.661538461538456\n",
      "\tBatch 2200 of 4874 training acc 88.14115716044317 val acc 86.58461538461538\n",
      "\tBatch 2300 of 4874 training acc 90.62371768567911 val acc 89.35384615384615\n",
      "\tBatch 2400 of 4874 training acc 92.08042675420599 val acc 91.50769230769231\n",
      "\tBatch 2500 of 4874 training acc 69.98358637669266 val acc 71.32307692307693\n",
      "\tBatch 2600 of 4874 training acc 68.42429216249487 val acc 65.78461538461539\n",
      "\tBatch 2700 of 4874 training acc 82.95034878949528 val acc 83.13846153846154\n",
      "\tBatch 2800 of 4874 training acc 89.98768978251948 val acc 87.87692307692308\n",
      "\tBatch 2900 of 4874 training acc 91.44439885104637 val acc 90.52307692307693\n",
      "\tBatch 3000 of 4874 training acc 90.13130898645876 val acc 89.72307692307693\n",
      "\tBatch 3100 of 4874 training acc 92.36766516208453 val acc 91.75384615384615\n",
      "\tBatch 3200 of 4874 training acc 92.57283545342634 val acc 91.13846153846154\n",
      "\tBatch 3300 of 4874 training acc 87.19737382027083 val acc 87.07692307692308\n",
      "\tBatch 3400 of 4874 training acc 86.17152236356176 val acc 85.47692307692307\n",
      "\tBatch 3500 of 4874 training acc 87.62823143208863 val acc 86.27692307692307\n",
      "\tBatch 3600 of 4874 training acc 92.79852277390233 val acc 92.55384615384615\n",
      "\tBatch 3700 of 4874 training acc 66.70086171522364 val acc 67.32307692307693\n",
      "\tBatch 3800 of 4874 training acc 90.17234304472711 val acc 89.29230769230769\n",
      "\tBatch 3900 of 4874 training acc 78.49815346737793 val acc 76.98461538461538\n",
      "\tBatch 4000 of 4874 training acc 88.8797702092737 val acc 88.18461538461538\n",
      "\tBatch 4100 of 4874 training acc 73.63561756257694 val acc 73.53846153846155\n",
      "\tBatch 4200 of 4874 training acc 89.94665572425113 val acc 88.86153846153846\n",
      "\tBatch 4300 of 4874 training acc 82.76569552728765 val acc 81.84615384615384\n",
      "\tBatch 4400 of 4874 training acc 91.38284776364382 val acc 90.70769230769231\n",
      "\tBatch 4500 of 4874 training acc 90.99302421009438 val acc 90.27692307692308\n",
      "\tBatch 4600 of 4874 training acc 92.90110791957325 val acc 92.73846153846154\n",
      "\tBatch 4700 of 4874 training acc 93.20886335658597 val acc 92.86153846153846\n",
      "\tBatch 4800 of 4874 training acc 93.22938038572015 val acc 92.12307692307692\n",
      "\tBatch 0 of 4874 training acc 92.44973327862127 val acc 92.43076923076923\n",
      "\tBatch 100 of 4874 training acc 89.94665572425113 val acc 88.86153846153846\n",
      "\tBatch 200 of 4874 training acc 59.88920804267542 val acc 57.969230769230776\n",
      "\tBatch 300 of 4874 training acc 93.08576118178088 val acc 92.36923076923077\n",
      "\tBatch 400 of 4874 training acc 93.80385720147723 val acc 93.47692307692309\n",
      "\tBatch 500 of 4874 training acc 76.71317193270414 val acc 73.66153846153846\n",
      "\tBatch 600 of 4874 training acc 91.50594993844892 val acc 91.2\n",
      "\tBatch 700 of 4874 training acc 94.43988510463684 val acc 94.15384615384616\n",
      "\tBatch 800 of 4874 training acc 68.46532622076323 val acc 68.43076923076923\n",
      "\tBatch 900 of 4874 training acc 91.629052113254 val acc 90.76923076923077\n",
      "\tBatch 1000 of 4874 training acc 70.45547804677884 val acc 71.56923076923077\n",
      "\tBatch 1100 of 4874 training acc 89.84407057858023 val acc 88.3076923076923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 1200 of 4874 training acc 92.44973327862127 val acc 92.06153846153846\n",
      "\tBatch 1300 of 4874 training acc 90.33647927780058 val acc 88.8\n",
      "\tBatch 1400 of 4874 training acc 93.80385720147723 val acc 93.04615384615384\n",
      "\tBatch 1500 of 4874 training acc 86.72548215018465 val acc 85.16923076923077\n",
      "\tBatch 1600 of 4874 training acc 92.75748871563397 val acc 91.87692307692308\n",
      "\tBatch 1700 of 4874 training acc 74.47681575707837 val acc 74.33846153846154\n",
      "\tBatch 1800 of 4874 training acc 94.54247025030776 val acc 94.15384615384616\n",
      "\tBatch 1900 of 4874 training acc 93.08576118178088 val acc 92.18461538461538\n",
      "\tBatch 2000 of 4874 training acc 70.5990972507181 val acc 70.33846153846154\n",
      "\tBatch 2100 of 4874 training acc 83.1555190808371 val acc 83.13846153846154\n",
      "\tBatch 2200 of 4874 training acc 83.36068937217891 val acc 80.92307692307692\n",
      "\tBatch 2300 of 4874 training acc 90.52113254000821 val acc 89.53846153846153\n",
      "\tBatch 2400 of 4874 training acc 92.1830118998769 val acc 91.63076923076923\n",
      "\tBatch 2500 of 4874 training acc 83.75051292572836 val acc 83.50769230769231\n",
      "\tBatch 2600 of 4874 training acc 79.33935166187936 val acc 76.67692307692307\n",
      "\tBatch 2700 of 4874 training acc 93.53713582273286 val acc 93.1076923076923\n",
      "\tBatch 2800 of 4874 training acc 92.5112843660238 val acc 91.87692307692308\n",
      "\tBatch 2900 of 4874 training acc 94.25523184242923 val acc 94.15384615384616\n",
      "\tBatch 3000 of 4874 training acc 84.77636438243742 val acc 85.41538461538461\n",
      "\tBatch 3100 of 4874 training acc 83.54534263438654 val acc 81.35384615384615\n",
      "\tBatch 3200 of 4874 training acc 92.8395568321707 val acc 91.93846153846154\n",
      "\tBatch 3300 of 4874 training acc 93.6192039392696 val acc 92.67692307692307\n",
      "\tBatch 3400 of 4874 training acc 93.70127205580631 val acc 92.55384615384615\n",
      "\tBatch 3500 of 4874 training acc 90.80837094788674 val acc 89.78461538461538\n",
      "\tBatch 3600 of 4874 training acc 76.01559294214198 val acc 73.6\n",
      "\tBatch 3700 of 4874 training acc 91.97784160853509 val acc 91.01538461538462\n",
      "\tBatch 3800 of 4874 training acc 88.12064013130899 val acc 86.95384615384616\n",
      "\tBatch 3900 of 4874 training acc 93.59868691013541 val acc 93.16923076923077\n",
      "\tBatch 4000 of 4874 training acc 95.21953221173574 val acc 94.83076923076923\n",
      "\tBatch 4100 of 4874 training acc 92.32663110381617 val acc 91.32307692307691\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "\n",
    "percept_MR = Perceptron(n_class_MR, lr, n_epochs)\n",
    "percept_MR.train(X_train_MR, y_train_MR, X_val_MR, y_val_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = percept_MR.predict(X_train_MR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_percept, y_train_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Perceptron on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 95.630769\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_MR.predict(X_val_MR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_percept, y_val_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Perceptron on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 95.200000\n"
     ]
    }
   ],
   "source": [
    "pred_percept = percept_MR.predict(X_test_MR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_percept, y_test_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will implement a \"soft margin\" SVM. In this formulation you will maximize the margin between positive and negative training examples and penalize margin violations using a hinge loss.\n",
    "\n",
    "We will optimize the SVM loss using SGD. This means you must compute the loss function with respect to model weights. You will use this gradient to update the model weights.\n",
    "\n",
    "SVM optimized with SGD has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Epochs** - similar to as defined above in Perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case it is a coefficient on the term which maximizes the margin. You could try different values. The default value is set to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the SVM using SGD in the **models/svm.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the SVM classifier class \n",
    "- The train function of the SVM class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supportive Vector Machine Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Support Vector Machine (SVM) model.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, n_class: int, lr: float, epochs: int, reg_const: float):\n",
    "        \"\"\"Initialize a new classifier.\n",
    "\n",
    "        Parameters:\n",
    "            n_class: the number of classes\n",
    "            lr: the learning rate\n",
    "            epochs: the number of epochs to train for\n",
    "            reg_const: the regularization constant\n",
    "        \"\"\"\n",
    "        self.w = None  # TODO: change this\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.reg_const = reg_const\n",
    "        self.n_class = n_class\n",
    "\n",
    "    def calc_gradient(self, X_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate gradient of the svm hinge loss.\n",
    "\n",
    "        Inputs have dimension D, there are C classes, and we operate on\n",
    "        mini-batches of N examples.\n",
    "\n",
    "        Parameters:\n",
    "            X_train: a numpy array of shape (N, D) containing a mini-batch\n",
    "                of data\n",
    "            y_train: a numpy array of shape (N,) containing training labels;\n",
    "                y[i] = c means that X[i] has label c, where 0 <= c < C\n",
    "\n",
    "        Returns:\n",
    "            the gradient with respect to weights w; an array of the same shape\n",
    "                as w\n",
    "        \"\"\"\n",
    "        # TODO: implement me we don't do reg_term here\n",
    "        grad_w = np.array([[0 for j in range(X_train.shape[1])] for i in range(self.n_class)]).astype(\"float\")\n",
    "        N,D = X_train.shape\n",
    "        \n",
    "        for i in range(N):\n",
    "            tmp_grad = np.array([[0 for j in range(X_train.shape[1])] for i in range(self.n_class)]).astype(\"float\")\n",
    "            sum_xi = np.array([0 for i in range(D)]).astype(\"float\")\n",
    "            for c in range(len(tmp_grad)):\n",
    "                if c != y_train[i]: # \n",
    "                    if  np.dot(self.w[y_train[i]],X_train[i]) - np.dot(self.w[c],X_train[i]) < 1:\n",
    "                        tmp_grad[c] = X_train[i]\n",
    "                        tmp_grad[y_train[i]] -= X_train[i]\n",
    "            grad_w += tmp_grad\n",
    "        return grad_w\n",
    "        \n",
    "        \n",
    "            \n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray):\n",
    "        \"\"\"Train the classifier.\n",
    "\n",
    "        Hint: operate on mini-batches of data for SGD.\n",
    "\n",
    "        Parameters:\n",
    "            X_train: a numpy array of shape (N, D) containing training data;\n",
    "                N examples with D dimensions\n",
    "            y_train: a numpy array of shape (N,) containing training labels\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "        BATCH_SIZE = 128\n",
    "        \n",
    "        # start with random weights\n",
    "        random.seed(666)\n",
    "        b_up = np.min(X_train)\n",
    "        b_low = np.max(X_train)\n",
    "        self.w = np.array([[random.uniform(b_low,b_up) for j in range(X_train.shape[1])] for i in range(self.n_class)])\n",
    "        \n",
    "        N,D = X_train.shape\n",
    "        it = N//BATCH_SIZE\n",
    "        \n",
    "        pred_svm_t = self.predict(X_train)\n",
    "        t_acc = self.get_acc(pred_svm_t, y_train)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"epoch\",epoch)\n",
    "            for i in range(N//BATCH_SIZE): # feed in training data batch-wise\n",
    "                X_train_batch = X_train[BATCH_SIZE*i:BATCH_SIZE*(i+1)]\n",
    "                y_train_batch = y_train[BATCH_SIZE*i:BATCH_SIZE*(i+1)]\n",
    "        \n",
    "                grad_w = self.calc_gradient(X_train_batch, y_train_batch)\n",
    "                old_w = copy.deepcopy(self.w)\n",
    "                for c in range(len(self.w)):\n",
    "                    # TODO: update w\n",
    "                    self.w[c] = (1-self.lr*self.reg_const/it)*old_w[c] - self.lr*grad_w[c]\n",
    "                \n",
    "                ret = self.predict(X_train)\n",
    "                t_cur_acc = self.get_acc(ret, y_train)\n",
    "                pred_svm_v = self.predict(X_val)\n",
    "                cur_v_acc = self.get_acc(pred_svm_v, y_val)\n",
    "                if i%1 == 0:\n",
    "                    print(\"\\tBatch\",i,\"of\",it,\"training acc\",t_cur_acc,\"val acc\",cur_v_acc)\n",
    "                    # early stop\n",
    "                if cur_v_acc >= 83: # found 83\n",
    "                        return\n",
    "                    \n",
    "    def get_acc(self, pred, y_test):\n",
    "        return np.sum(y_test == pred) / len(y_test) * 100\n",
    "\n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use the trained weights to predict labels for test data points.\n",
    "\n",
    "        Parameters:\n",
    "            X_test: a numpy array of shape (N, D) containing testing data;\n",
    "                N examples with D dimensions\n",
    "\n",
    "        Returns:\n",
    "            predicted labels for the data in X_test; a 1-dimensional array of\n",
    "                length N, where each element is an integer giving the predicted\n",
    "                class.\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "        ret = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            scores = np.dot(self.w, X_test[i])\n",
    "#             print(scores)\n",
    "            max_score = float(\"-inf\")\n",
    "            max_class = -1\n",
    "            for j in range(len(scores)):\n",
    "                if scores[j] > max_score:\n",
    "                    max_score = scores[j]\n",
    "                    max_class = j\n",
    "            ret.append(max_class)\n",
    "        return np.array(ret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\tBatch 0 of 390 training acc 43.632 val acc 44.019999999999996\n",
      "\tBatch 1 of 390 training acc 52.028 val acc 52.290000000000006\n",
      "\tBatch 2 of 390 training acc 54.647999999999996 val acc 55.15\n",
      "\tBatch 3 of 390 training acc 62.726000000000006 val acc 62.55\n",
      "\tBatch 4 of 390 training acc 64.66 val acc 64.03999999999999\n",
      "\tBatch 5 of 390 training acc 67.628 val acc 67.56\n",
      "\tBatch 6 of 390 training acc 70.368 val acc 70.0\n",
      "\tBatch 7 of 390 training acc 69.45400000000001 val acc 69.0\n",
      "\tBatch 8 of 390 training acc 72.906 val acc 72.64\n",
      "\tBatch 9 of 390 training acc 72.372 val acc 72.26\n",
      "\tBatch 10 of 390 training acc 71.454 val acc 71.00999999999999\n",
      "\tBatch 11 of 390 training acc 70.658 val acc 70.48\n",
      "\tBatch 12 of 390 training acc 72.174 val acc 71.63000000000001\n",
      "\tBatch 13 of 390 training acc 73.10799999999999 val acc 73.21\n",
      "\tBatch 14 of 390 training acc 74.606 val acc 74.42999999999999\n",
      "\tBatch 15 of 390 training acc 74.442 val acc 74.44\n",
      "\tBatch 16 of 390 training acc 73.188 val acc 72.87\n",
      "\tBatch 17 of 390 training acc 72.588 val acc 72.16\n",
      "\tBatch 18 of 390 training acc 76.39200000000001 val acc 76.21\n",
      "\tBatch 19 of 390 training acc 70.52199999999999 val acc 70.73\n",
      "\tBatch 20 of 390 training acc 67.99199999999999 val acc 67.42\n",
      "\tBatch 21 of 390 training acc 73.688 val acc 73.11\n",
      "\tBatch 22 of 390 training acc 68.42200000000001 val acc 68.2\n",
      "\tBatch 23 of 390 training acc 75.53 val acc 75.07000000000001\n",
      "\tBatch 24 of 390 training acc 77.994 val acc 77.14999999999999\n",
      "\tBatch 25 of 390 training acc 76.908 val acc 76.44999999999999\n",
      "\tBatch 26 of 390 training acc 75.198 val acc 74.6\n",
      "\tBatch 27 of 390 training acc 77.594 val acc 76.85\n",
      "\tBatch 28 of 390 training acc 76.25800000000001 val acc 76.09\n",
      "\tBatch 29 of 390 training acc 74.98599999999999 val acc 74.44\n",
      "\tBatch 30 of 390 training acc 72.67 val acc 71.54\n",
      "\tBatch 31 of 390 training acc 70.26 val acc 69.69\n",
      "\tBatch 32 of 390 training acc 74.332 val acc 73.71\n",
      "\tBatch 33 of 390 training acc 75.924 val acc 75.33\n",
      "\tBatch 34 of 390 training acc 77.562 val acc 76.87\n",
      "\tBatch 35 of 390 training acc 78.276 val acc 77.86\n",
      "\tBatch 36 of 390 training acc 77.74 val acc 77.42999999999999\n",
      "\tBatch 37 of 390 training acc 79.352 val acc 78.52\n",
      "\tBatch 38 of 390 training acc 78.034 val acc 77.57\n",
      "\tBatch 39 of 390 training acc 76.922 val acc 76.2\n",
      "\tBatch 40 of 390 training acc 69.53399999999999 val acc 68.77\n",
      "\tBatch 41 of 390 training acc 66.59 val acc 66.21000000000001\n",
      "\tBatch 42 of 390 training acc 73.992 val acc 73.42999999999999\n",
      "\tBatch 43 of 390 training acc 76.464 val acc 76.05\n",
      "\tBatch 44 of 390 training acc 77.598 val acc 76.97\n",
      "\tBatch 45 of 390 training acc 70.32000000000001 val acc 70.16\n",
      "\tBatch 46 of 390 training acc 61.077999999999996 val acc 60.81999999999999\n",
      "\tBatch 47 of 390 training acc 75.53800000000001 val acc 74.86\n",
      "\tBatch 48 of 390 training acc 79.074 val acc 78.77\n",
      "\tBatch 49 of 390 training acc 78.154 val acc 77.86\n",
      "\tBatch 50 of 390 training acc 69.606 val acc 68.72\n",
      "\tBatch 51 of 390 training acc 74.006 val acc 73.88\n",
      "\tBatch 52 of 390 training acc 72.77 val acc 72.39999999999999\n",
      "\tBatch 53 of 390 training acc 70.634 val acc 70.00999999999999\n",
      "\tBatch 54 of 390 training acc 70.75399999999999 val acc 70.39999999999999\n",
      "\tBatch 55 of 390 training acc 77.716 val acc 76.95\n",
      "\tBatch 56 of 390 training acc 69.024 val acc 68.11\n",
      "\tBatch 57 of 390 training acc 74.454 val acc 73.36\n",
      "\tBatch 58 of 390 training acc 65.362 val acc 64.5\n",
      "\tBatch 59 of 390 training acc 75.088 val acc 74.08\n",
      "\tBatch 60 of 390 training acc 77.396 val acc 76.09\n",
      "\tBatch 61 of 390 training acc 76.902 val acc 76.14\n",
      "\tBatch 62 of 390 training acc 78.21000000000001 val acc 76.92999999999999\n",
      "\tBatch 63 of 390 training acc 80.03 val acc 79.4\n",
      "\tBatch 64 of 390 training acc 77.842 val acc 76.81\n",
      "\tBatch 65 of 390 training acc 76.786 val acc 76.39\n",
      "\tBatch 66 of 390 training acc 80.482 val acc 79.32000000000001\n",
      "\tBatch 67 of 390 training acc 81.572 val acc 80.96\n",
      "\tBatch 68 of 390 training acc 81.382 val acc 80.46\n",
      "\tBatch 69 of 390 training acc 76.904 val acc 75.46000000000001\n",
      "\tBatch 70 of 390 training acc 78.252 val acc 77.7\n",
      "\tBatch 71 of 390 training acc 81.092 val acc 80.17\n",
      "\tBatch 72 of 390 training acc 75.778 val acc 74.97\n",
      "\tBatch 73 of 390 training acc 80.15 val acc 79.36999999999999\n",
      "\tBatch 74 of 390 training acc 73.642 val acc 73.0\n",
      "\tBatch 75 of 390 training acc 73.33 val acc 72.6\n",
      "\tBatch 76 of 390 training acc 71.41999999999999 val acc 71.02000000000001\n",
      "\tBatch 77 of 390 training acc 66.904 val acc 66.31\n",
      "\tBatch 78 of 390 training acc 77.834 val acc 76.99000000000001\n",
      "\tBatch 79 of 390 training acc 75.036 val acc 74.42\n",
      "\tBatch 80 of 390 training acc 76.922 val acc 76.06\n",
      "\tBatch 81 of 390 training acc 77.024 val acc 76.23\n",
      "\tBatch 82 of 390 training acc 79.298 val acc 78.53\n",
      "\tBatch 83 of 390 training acc 80.172 val acc 79.52\n",
      "\tBatch 84 of 390 training acc 79.644 val acc 79.22\n",
      "\tBatch 85 of 390 training acc 78.572 val acc 78.0\n",
      "\tBatch 86 of 390 training acc 77.73 val acc 77.5\n",
      "\tBatch 87 of 390 training acc 75.742 val acc 74.95\n",
      "\tBatch 88 of 390 training acc 75.966 val acc 75.39\n",
      "\tBatch 89 of 390 training acc 70.056 val acc 69.28999999999999\n",
      "\tBatch 90 of 390 training acc 73.006 val acc 72.71\n",
      "\tBatch 91 of 390 training acc 75.92 val acc 75.16000000000001\n",
      "\tBatch 92 of 390 training acc 71.088 val acc 70.89999999999999\n",
      "\tBatch 93 of 390 training acc 57.414 val acc 57.269999999999996\n",
      "\tBatch 94 of 390 training acc 70.556 val acc 69.96\n",
      "\tBatch 95 of 390 training acc 74.188 val acc 73.76\n",
      "\tBatch 96 of 390 training acc 72.98400000000001 val acc 72.0\n",
      "\tBatch 97 of 390 training acc 76.592 val acc 76.14999999999999\n",
      "\tBatch 98 of 390 training acc 81.094 val acc 80.44\n",
      "\tBatch 99 of 390 training acc 74.19200000000001 val acc 73.26\n",
      "\tBatch 100 of 390 training acc 79.762 val acc 79.44\n",
      "\tBatch 101 of 390 training acc 80.58999999999999 val acc 80.07\n",
      "\tBatch 102 of 390 training acc 79.496 val acc 79.19\n",
      "\tBatch 103 of 390 training acc 81.248 val acc 80.73\n",
      "\tBatch 104 of 390 training acc 79.46600000000001 val acc 79.3\n",
      "\tBatch 105 of 390 training acc 80.132 val acc 79.54\n",
      "\tBatch 106 of 390 training acc 80.196 val acc 79.73\n",
      "\tBatch 107 of 390 training acc 78.428 val acc 78.12\n",
      "\tBatch 108 of 390 training acc 77.69 val acc 77.34\n",
      "\tBatch 109 of 390 training acc 80.338 val acc 79.80000000000001\n",
      "\tBatch 110 of 390 training acc 80.014 val acc 79.31\n",
      "\tBatch 111 of 390 training acc 80.972 val acc 79.97999999999999\n",
      "\tBatch 112 of 390 training acc 76.936 val acc 76.44\n",
      "\tBatch 113 of 390 training acc 80.80199999999999 val acc 80.07\n",
      "\tBatch 114 of 390 training acc 77.27199999999999 val acc 76.73\n",
      "\tBatch 115 of 390 training acc 75.016 val acc 74.36\n",
      "\tBatch 116 of 390 training acc 79.81200000000001 val acc 79.33\n",
      "\tBatch 117 of 390 training acc 75.64800000000001 val acc 75.22\n",
      "\tBatch 118 of 390 training acc 77.586 val acc 76.79\n",
      "\tBatch 119 of 390 training acc 78.756 val acc 78.05\n",
      "\tBatch 120 of 390 training acc 72.744 val acc 71.82\n",
      "\tBatch 121 of 390 training acc 71.642 val acc 71.93\n",
      "\tBatch 122 of 390 training acc 75.17 val acc 74.66000000000001\n",
      "\tBatch 123 of 390 training acc 77.876 val acc 77.97\n",
      "\tBatch 124 of 390 training acc 74.286 val acc 74.39\n",
      "\tBatch 125 of 390 training acc 78.314 val acc 78.46\n",
      "\tBatch 126 of 390 training acc 79.322 val acc 79.12\n",
      "\tBatch 127 of 390 training acc 71.664 val acc 70.96000000000001\n",
      "\tBatch 128 of 390 training acc 75.564 val acc 75.03\n",
      "\tBatch 129 of 390 training acc 74.29400000000001 val acc 74.21\n",
      "\tBatch 130 of 390 training acc 66.39399999999999 val acc 65.95\n",
      "\tBatch 131 of 390 training acc 63.806 val acc 63.349999999999994\n",
      "\tBatch 132 of 390 training acc 76.88199999999999 val acc 75.84\n",
      "\tBatch 133 of 390 training acc 80.354 val acc 79.7\n",
      "\tBatch 134 of 390 training acc 79.804 val acc 79.27\n",
      "\tBatch 135 of 390 training acc 79.784 val acc 79.3\n",
      "\tBatch 136 of 390 training acc 74.22 val acc 73.78\n",
      "\tBatch 137 of 390 training acc 77.366 val acc 77.09\n",
      "\tBatch 138 of 390 training acc 79.026 val acc 78.73\n",
      "\tBatch 139 of 390 training acc 80.256 val acc 79.95\n",
      "\tBatch 140 of 390 training acc 78.314 val acc 78.02\n",
      "\tBatch 141 of 390 training acc 80.324 val acc 80.02\n",
      "\tBatch 142 of 390 training acc 76.616 val acc 76.33\n",
      "\tBatch 143 of 390 training acc 79.97 val acc 79.51\n",
      "\tBatch 144 of 390 training acc 79.526 val acc 78.92\n",
      "\tBatch 145 of 390 training acc 78.572 val acc 78.11\n",
      "\tBatch 146 of 390 training acc 77.952 val acc 77.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 147 of 390 training acc 75.31400000000001 val acc 74.64\n",
      "\tBatch 148 of 390 training acc 70.842 val acc 70.19999999999999\n",
      "\tBatch 149 of 390 training acc 73.874 val acc 73.19\n",
      "\tBatch 150 of 390 training acc 79.72 val acc 79.35\n",
      "\tBatch 151 of 390 training acc 80.268 val acc 79.56\n",
      "\tBatch 152 of 390 training acc 76.974 val acc 76.38000000000001\n",
      "\tBatch 153 of 390 training acc 81.922 val acc 81.35\n",
      "\tBatch 154 of 390 training acc 77.61 val acc 77.32\n",
      "\tBatch 155 of 390 training acc 78.08 val acc 77.38000000000001\n",
      "\tBatch 156 of 390 training acc 79.188 val acc 78.44\n",
      "\tBatch 157 of 390 training acc 76.744 val acc 76.73\n",
      "\tBatch 158 of 390 training acc 78.474 val acc 77.88000000000001\n",
      "\tBatch 159 of 390 training acc 80.292 val acc 79.65\n",
      "\tBatch 160 of 390 training acc 75.062 val acc 73.95\n",
      "\tBatch 161 of 390 training acc 72.386 val acc 71.82\n",
      "\tBatch 162 of 390 training acc 67.95400000000001 val acc 67.82000000000001\n",
      "\tBatch 163 of 390 training acc 73.556 val acc 72.77\n",
      "\tBatch 164 of 390 training acc 77.212 val acc 76.55\n",
      "\tBatch 165 of 390 training acc 77.89 val acc 77.91\n",
      "\tBatch 166 of 390 training acc 73.698 val acc 73.05\n",
      "\tBatch 167 of 390 training acc 66.67999999999999 val acc 65.97\n",
      "\tBatch 168 of 390 training acc 81.6 val acc 80.85\n",
      "\tBatch 169 of 390 training acc 79.074 val acc 78.56\n",
      "\tBatch 170 of 390 training acc 79.288 val acc 78.13\n",
      "\tBatch 171 of 390 training acc 81.286 val acc 80.75\n",
      "\tBatch 172 of 390 training acc 81.718 val acc 81.54\n",
      "\tBatch 173 of 390 training acc 77.764 val acc 76.69\n",
      "\tBatch 174 of 390 training acc 79.61200000000001 val acc 79.0\n",
      "\tBatch 175 of 390 training acc 80.36 val acc 79.77\n",
      "\tBatch 176 of 390 training acc 79.782 val acc 79.36999999999999\n",
      "\tBatch 177 of 390 training acc 77.08 val acc 76.31\n",
      "\tBatch 178 of 390 training acc 74.52600000000001 val acc 73.54\n",
      "\tBatch 179 of 390 training acc 71.75200000000001 val acc 70.54\n",
      "\tBatch 180 of 390 training acc 80.392 val acc 79.66\n",
      "\tBatch 181 of 390 training acc 81.042 val acc 80.69\n",
      "\tBatch 182 of 390 training acc 80.738 val acc 79.9\n",
      "\tBatch 183 of 390 training acc 81.138 val acc 80.17\n",
      "\tBatch 184 of 390 training acc 78.374 val acc 77.44\n",
      "\tBatch 185 of 390 training acc 78.88199999999999 val acc 78.01\n",
      "\tBatch 186 of 390 training acc 81.614 val acc 80.55\n",
      "\tBatch 187 of 390 training acc 75.972 val acc 75.33\n",
      "\tBatch 188 of 390 training acc 75.21799999999999 val acc 74.61\n",
      "\tBatch 189 of 390 training acc 77.37 val acc 76.77000000000001\n",
      "\tBatch 190 of 390 training acc 78.568 val acc 77.71000000000001\n",
      "\tBatch 191 of 390 training acc 79.956 val acc 79.41\n",
      "\tBatch 192 of 390 training acc 81.07 val acc 80.11\n",
      "\tBatch 193 of 390 training acc 82.988 val acc 82.31\n",
      "\tBatch 194 of 390 training acc 82.146 val acc 81.44\n",
      "\tBatch 195 of 390 training acc 82.608 val acc 81.89\n",
      "\tBatch 196 of 390 training acc 83.05799999999999 val acc 82.08\n",
      "\tBatch 197 of 390 training acc 81.774 val acc 81.39\n",
      "\tBatch 198 of 390 training acc 82.32199999999999 val acc 81.56\n",
      "\tBatch 199 of 390 training acc 77.676 val acc 76.73\n",
      "\tBatch 200 of 390 training acc 79.202 val acc 78.39\n",
      "\tBatch 201 of 390 training acc 79.12400000000001 val acc 78.23\n",
      "\tBatch 202 of 390 training acc 77.376 val acc 76.37\n",
      "\tBatch 203 of 390 training acc 77.446 val acc 76.73\n",
      "\tBatch 204 of 390 training acc 76.864 val acc 76.05\n",
      "\tBatch 205 of 390 training acc 78.38000000000001 val acc 77.97\n",
      "\tBatch 206 of 390 training acc 75.20400000000001 val acc 74.38\n",
      "\tBatch 207 of 390 training acc 78.79599999999999 val acc 78.14999999999999\n",
      "\tBatch 208 of 390 training acc 78.872 val acc 78.25\n",
      "\tBatch 209 of 390 training acc 80.62 val acc 80.07\n",
      "\tBatch 210 of 390 training acc 81.006 val acc 80.25999999999999\n",
      "\tBatch 211 of 390 training acc 79.84400000000001 val acc 79.16\n",
      "\tBatch 212 of 390 training acc 73.558 val acc 72.67\n",
      "\tBatch 213 of 390 training acc 73.058 val acc 73.05\n",
      "\tBatch 214 of 390 training acc 61.12 val acc 60.029999999999994\n",
      "\tBatch 215 of 390 training acc 72.166 val acc 72.37\n",
      "\tBatch 216 of 390 training acc 79.42399999999999 val acc 78.97\n",
      "\tBatch 217 of 390 training acc 81.186 val acc 80.67\n",
      "\tBatch 218 of 390 training acc 79.586 val acc 78.79\n",
      "\tBatch 219 of 390 training acc 79.752 val acc 79.12\n",
      "\tBatch 220 of 390 training acc 77.352 val acc 76.13\n",
      "\tBatch 221 of 390 training acc 78.998 val acc 78.52\n",
      "\tBatch 222 of 390 training acc 80.568 val acc 79.5\n",
      "\tBatch 223 of 390 training acc 81.04599999999999 val acc 80.41\n",
      "\tBatch 224 of 390 training acc 77.054 val acc 75.94\n",
      "\tBatch 225 of 390 training acc 79.23 val acc 78.53\n",
      "\tBatch 226 of 390 training acc 79.096 val acc 78.21000000000001\n",
      "\tBatch 227 of 390 training acc 78.66199999999999 val acc 77.85\n",
      "\tBatch 228 of 390 training acc 76.982 val acc 76.88000000000001\n",
      "\tBatch 229 of 390 training acc 80.566 val acc 80.05\n",
      "\tBatch 230 of 390 training acc 72.38 val acc 71.88\n",
      "\tBatch 231 of 390 training acc 74.98599999999999 val acc 74.03999999999999\n",
      "\tBatch 232 of 390 training acc 79.218 val acc 78.69\n",
      "\tBatch 233 of 390 training acc 79.166 val acc 78.7\n",
      "\tBatch 234 of 390 training acc 81.794 val acc 81.17\n",
      "\tBatch 235 of 390 training acc 78.46600000000001 val acc 77.59\n",
      "\tBatch 236 of 390 training acc 80.258 val acc 79.51\n",
      "\tBatch 237 of 390 training acc 78.66 val acc 77.77\n",
      "\tBatch 238 of 390 training acc 82.018 val acc 81.41000000000001\n",
      "\tBatch 239 of 390 training acc 82.548 val acc 81.84\n",
      "\tBatch 240 of 390 training acc 80.512 val acc 80.03\n",
      "\tBatch 241 of 390 training acc 67.252 val acc 65.89\n",
      "\tBatch 242 of 390 training acc 75.854 val acc 75.49\n",
      "\tBatch 243 of 390 training acc 71.11800000000001 val acc 69.95\n",
      "\tBatch 244 of 390 training acc 77.488 val acc 77.41\n",
      "\tBatch 245 of 390 training acc 80.272 val acc 79.75999999999999\n",
      "\tBatch 246 of 390 training acc 77.18 val acc 76.63\n",
      "\tBatch 247 of 390 training acc 73.462 val acc 72.96000000000001\n",
      "\tBatch 248 of 390 training acc 74.7 val acc 74.41\n",
      "\tBatch 249 of 390 training acc 79.642 val acc 79.32000000000001\n",
      "\tBatch 250 of 390 training acc 76.72200000000001 val acc 76.34\n",
      "\tBatch 251 of 390 training acc 81.58800000000001 val acc 81.21000000000001\n",
      "\tBatch 252 of 390 training acc 81.208 val acc 80.82000000000001\n",
      "\tBatch 253 of 390 training acc 82.452 val acc 81.55\n",
      "\tBatch 254 of 390 training acc 83.146 val acc 82.55\n",
      "\tBatch 255 of 390 training acc 81.46600000000001 val acc 80.52\n",
      "\tBatch 256 of 390 training acc 81.864 val acc 81.10000000000001\n",
      "\tBatch 257 of 390 training acc 80.21000000000001 val acc 79.57\n",
      "\tBatch 258 of 390 training acc 78.86999999999999 val acc 77.4\n",
      "\tBatch 259 of 390 training acc 76.428 val acc 75.92\n",
      "\tBatch 260 of 390 training acc 79.036 val acc 78.28\n",
      "\tBatch 261 of 390 training acc 77.524 val acc 77.37\n",
      "\tBatch 262 of 390 training acc 75.424 val acc 74.76\n",
      "\tBatch 263 of 390 training acc 80.746 val acc 80.39\n",
      "\tBatch 264 of 390 training acc 81.736 val acc 80.72\n",
      "\tBatch 265 of 390 training acc 81.142 val acc 80.25\n",
      "\tBatch 266 of 390 training acc 78.808 val acc 78.43\n",
      "\tBatch 267 of 390 training acc 75.982 val acc 75.56\n",
      "\tBatch 268 of 390 training acc 76.096 val acc 75.6\n",
      "\tBatch 269 of 390 training acc 81.312 val acc 80.58\n",
      "\tBatch 270 of 390 training acc 82.722 val acc 82.28999999999999\n",
      "\tBatch 271 of 390 training acc 75.402 val acc 74.7\n",
      "\tBatch 272 of 390 training acc 79.81200000000001 val acc 79.17\n",
      "\tBatch 273 of 390 training acc 67.96799999999999 val acc 67.19000000000001\n",
      "\tBatch 274 of 390 training acc 69.872 val acc 68.8\n",
      "\tBatch 275 of 390 training acc 71.054 val acc 70.7\n",
      "\tBatch 276 of 390 training acc 77.064 val acc 76.75\n",
      "\tBatch 277 of 390 training acc 77.592 val acc 76.7\n",
      "\tBatch 278 of 390 training acc 79.692 val acc 78.71000000000001\n",
      "\tBatch 279 of 390 training acc 78.928 val acc 78.41\n",
      "\tBatch 280 of 390 training acc 81.946 val acc 80.93\n",
      "\tBatch 281 of 390 training acc 79.55 val acc 78.91\n",
      "\tBatch 282 of 390 training acc 79.64 val acc 78.79\n",
      "\tBatch 283 of 390 training acc 77.3 val acc 76.72\n",
      "\tBatch 284 of 390 training acc 72.312 val acc 71.66\n",
      "\tBatch 285 of 390 training acc 67.208 val acc 66.82000000000001\n",
      "\tBatch 286 of 390 training acc 75.298 val acc 74.64\n",
      "\tBatch 287 of 390 training acc 71.504 val acc 70.78\n",
      "\tBatch 288 of 390 training acc 80.848 val acc 80.23\n",
      "\tBatch 289 of 390 training acc 80.742 val acc 80.15\n",
      "\tBatch 290 of 390 training acc 81.146 val acc 80.66\n",
      "\tBatch 291 of 390 training acc 81.384 val acc 80.86\n",
      "\tBatch 292 of 390 training acc 82.692 val acc 82.04\n",
      "\tBatch 293 of 390 training acc 80.87 val acc 80.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 294 of 390 training acc 76.02799999999999 val acc 75.39\n",
      "\tBatch 295 of 390 training acc 80.33 val acc 80.07\n",
      "\tBatch 296 of 390 training acc 78.208 val acc 77.52\n",
      "\tBatch 297 of 390 training acc 77.324 val acc 76.91\n",
      "\tBatch 298 of 390 training acc 79.11399999999999 val acc 78.62\n",
      "\tBatch 299 of 390 training acc 75.71799999999999 val acc 75.14\n",
      "\tBatch 300 of 390 training acc 79.56400000000001 val acc 79.14999999999999\n",
      "\tBatch 301 of 390 training acc 81.978 val acc 81.26\n",
      "\tBatch 302 of 390 training acc 80.994 val acc 80.25\n",
      "\tBatch 303 of 390 training acc 78.774 val acc 78.18\n",
      "\tBatch 304 of 390 training acc 73.482 val acc 72.78\n",
      "\tBatch 305 of 390 training acc 76.088 val acc 75.77000000000001\n",
      "\tBatch 306 of 390 training acc 75.022 val acc 74.06\n",
      "\tBatch 307 of 390 training acc 77.704 val acc 77.45\n",
      "\tBatch 308 of 390 training acc 66.988 val acc 66.72\n",
      "\tBatch 309 of 390 training acc 68.726 val acc 68.4\n",
      "\tBatch 310 of 390 training acc 77.58800000000001 val acc 76.52\n",
      "\tBatch 311 of 390 training acc 77.672 val acc 77.42\n",
      "\tBatch 312 of 390 training acc 80.76 val acc 80.04\n",
      "\tBatch 313 of 390 training acc 81.038 val acc 80.19\n",
      "\tBatch 314 of 390 training acc 75.198 val acc 74.69\n",
      "\tBatch 315 of 390 training acc 75.542 val acc 75.19\n",
      "\tBatch 316 of 390 training acc 73.924 val acc 73.02\n",
      "\tBatch 317 of 390 training acc 79.408 val acc 78.51\n",
      "\tBatch 318 of 390 training acc 82.254 val acc 81.53\n",
      "\tBatch 319 of 390 training acc 82.45 val acc 81.89999999999999\n",
      "\tBatch 320 of 390 training acc 79.218 val acc 78.57\n",
      "\tBatch 321 of 390 training acc 80.116 val acc 79.66\n",
      "\tBatch 322 of 390 training acc 71.722 val acc 70.5\n",
      "\tBatch 323 of 390 training acc 79.838 val acc 78.85\n",
      "\tBatch 324 of 390 training acc 80.49 val acc 79.79\n",
      "\tBatch 325 of 390 training acc 77.29 val acc 76.6\n",
      "\tBatch 326 of 390 training acc 79.298 val acc 78.31\n",
      "\tBatch 327 of 390 training acc 78.91 val acc 78.23\n",
      "\tBatch 328 of 390 training acc 76.084 val acc 75.35\n",
      "\tBatch 329 of 390 training acc 77.78 val acc 77.3\n",
      "\tBatch 330 of 390 training acc 79.55799999999999 val acc 78.69\n",
      "\tBatch 331 of 390 training acc 81.43 val acc 80.84\n",
      "\tBatch 332 of 390 training acc 81.024 val acc 80.33\n",
      "\tBatch 333 of 390 training acc 82.828 val acc 81.76\n",
      "\tBatch 334 of 390 training acc 81.148 val acc 79.89\n",
      "\tBatch 335 of 390 training acc 79.36800000000001 val acc 78.49000000000001\n",
      "\tBatch 336 of 390 training acc 79.36 val acc 78.61\n",
      "\tBatch 337 of 390 training acc 82.028 val acc 80.87\n",
      "\tBatch 338 of 390 training acc 78.476 val acc 77.25999999999999\n",
      "\tBatch 339 of 390 training acc 78.818 val acc 77.55\n",
      "\tBatch 340 of 390 training acc 79.95400000000001 val acc 79.24\n",
      "\tBatch 341 of 390 training acc 80.196 val acc 78.86\n",
      "\tBatch 342 of 390 training acc 81.876 val acc 80.57\n",
      "\tBatch 343 of 390 training acc 78.854 val acc 77.59\n",
      "\tBatch 344 of 390 training acc 77.884 val acc 76.77000000000001\n",
      "\tBatch 345 of 390 training acc 78.892 val acc 78.29\n",
      "\tBatch 346 of 390 training acc 70.0 val acc 69.11\n",
      "\tBatch 347 of 390 training acc 77.97 val acc 77.11\n",
      "\tBatch 348 of 390 training acc 76.426 val acc 74.98\n",
      "\tBatch 349 of 390 training acc 75.64800000000001 val acc 74.87\n",
      "\tBatch 350 of 390 training acc 68.17800000000001 val acc 66.82000000000001\n",
      "\tBatch 351 of 390 training acc 65.374 val acc 64.48\n",
      "\tBatch 352 of 390 training acc 77.732 val acc 76.6\n",
      "\tBatch 353 of 390 training acc 75.086 val acc 73.76\n",
      "\tBatch 354 of 390 training acc 68.766 val acc 68.8\n",
      "\tBatch 355 of 390 training acc 77.104 val acc 76.75999999999999\n",
      "\tBatch 356 of 390 training acc 77.842 val acc 77.0\n",
      "\tBatch 357 of 390 training acc 77.084 val acc 76.19\n",
      "\tBatch 358 of 390 training acc 81.388 val acc 80.66\n",
      "\tBatch 359 of 390 training acc 78.764 val acc 77.68\n",
      "\tBatch 360 of 390 training acc 79.13799999999999 val acc 78.47\n",
      "\tBatch 361 of 390 training acc 71.702 val acc 70.52000000000001\n",
      "\tBatch 362 of 390 training acc 79.57600000000001 val acc 78.53999999999999\n",
      "\tBatch 363 of 390 training acc 78.0 val acc 76.86\n",
      "\tBatch 364 of 390 training acc 78.866 val acc 78.13\n",
      "\tBatch 365 of 390 training acc 82.768 val acc 81.93\n",
      "\tBatch 366 of 390 training acc 82.488 val acc 81.56\n",
      "\tBatch 367 of 390 training acc 80.918 val acc 80.04\n",
      "\tBatch 368 of 390 training acc 81.78 val acc 80.97999999999999\n",
      "\tBatch 369 of 390 training acc 79.676 val acc 79.25999999999999\n",
      "\tBatch 370 of 390 training acc 82.56 val acc 81.88\n",
      "\tBatch 371 of 390 training acc 81.812 val acc 80.97999999999999\n",
      "\tBatch 372 of 390 training acc 78.24 val acc 77.42\n",
      "\tBatch 373 of 390 training acc 78.142 val acc 77.25999999999999\n",
      "\tBatch 374 of 390 training acc 77.984 val acc 77.01\n",
      "\tBatch 375 of 390 training acc 81.768 val acc 81.04\n",
      "\tBatch 376 of 390 training acc 82.588 val acc 81.78999999999999\n",
      "\tBatch 377 of 390 training acc 82.068 val acc 80.93\n",
      "\tBatch 378 of 390 training acc 82.66799999999999 val acc 81.81\n",
      "\tBatch 379 of 390 training acc 82.63000000000001 val acc 81.57\n",
      "\tBatch 380 of 390 training acc 80.796 val acc 79.59\n",
      "\tBatch 381 of 390 training acc 74.41600000000001 val acc 73.00999999999999\n",
      "\tBatch 382 of 390 training acc 75.288 val acc 74.36\n",
      "\tBatch 383 of 390 training acc 61.636 val acc 60.309999999999995\n",
      "\tBatch 384 of 390 training acc 78.62 val acc 77.92\n",
      "\tBatch 385 of 390 training acc 80.182 val acc 79.34\n",
      "\tBatch 386 of 390 training acc 80.702 val acc 79.89\n",
      "\tBatch 387 of 390 training acc 73.938 val acc 72.8\n",
      "\tBatch 388 of 390 training acc 79.41 val acc 78.49000000000001\n",
      "\tBatch 389 of 390 training acc 81.328 val acc 80.24\n",
      "epoch 1\n",
      "\tBatch 0 of 390 training acc 82.52000000000001 val acc 81.36\n",
      "\tBatch 1 of 390 training acc 82.256 val acc 81.47999999999999\n",
      "\tBatch 2 of 390 training acc 79.65 val acc 78.61\n",
      "\tBatch 3 of 390 training acc 80.134 val acc 79.56\n",
      "\tBatch 4 of 390 training acc 80.56 val acc 79.64\n",
      "\tBatch 5 of 390 training acc 80.068 val acc 79.08\n",
      "\tBatch 6 of 390 training acc 81.64200000000001 val acc 80.7\n",
      "\tBatch 7 of 390 training acc 79.946 val acc 79.12\n",
      "\tBatch 8 of 390 training acc 79.838 val acc 78.61\n",
      "\tBatch 9 of 390 training acc 80.214 val acc 79.02\n",
      "\tBatch 10 of 390 training acc 81.08800000000001 val acc 79.57\n",
      "\tBatch 11 of 390 training acc 78.916 val acc 78.14\n",
      "\tBatch 12 of 390 training acc 79.916 val acc 79.21000000000001\n",
      "\tBatch 13 of 390 training acc 82.77799999999999 val acc 82.07\n",
      "\tBatch 14 of 390 training acc 77.14800000000001 val acc 76.1\n",
      "\tBatch 15 of 390 training acc 80.392 val acc 79.86\n",
      "\tBatch 16 of 390 training acc 76.854 val acc 76.06\n",
      "\tBatch 17 of 390 training acc 72.81800000000001 val acc 72.19\n",
      "\tBatch 18 of 390 training acc 82.184 val acc 81.31\n",
      "\tBatch 19 of 390 training acc 79.518 val acc 79.19\n",
      "\tBatch 20 of 390 training acc 76.554 val acc 74.91\n",
      "\tBatch 21 of 390 training acc 79.658 val acc 78.79\n",
      "\tBatch 22 of 390 training acc 72.298 val acc 71.3\n",
      "\tBatch 23 of 390 training acc 74.088 val acc 73.72\n",
      "\tBatch 24 of 390 training acc 80.034 val acc 78.84\n",
      "\tBatch 25 of 390 training acc 79.524 val acc 78.92\n",
      "\tBatch 26 of 390 training acc 80.53200000000001 val acc 79.43\n",
      "\tBatch 27 of 390 training acc 80.138 val acc 79.03999999999999\n",
      "\tBatch 28 of 390 training acc 79.756 val acc 78.86999999999999\n",
      "\tBatch 29 of 390 training acc 82.06599999999999 val acc 81.14\n",
      "\tBatch 30 of 390 training acc 73.566 val acc 72.67\n",
      "\tBatch 31 of 390 training acc 70.758 val acc 70.33\n",
      "\tBatch 32 of 390 training acc 71.52199999999999 val acc 70.54\n",
      "\tBatch 33 of 390 training acc 79.05799999999999 val acc 78.10000000000001\n",
      "\tBatch 34 of 390 training acc 82.202 val acc 81.24\n",
      "\tBatch 35 of 390 training acc 81.364 val acc 80.76\n",
      "\tBatch 36 of 390 training acc 82.978 val acc 82.26\n",
      "\tBatch 37 of 390 training acc 82.84 val acc 82.03\n",
      "\tBatch 38 of 390 training acc 81.092 val acc 80.36999999999999\n",
      "\tBatch 39 of 390 training acc 81.188 val acc 80.2\n",
      "\tBatch 40 of 390 training acc 73.302 val acc 72.31\n",
      "\tBatch 41 of 390 training acc 69.788 val acc 69.03\n",
      "\tBatch 42 of 390 training acc 76.53 val acc 75.64999999999999\n",
      "\tBatch 43 of 390 training acc 82.948 val acc 81.74\n",
      "\tBatch 44 of 390 training acc 81.542 val acc 80.25\n",
      "\tBatch 45 of 390 training acc 79.596 val acc 78.91\n",
      "\tBatch 46 of 390 training acc 75.194 val acc 74.49\n",
      "\tBatch 47 of 390 training acc 78.104 val acc 77.4\n",
      "\tBatch 48 of 390 training acc 78.57600000000001 val acc 77.47\n",
      "\tBatch 49 of 390 training acc 82.75200000000001 val acc 81.75\n",
      "\tBatch 50 of 390 training acc 82.17 val acc 80.66\n",
      "\tBatch 51 of 390 training acc 83.76 val acc 82.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 52 of 390 training acc 83.016 val acc 82.11\n",
      "\tBatch 53 of 390 training acc 81.66 val acc 80.60000000000001\n",
      "\tBatch 54 of 390 training acc 76.386 val acc 75.36\n",
      "\tBatch 55 of 390 training acc 78.192 val acc 77.17\n",
      "\tBatch 56 of 390 training acc 67.976 val acc 66.52\n",
      "\tBatch 57 of 390 training acc 69.726 val acc 68.91000000000001\n",
      "\tBatch 58 of 390 training acc 64.872 val acc 63.63999999999999\n",
      "\tBatch 59 of 390 training acc 73.136 val acc 72.02\n",
      "\tBatch 60 of 390 training acc 76.084 val acc 74.88\n",
      "\tBatch 61 of 390 training acc 75.884 val acc 75.17\n",
      "\tBatch 62 of 390 training acc 77.618 val acc 77.07000000000001\n",
      "\tBatch 63 of 390 training acc 81.186 val acc 80.38\n",
      "\tBatch 64 of 390 training acc 81.696 val acc 80.74\n",
      "\tBatch 65 of 390 training acc 81.042 val acc 80.47999999999999\n",
      "\tBatch 66 of 390 training acc 81.44 val acc 80.71000000000001\n",
      "\tBatch 67 of 390 training acc 80.972 val acc 79.91\n",
      "\tBatch 68 of 390 training acc 81.356 val acc 80.52\n",
      "\tBatch 69 of 390 training acc 78.704 val acc 77.51\n",
      "\tBatch 70 of 390 training acc 80.328 val acc 79.73\n",
      "\tBatch 71 of 390 training acc 81.67999999999999 val acc 80.83\n",
      "\tBatch 72 of 390 training acc 82.346 val acc 81.98\n",
      "\tBatch 73 of 390 training acc 82.55799999999999 val acc 82.06\n",
      "\tBatch 74 of 390 training acc 78.886 val acc 78.46\n",
      "\tBatch 75 of 390 training acc 76.222 val acc 74.92999999999999\n",
      "\tBatch 76 of 390 training acc 78.694 val acc 77.55\n",
      "\tBatch 77 of 390 training acc 78.884 val acc 78.03\n",
      "\tBatch 78 of 390 training acc 77.634 val acc 76.44\n",
      "\tBatch 79 of 390 training acc 81.47 val acc 80.36\n",
      "\tBatch 80 of 390 training acc 80.006 val acc 78.88\n",
      "\tBatch 81 of 390 training acc 77.51400000000001 val acc 76.66\n",
      "\tBatch 82 of 390 training acc 78.22 val acc 77.25999999999999\n",
      "\tBatch 83 of 390 training acc 75.09400000000001 val acc 74.72\n",
      "\tBatch 84 of 390 training acc 80.272 val acc 79.85\n",
      "\tBatch 85 of 390 training acc 72.372 val acc 71.63000000000001\n",
      "\tBatch 86 of 390 training acc 79.448 val acc 78.91\n",
      "\tBatch 87 of 390 training acc 75.866 val acc 75.03\n",
      "\tBatch 88 of 390 training acc 79.71000000000001 val acc 79.17999999999999\n",
      "\tBatch 89 of 390 training acc 74.90599999999999 val acc 74.3\n",
      "\tBatch 90 of 390 training acc 77.508 val acc 77.22\n",
      "\tBatch 91 of 390 training acc 77.384 val acc 76.01\n",
      "\tBatch 92 of 390 training acc 73.628 val acc 73.19\n",
      "\tBatch 93 of 390 training acc 63.20400000000001 val acc 62.339999999999996\n",
      "\tBatch 94 of 390 training acc 70.986 val acc 70.66\n",
      "\tBatch 95 of 390 training acc 76.58 val acc 76.07000000000001\n",
      "\tBatch 96 of 390 training acc 75.386 val acc 74.67\n",
      "\tBatch 97 of 390 training acc 82.074 val acc 81.24\n",
      "\tBatch 98 of 390 training acc 81.21199999999999 val acc 80.21000000000001\n",
      "\tBatch 99 of 390 training acc 73.904 val acc 72.72\n",
      "\tBatch 100 of 390 training acc 80.458 val acc 80.31\n",
      "\tBatch 101 of 390 training acc 78.93 val acc 78.4\n",
      "\tBatch 102 of 390 training acc 81.21000000000001 val acc 80.56\n",
      "\tBatch 103 of 390 training acc 82.45 val acc 81.56\n",
      "\tBatch 104 of 390 training acc 79.2 val acc 78.16\n",
      "\tBatch 105 of 390 training acc 81.648 val acc 80.78\n",
      "\tBatch 106 of 390 training acc 81.798 val acc 80.88\n",
      "\tBatch 107 of 390 training acc 80.906 val acc 80.32000000000001\n",
      "\tBatch 108 of 390 training acc 82.78 val acc 81.6\n",
      "\tBatch 109 of 390 training acc 81.402 val acc 80.65\n",
      "\tBatch 110 of 390 training acc 82.786 val acc 81.88\n",
      "\tBatch 111 of 390 training acc 79.51599999999999 val acc 78.99000000000001\n",
      "\tBatch 112 of 390 training acc 80.11200000000001 val acc 79.27\n",
      "\tBatch 113 of 390 training acc 82.918 val acc 82.25\n",
      "\tBatch 114 of 390 training acc 82.514 val acc 81.66\n",
      "\tBatch 115 of 390 training acc 75.1 val acc 74.22\n",
      "\tBatch 116 of 390 training acc 80.354 val acc 79.66\n",
      "\tBatch 117 of 390 training acc 79.708 val acc 78.81\n",
      "\tBatch 118 of 390 training acc 81.816 val acc 81.37\n",
      "\tBatch 119 of 390 training acc 80.672 val acc 79.72\n",
      "\tBatch 120 of 390 training acc 80.08800000000001 val acc 79.24\n",
      "\tBatch 121 of 390 training acc 79.628 val acc 78.96\n",
      "\tBatch 122 of 390 training acc 82.43 val acc 81.73\n",
      "\tBatch 123 of 390 training acc 83.126 val acc 82.6\n",
      "\tBatch 124 of 390 training acc 79.08800000000001 val acc 78.55\n",
      "\tBatch 125 of 390 training acc 80.36 val acc 79.78\n",
      "\tBatch 126 of 390 training acc 82.378 val acc 81.92\n",
      "\tBatch 127 of 390 training acc 74.612 val acc 73.41\n",
      "\tBatch 128 of 390 training acc 78.452 val acc 77.46\n",
      "\tBatch 129 of 390 training acc 74.822 val acc 74.00999999999999\n",
      "\tBatch 130 of 390 training acc 71.476 val acc 70.47\n",
      "\tBatch 131 of 390 training acc 68.71000000000001 val acc 68.0\n",
      "\tBatch 132 of 390 training acc 79.02 val acc 78.36999999999999\n",
      "\tBatch 133 of 390 training acc 82.646 val acc 82.05\n",
      "\tBatch 134 of 390 training acc 81.39800000000001 val acc 80.72\n",
      "\tBatch 135 of 390 training acc 80.518 val acc 80.36\n",
      "\tBatch 136 of 390 training acc 80.066 val acc 79.29\n",
      "\tBatch 137 of 390 training acc 70.798 val acc 70.06\n",
      "\tBatch 138 of 390 training acc 77.926 val acc 77.46\n",
      "\tBatch 139 of 390 training acc 78.196 val acc 77.62\n",
      "\tBatch 140 of 390 training acc 79.418 val acc 78.84\n",
      "\tBatch 141 of 390 training acc 81.11 val acc 80.42\n",
      "\tBatch 142 of 390 training acc 82.384 val acc 81.71000000000001\n",
      "\tBatch 143 of 390 training acc 81.806 val acc 80.96\n",
      "\tBatch 144 of 390 training acc 81.964 val acc 80.97999999999999\n",
      "\tBatch 145 of 390 training acc 78.806 val acc 77.84\n",
      "\tBatch 146 of 390 training acc 79.25 val acc 78.97999999999999\n",
      "\tBatch 147 of 390 training acc 80.338 val acc 79.08\n",
      "\tBatch 148 of 390 training acc 77.086 val acc 76.46\n",
      "\tBatch 149 of 390 training acc 79.818 val acc 79.14999999999999\n",
      "\tBatch 150 of 390 training acc 82.242 val acc 81.32000000000001\n",
      "\tBatch 151 of 390 training acc 80.888 val acc 80.34\n",
      "\tBatch 152 of 390 training acc 78.88199999999999 val acc 78.55\n",
      "\tBatch 153 of 390 training acc 81.696 val acc 81.05\n",
      "\tBatch 154 of 390 training acc 77.778 val acc 77.39\n",
      "\tBatch 155 of 390 training acc 79.25 val acc 78.57\n",
      "\tBatch 156 of 390 training acc 80.116 val acc 79.47\n",
      "\tBatch 157 of 390 training acc 79.176 val acc 78.83\n",
      "\tBatch 158 of 390 training acc 78.184 val acc 76.98\n",
      "\tBatch 159 of 390 training acc 80.538 val acc 79.67999999999999\n",
      "\tBatch 160 of 390 training acc 73.38799999999999 val acc 72.78999999999999\n",
      "\tBatch 161 of 390 training acc 75.804 val acc 75.28\n",
      "\tBatch 162 of 390 training acc 68.052 val acc 67.85\n",
      "\tBatch 163 of 390 training acc 74.464 val acc 73.87\n",
      "\tBatch 164 of 390 training acc 79.668 val acc 79.25999999999999\n",
      "\tBatch 165 of 390 training acc 80.378 val acc 79.67\n",
      "\tBatch 166 of 390 training acc 76.794 val acc 76.01\n",
      "\tBatch 167 of 390 training acc 73.922 val acc 73.31\n",
      "\tBatch 168 of 390 training acc 83.12 val acc 82.23\n",
      "\tBatch 169 of 390 training acc 83.346 val acc 82.0\n",
      "\tBatch 170 of 390 training acc 83.25399999999999 val acc 81.83\n",
      "\tBatch 171 of 390 training acc 83.418 val acc 82.23\n",
      "\tBatch 172 of 390 training acc 82.49 val acc 81.63\n",
      "\tBatch 173 of 390 training acc 78.252 val acc 76.81\n",
      "\tBatch 174 of 390 training acc 81.094 val acc 80.24\n",
      "\tBatch 175 of 390 training acc 82.448 val acc 81.39\n",
      "\tBatch 176 of 390 training acc 78.254 val acc 77.19\n",
      "\tBatch 177 of 390 training acc 76.664 val acc 75.39\n",
      "\tBatch 178 of 390 training acc 68.22399999999999 val acc 67.25999999999999\n",
      "\tBatch 179 of 390 training acc 70.68799999999999 val acc 69.98\n",
      "\tBatch 180 of 390 training acc 82.676 val acc 81.82000000000001\n",
      "\tBatch 181 of 390 training acc 81.124 val acc 80.08999999999999\n",
      "\tBatch 182 of 390 training acc 73.466 val acc 72.82\n",
      "\tBatch 183 of 390 training acc 78.36 val acc 77.57\n",
      "\tBatch 184 of 390 training acc 79.592 val acc 78.53\n",
      "\tBatch 185 of 390 training acc 77.02799999999999 val acc 76.19\n",
      "\tBatch 186 of 390 training acc 82.968 val acc 81.96\n",
      "\tBatch 187 of 390 training acc 78.242 val acc 77.25\n",
      "\tBatch 188 of 390 training acc 79.56800000000001 val acc 78.3\n",
      "\tBatch 189 of 390 training acc 81.362 val acc 80.78999999999999\n",
      "\tBatch 190 of 390 training acc 80.574 val acc 79.29\n",
      "\tBatch 191 of 390 training acc 80.77 val acc 79.82000000000001\n",
      "\tBatch 192 of 390 training acc 81.42 val acc 80.15\n",
      "\tBatch 193 of 390 training acc 81.804 val acc 80.84\n",
      "\tBatch 194 of 390 training acc 81.494 val acc 80.34\n",
      "\tBatch 195 of 390 training acc 81.684 val acc 80.81\n",
      "\tBatch 196 of 390 training acc 83.604 val acc 82.57\n",
      "\tBatch 197 of 390 training acc 83.06 val acc 82.16\n",
      "\tBatch 198 of 390 training acc 83.794 val acc 82.87\n",
      "\tBatch 199 of 390 training acc 77.584 val acc 76.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 200 of 390 training acc 76.336 val acc 75.98\n",
      "\tBatch 201 of 390 training acc 76.108 val acc 74.85000000000001\n",
      "\tBatch 202 of 390 training acc 80.032 val acc 78.91\n",
      "\tBatch 203 of 390 training acc 82.222 val acc 81.17999999999999\n",
      "\tBatch 204 of 390 training acc 81.64200000000001 val acc 80.36999999999999\n",
      "\tBatch 205 of 390 training acc 81.374 val acc 80.2\n",
      "\tBatch 206 of 390 training acc 81.116 val acc 79.96\n",
      "\tBatch 207 of 390 training acc 79.892 val acc 79.33\n",
      "\tBatch 208 of 390 training acc 76.05199999999999 val acc 75.24\n",
      "\tBatch 209 of 390 training acc 82.018 val acc 81.07\n",
      "\tBatch 210 of 390 training acc 83.964 val acc 83.00999999999999\n",
      "\tBatch 211 of 390 training acc 83.304 val acc 82.16\n",
      "\tBatch 212 of 390 training acc 79.264 val acc 78.08\n",
      "\tBatch 213 of 390 training acc 81.372 val acc 80.58\n",
      "\tBatch 214 of 390 training acc 74.124 val acc 72.88\n",
      "\tBatch 215 of 390 training acc 72.056 val acc 71.84\n",
      "\tBatch 216 of 390 training acc 76.068 val acc 75.42\n",
      "\tBatch 217 of 390 training acc 81.038 val acc 80.34\n",
      "\tBatch 218 of 390 training acc 78.628 val acc 77.27000000000001\n",
      "\tBatch 219 of 390 training acc 74.02 val acc 73.81\n",
      "\tBatch 220 of 390 training acc 74.028 val acc 72.84\n",
      "\tBatch 221 of 390 training acc 80.708 val acc 79.94\n",
      "\tBatch 222 of 390 training acc 82.282 val acc 80.94\n",
      "\tBatch 223 of 390 training acc 82.648 val acc 81.75\n",
      "\tBatch 224 of 390 training acc 78.57 val acc 77.25\n",
      "\tBatch 225 of 390 training acc 78.914 val acc 78.18\n",
      "\tBatch 226 of 390 training acc 80.552 val acc 79.94\n",
      "\tBatch 227 of 390 training acc 81.04599999999999 val acc 80.08999999999999\n",
      "\tBatch 228 of 390 training acc 77.926 val acc 77.14999999999999\n",
      "\tBatch 229 of 390 training acc 81.644 val acc 80.97\n",
      "\tBatch 230 of 390 training acc 78.944 val acc 78.02\n",
      "\tBatch 231 of 390 training acc 81.65400000000001 val acc 80.36\n",
      "\tBatch 232 of 390 training acc 80.096 val acc 79.17\n",
      "\tBatch 233 of 390 training acc 81.658 val acc 80.38\n",
      "\tBatch 234 of 390 training acc 82.828 val acc 81.99\n",
      "\tBatch 235 of 390 training acc 81.314 val acc 80.33\n",
      "\tBatch 236 of 390 training acc 80.804 val acc 79.57\n",
      "\tBatch 237 of 390 training acc 75.57199999999999 val acc 74.22\n",
      "\tBatch 238 of 390 training acc 82.72800000000001 val acc 81.69\n",
      "\tBatch 239 of 390 training acc 81.176 val acc 80.05\n",
      "\tBatch 240 of 390 training acc 81.542 val acc 80.69\n",
      "\tBatch 241 of 390 training acc 66.932 val acc 65.12\n",
      "\tBatch 242 of 390 training acc 73.9 val acc 73.24000000000001\n",
      "\tBatch 243 of 390 training acc 75.90599999999999 val acc 74.96000000000001\n",
      "\tBatch 244 of 390 training acc 78.24600000000001 val acc 77.79\n",
      "\tBatch 245 of 390 training acc 79.378 val acc 78.52\n",
      "\tBatch 246 of 390 training acc 78.534 val acc 77.69\n",
      "\tBatch 247 of 390 training acc 77.458 val acc 76.23\n",
      "\tBatch 248 of 390 training acc 79.158 val acc 78.22\n",
      "\tBatch 249 of 390 training acc 78.708 val acc 78.02\n",
      "\tBatch 250 of 390 training acc 78.448 val acc 77.41\n",
      "\tBatch 251 of 390 training acc 82.234 val acc 81.39\n",
      "\tBatch 252 of 390 training acc 82.352 val acc 81.53\n",
      "\tBatch 253 of 390 training acc 82.174 val acc 81.2\n",
      "\tBatch 254 of 390 training acc 83.548 val acc 82.77\n",
      "\tBatch 255 of 390 training acc 82.308 val acc 81.64\n",
      "\tBatch 256 of 390 training acc 77.032 val acc 76.09\n",
      "\tBatch 257 of 390 training acc 77.806 val acc 77.2\n",
      "\tBatch 258 of 390 training acc 75.302 val acc 73.85000000000001\n",
      "\tBatch 259 of 390 training acc 74.256 val acc 73.39\n",
      "\tBatch 260 of 390 training acc 80.308 val acc 79.06\n",
      "\tBatch 261 of 390 training acc 76.55199999999999 val acc 76.17\n",
      "\tBatch 262 of 390 training acc 73.87 val acc 72.69\n",
      "\tBatch 263 of 390 training acc 79.496 val acc 78.77\n",
      "\tBatch 264 of 390 training acc 81.824 val acc 81.06\n",
      "\tBatch 265 of 390 training acc 81.718 val acc 80.64\n",
      "\tBatch 266 of 390 training acc 81.316 val acc 80.69\n",
      "\tBatch 267 of 390 training acc 77.166 val acc 76.64999999999999\n",
      "\tBatch 268 of 390 training acc 80.364 val acc 79.74\n",
      "\tBatch 269 of 390 training acc 82.812 val acc 82.01\n",
      "\tBatch 270 of 390 training acc 82.186 val acc 81.53\n",
      "\tBatch 271 of 390 training acc 77.312 val acc 76.44\n",
      "\tBatch 272 of 390 training acc 80.25 val acc 78.86\n",
      "\tBatch 273 of 390 training acc 69.188 val acc 68.0\n",
      "\tBatch 274 of 390 training acc 72.068 val acc 71.06\n",
      "\tBatch 275 of 390 training acc 72.672 val acc 71.93\n",
      "\tBatch 276 of 390 training acc 80.63 val acc 79.77\n",
      "\tBatch 277 of 390 training acc 78.752 val acc 77.63\n",
      "\tBatch 278 of 390 training acc 78.822 val acc 78.3\n",
      "\tBatch 279 of 390 training acc 78.408 val acc 77.51\n",
      "\tBatch 280 of 390 training acc 82.986 val acc 81.91000000000001\n",
      "\tBatch 281 of 390 training acc 80.092 val acc 79.10000000000001\n",
      "\tBatch 282 of 390 training acc 76.386 val acc 75.7\n",
      "\tBatch 283 of 390 training acc 76.01599999999999 val acc 75.3\n",
      "\tBatch 284 of 390 training acc 76.824 val acc 75.5\n",
      "\tBatch 285 of 390 training acc 71.108 val acc 70.19\n",
      "\tBatch 286 of 390 training acc 76.488 val acc 75.97\n",
      "\tBatch 287 of 390 training acc 75.72 val acc 74.82\n",
      "\tBatch 288 of 390 training acc 80.328 val acc 79.86\n",
      "\tBatch 289 of 390 training acc 82.594 val acc 82.09\n",
      "\tBatch 290 of 390 training acc 82.682 val acc 81.87\n",
      "\tBatch 291 of 390 training acc 83.738 val acc 82.93\n",
      "\tBatch 292 of 390 training acc 81.964 val acc 80.74\n",
      "\tBatch 293 of 390 training acc 81.762 val acc 81.21000000000001\n",
      "\tBatch 294 of 390 training acc 75.33 val acc 74.06\n",
      "\tBatch 295 of 390 training acc 80.28 val acc 79.44\n",
      "\tBatch 296 of 390 training acc 78.532 val acc 77.29\n",
      "\tBatch 297 of 390 training acc 78.648 val acc 78.22\n",
      "\tBatch 298 of 390 training acc 81.95 val acc 80.97999999999999\n",
      "\tBatch 299 of 390 training acc 82.556 val acc 81.85\n",
      "\tBatch 300 of 390 training acc 80.714 val acc 79.58\n",
      "\tBatch 301 of 390 training acc 79.526 val acc 78.82000000000001\n",
      "\tBatch 302 of 390 training acc 78.596 val acc 77.59\n",
      "\tBatch 303 of 390 training acc 82.208 val acc 81.31\n",
      "\tBatch 304 of 390 training acc 78.10000000000001 val acc 77.29\n",
      "\tBatch 305 of 390 training acc 81.41000000000001 val acc 80.74\n",
      "\tBatch 306 of 390 training acc 78.756 val acc 77.38000000000001\n",
      "\tBatch 307 of 390 training acc 78.57600000000001 val acc 77.97\n",
      "\tBatch 308 of 390 training acc 66.836 val acc 66.17\n",
      "\tBatch 309 of 390 training acc 69.702 val acc 69.01\n",
      "\tBatch 310 of 390 training acc 76.414 val acc 75.33999999999999\n",
      "\tBatch 311 of 390 training acc 79.542 val acc 79.03\n",
      "\tBatch 312 of 390 training acc 80.15 val acc 79.14\n",
      "\tBatch 313 of 390 training acc 82.108 val acc 81.11\n",
      "\tBatch 314 of 390 training acc 77.16 val acc 76.41\n",
      "\tBatch 315 of 390 training acc 78.872 val acc 78.05\n",
      "\tBatch 316 of 390 training acc 78.518 val acc 77.58\n",
      "\tBatch 317 of 390 training acc 83.03399999999999 val acc 82.07\n",
      "\tBatch 318 of 390 training acc 82.682 val acc 81.43\n",
      "\tBatch 319 of 390 training acc 82.80199999999999 val acc 81.78\n",
      "\tBatch 320 of 390 training acc 77.962 val acc 77.06\n",
      "\tBatch 321 of 390 training acc 80.66600000000001 val acc 79.91\n",
      "\tBatch 322 of 390 training acc 71.25200000000001 val acc 69.81\n",
      "\tBatch 323 of 390 training acc 80.124 val acc 78.9\n",
      "\tBatch 324 of 390 training acc 82.842 val acc 81.52000000000001\n",
      "\tBatch 325 of 390 training acc 82.356 val acc 81.0\n",
      "\tBatch 326 of 390 training acc 83.636 val acc 82.46\n",
      "\tBatch 327 of 390 training acc 79.678 val acc 78.62\n",
      "\tBatch 328 of 390 training acc 79.666 val acc 78.60000000000001\n",
      "\tBatch 329 of 390 training acc 83.086 val acc 81.76\n",
      "\tBatch 330 of 390 training acc 80.07600000000001 val acc 78.42\n",
      "\tBatch 331 of 390 training acc 81.664 val acc 80.81\n",
      "\tBatch 332 of 390 training acc 80.474 val acc 79.58\n",
      "\tBatch 333 of 390 training acc 83.844 val acc 82.16\n",
      "\tBatch 334 of 390 training acc 83.126 val acc 81.33\n",
      "\tBatch 335 of 390 training acc 79.94200000000001 val acc 78.92\n",
      "\tBatch 336 of 390 training acc 80.43400000000001 val acc 78.62\n",
      "\tBatch 337 of 390 training acc 83.03399999999999 val acc 81.89999999999999\n",
      "\tBatch 338 of 390 training acc 74.14 val acc 72.55\n",
      "\tBatch 339 of 390 training acc 76.472 val acc 75.62\n",
      "\tBatch 340 of 390 training acc 79.304 val acc 78.52\n",
      "\tBatch 341 of 390 training acc 78.636 val acc 77.11\n",
      "\tBatch 342 of 390 training acc 75.28 val acc 74.69\n",
      "\tBatch 343 of 390 training acc 71.41199999999999 val acc 70.54\n",
      "\tBatch 344 of 390 training acc 77.68599999999999 val acc 76.16000000000001\n",
      "\tBatch 345 of 390 training acc 76.02 val acc 74.71\n",
      "\tBatch 346 of 390 training acc 68.47999999999999 val acc 67.27\n",
      "\tBatch 347 of 390 training acc 78.414 val acc 77.64999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 348 of 390 training acc 77.01599999999999 val acc 75.7\n",
      "\tBatch 349 of 390 training acc 75.576 val acc 74.91\n",
      "\tBatch 350 of 390 training acc 71.37400000000001 val acc 69.97\n",
      "\tBatch 351 of 390 training acc 67.204 val acc 66.3\n",
      "\tBatch 352 of 390 training acc 79.652 val acc 78.95\n",
      "\tBatch 353 of 390 training acc 74.32 val acc 73.35000000000001\n",
      "\tBatch 354 of 390 training acc 72.15 val acc 72.05\n",
      "\tBatch 355 of 390 training acc 78.45400000000001 val acc 77.42\n",
      "\tBatch 356 of 390 training acc 79.426 val acc 78.64\n",
      "\tBatch 357 of 390 training acc 80.16 val acc 78.71000000000001\n",
      "\tBatch 358 of 390 training acc 81.152 val acc 80.04\n",
      "\tBatch 359 of 390 training acc 78.94 val acc 77.64999999999999\n",
      "\tBatch 360 of 390 training acc 77.59 val acc 76.32\n",
      "\tBatch 361 of 390 training acc 72.584 val acc 71.37\n",
      "\tBatch 362 of 390 training acc 78.096 val acc 77.08\n",
      "\tBatch 363 of 390 training acc 73.292 val acc 72.61\n",
      "\tBatch 364 of 390 training acc 81.994 val acc 81.17999999999999\n",
      "\tBatch 365 of 390 training acc 82.652 val acc 81.72\n",
      "\tBatch 366 of 390 training acc 83.38600000000001 val acc 82.48\n",
      "\tBatch 367 of 390 training acc 82.478 val acc 81.54\n",
      "\tBatch 368 of 390 training acc 80.782 val acc 79.93\n",
      "\tBatch 369 of 390 training acc 78.194 val acc 77.35\n",
      "\tBatch 370 of 390 training acc 82.28999999999999 val acc 81.39\n",
      "\tBatch 371 of 390 training acc 81.22399999999999 val acc 80.16\n",
      "\tBatch 372 of 390 training acc 80.848 val acc 79.78\n",
      "\tBatch 373 of 390 training acc 82.08 val acc 81.2\n",
      "\tBatch 374 of 390 training acc 80.806 val acc 79.73\n",
      "\tBatch 375 of 390 training acc 82.506 val acc 81.56\n",
      "\tBatch 376 of 390 training acc 81.42200000000001 val acc 80.56\n",
      "\tBatch 377 of 390 training acc 81.88 val acc 80.78\n",
      "\tBatch 378 of 390 training acc 81.922 val acc 81.05\n",
      "\tBatch 379 of 390 training acc 82.95 val acc 81.83\n",
      "\tBatch 380 of 390 training acc 82.136 val acc 80.36999999999999\n",
      "\tBatch 381 of 390 training acc 74.654 val acc 73.11\n",
      "\tBatch 382 of 390 training acc 76.36800000000001 val acc 75.5\n",
      "\tBatch 383 of 390 training acc 60.848 val acc 59.709999999999994\n",
      "\tBatch 384 of 390 training acc 77.826 val acc 77.09\n",
      "\tBatch 385 of 390 training acc 81.726 val acc 80.27\n",
      "\tBatch 386 of 390 training acc 81.326 val acc 80.10000000000001\n",
      "\tBatch 387 of 390 training acc 79.928 val acc 79.01\n",
      "\tBatch 388 of 390 training acc 79.778 val acc 78.62\n",
      "\tBatch 389 of 390 training acc 81.842 val acc 80.83\n",
      "epoch 2\n",
      "\tBatch 0 of 390 training acc 82.50999999999999 val acc 81.12\n",
      "\tBatch 1 of 390 training acc 81.52000000000001 val acc 80.56\n",
      "\tBatch 2 of 390 training acc 81.172 val acc 79.97\n",
      "\tBatch 3 of 390 training acc 78.118 val acc 77.36\n",
      "\tBatch 4 of 390 training acc 79.524 val acc 78.49000000000001\n",
      "\tBatch 5 of 390 training acc 80.67 val acc 79.94\n",
      "\tBatch 6 of 390 training acc 81.796 val acc 80.53\n",
      "\tBatch 7 of 390 training acc 77.51599999999999 val acc 77.02\n",
      "\tBatch 8 of 390 training acc 81.88 val acc 81.2\n",
      "\tBatch 9 of 390 training acc 78.994 val acc 77.95\n",
      "\tBatch 10 of 390 training acc 77.144 val acc 75.94\n",
      "\tBatch 11 of 390 training acc 80.662 val acc 79.81\n",
      "\tBatch 12 of 390 training acc 80.238 val acc 79.4\n",
      "\tBatch 13 of 390 training acc 82.01 val acc 81.5\n",
      "\tBatch 14 of 390 training acc 75.666 val acc 74.55000000000001\n",
      "\tBatch 15 of 390 training acc 80.354 val acc 79.66\n",
      "\tBatch 16 of 390 training acc 77.644 val acc 76.8\n",
      "\tBatch 17 of 390 training acc 75.136 val acc 74.44\n",
      "\tBatch 18 of 390 training acc 82.536 val acc 81.51\n",
      "\tBatch 19 of 390 training acc 79.944 val acc 79.11\n",
      "\tBatch 20 of 390 training acc 75.848 val acc 74.17\n",
      "\tBatch 21 of 390 training acc 77.53 val acc 77.12\n",
      "\tBatch 22 of 390 training acc 72.406 val acc 71.46000000000001\n",
      "\tBatch 23 of 390 training acc 76.112 val acc 75.32\n",
      "\tBatch 24 of 390 training acc 82.02000000000001 val acc 80.67999999999999\n",
      "\tBatch 25 of 390 training acc 81.69 val acc 80.74\n",
      "\tBatch 26 of 390 training acc 80.22399999999999 val acc 79.2\n",
      "\tBatch 27 of 390 training acc 81.84 val acc 80.38\n",
      "\tBatch 28 of 390 training acc 78.982 val acc 78.36999999999999\n",
      "\tBatch 29 of 390 training acc 80.45 val acc 79.05\n",
      "\tBatch 30 of 390 training acc 73.86200000000001 val acc 72.78999999999999\n",
      "\tBatch 31 of 390 training acc 71.306 val acc 70.94\n",
      "\tBatch 32 of 390 training acc 71.03399999999999 val acc 70.02000000000001\n",
      "\tBatch 33 of 390 training acc 79.496 val acc 78.61\n",
      "\tBatch 34 of 390 training acc 82.786 val acc 81.86\n",
      "\tBatch 35 of 390 training acc 81.03399999999999 val acc 80.23\n",
      "\tBatch 36 of 390 training acc 82.38 val acc 81.2\n",
      "\tBatch 37 of 390 training acc 82.624 val acc 81.25\n",
      "\tBatch 38 of 390 training acc 81.716 val acc 80.64\n",
      "\tBatch 39 of 390 training acc 80.86 val acc 80.0\n",
      "\tBatch 40 of 390 training acc 73.68400000000001 val acc 72.07000000000001\n",
      "\tBatch 41 of 390 training acc 72.868 val acc 72.11\n",
      "\tBatch 42 of 390 training acc 77.852 val acc 77.09\n",
      "\tBatch 43 of 390 training acc 82.504 val acc 81.19\n",
      "\tBatch 44 of 390 training acc 81.26400000000001 val acc 80.15\n",
      "\tBatch 45 of 390 training acc 74.25 val acc 73.45\n",
      "\tBatch 46 of 390 training acc 70.588 val acc 69.6\n",
      "\tBatch 47 of 390 training acc 78.41799999999999 val acc 77.88000000000001\n",
      "\tBatch 48 of 390 training acc 81.606 val acc 80.81\n",
      "\tBatch 49 of 390 training acc 82.806 val acc 81.85\n",
      "\tBatch 50 of 390 training acc 81.826 val acc 80.17\n",
      "\tBatch 51 of 390 training acc 82.91 val acc 82.19\n",
      "\tBatch 52 of 390 training acc 81.958 val acc 80.84\n",
      "\tBatch 53 of 390 training acc 77.574 val acc 76.44999999999999\n",
      "\tBatch 54 of 390 training acc 77.89399999999999 val acc 76.96\n",
      "\tBatch 55 of 390 training acc 82.676 val acc 81.52000000000001\n",
      "\tBatch 56 of 390 training acc 76.61 val acc 75.6\n",
      "\tBatch 57 of 390 training acc 74.898 val acc 73.68\n",
      "\tBatch 58 of 390 training acc 72.178 val acc 70.72\n",
      "\tBatch 59 of 390 training acc 69.388 val acc 68.36\n",
      "\tBatch 60 of 390 training acc 78.762 val acc 78.11\n",
      "\tBatch 61 of 390 training acc 81.83 val acc 81.16\n",
      "\tBatch 62 of 390 training acc 81.88 val acc 80.53\n",
      "\tBatch 63 of 390 training acc 80.28999999999999 val acc 79.54\n",
      "\tBatch 64 of 390 training acc 79.702 val acc 78.46\n",
      "\tBatch 65 of 390 training acc 77.4 val acc 76.41\n",
      "\tBatch 66 of 390 training acc 79.36999999999999 val acc 78.57\n",
      "\tBatch 67 of 390 training acc 82.99600000000001 val acc 81.87\n",
      "\tBatch 68 of 390 training acc 82.318 val acc 81.53\n",
      "\tBatch 69 of 390 training acc 81.99600000000001 val acc 80.43\n",
      "\tBatch 70 of 390 training acc 83.918 val acc 82.38\n",
      "\tBatch 71 of 390 training acc 83.66 val acc 82.19999999999999\n",
      "\tBatch 72 of 390 training acc 83.122 val acc 81.8\n",
      "\tBatch 73 of 390 training acc 81.918 val acc 81.07\n",
      "\tBatch 74 of 390 training acc 80.932 val acc 80.01\n",
      "\tBatch 75 of 390 training acc 72.102 val acc 71.28999999999999\n",
      "\tBatch 76 of 390 training acc 72.088 val acc 71.57\n",
      "\tBatch 77 of 390 training acc 74.24199999999999 val acc 73.72\n",
      "\tBatch 78 of 390 training acc 79.896 val acc 78.97\n",
      "\tBatch 79 of 390 training acc 82.03399999999999 val acc 80.76\n",
      "\tBatch 80 of 390 training acc 81.574 val acc 80.25\n",
      "\tBatch 81 of 390 training acc 78.862 val acc 78.22\n",
      "\tBatch 82 of 390 training acc 82.502 val acc 81.51\n",
      "\tBatch 83 of 390 training acc 81.27799999999999 val acc 80.2\n",
      "\tBatch 84 of 390 training acc 83.078 val acc 81.87\n",
      "\tBatch 85 of 390 training acc 80.32000000000001 val acc 79.14\n",
      "\tBatch 86 of 390 training acc 80.146 val acc 79.16\n",
      "\tBatch 87 of 390 training acc 76.36800000000001 val acc 74.97\n",
      "\tBatch 88 of 390 training acc 77.288 val acc 76.66\n",
      "\tBatch 89 of 390 training acc 75.268 val acc 74.00999999999999\n",
      "\tBatch 90 of 390 training acc 74.512 val acc 73.98\n",
      "\tBatch 91 of 390 training acc 77.936 val acc 76.82\n",
      "\tBatch 92 of 390 training acc 73.024 val acc 72.16\n",
      "\tBatch 93 of 390 training acc 64.034 val acc 63.13999999999999\n",
      "\tBatch 94 of 390 training acc 72.026 val acc 71.66\n",
      "\tBatch 95 of 390 training acc 77.924 val acc 77.39\n",
      "\tBatch 96 of 390 training acc 77.168 val acc 76.49000000000001\n",
      "\tBatch 97 of 390 training acc 80.612 val acc 79.75999999999999\n",
      "\tBatch 98 of 390 training acc 81.202 val acc 79.86999999999999\n",
      "\tBatch 99 of 390 training acc 74.074 val acc 72.63\n",
      "\tBatch 100 of 390 training acc 81.322 val acc 81.13\n",
      "\tBatch 101 of 390 training acc 78.952 val acc 78.03\n",
      "\tBatch 102 of 390 training acc 81.57 val acc 80.76\n",
      "\tBatch 103 of 390 training acc 82.826 val acc 81.51\n",
      "\tBatch 104 of 390 training acc 79.708 val acc 78.8\n",
      "\tBatch 105 of 390 training acc 82.72 val acc 81.73\n",
      "\tBatch 106 of 390 training acc 80.262 val acc 79.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 107 of 390 training acc 79.33 val acc 78.27\n",
      "\tBatch 108 of 390 training acc 82.554 val acc 81.57\n",
      "\tBatch 109 of 390 training acc 81.53200000000001 val acc 80.43\n",
      "\tBatch 110 of 390 training acc 81.52199999999999 val acc 80.72\n",
      "\tBatch 111 of 390 training acc 75.432 val acc 74.7\n",
      "\tBatch 112 of 390 training acc 77.05 val acc 76.13\n",
      "\tBatch 113 of 390 training acc 82.99600000000001 val acc 82.42\n",
      "\tBatch 114 of 390 training acc 80.86 val acc 79.88\n",
      "\tBatch 115 of 390 training acc 79.412 val acc 78.53999999999999\n",
      "\tBatch 116 of 390 training acc 82.536 val acc 81.62\n",
      "\tBatch 117 of 390 training acc 81.826 val acc 80.78\n",
      "\tBatch 118 of 390 training acc 79.448 val acc 78.83\n",
      "\tBatch 119 of 390 training acc 81.596 val acc 80.25\n",
      "\tBatch 120 of 390 training acc 78.352 val acc 77.27000000000001\n",
      "\tBatch 121 of 390 training acc 74.876 val acc 74.81\n",
      "\tBatch 122 of 390 training acc 79.208 val acc 78.31\n",
      "\tBatch 123 of 390 training acc 83.592 val acc 82.73\n",
      "\tBatch 124 of 390 training acc 78.794 val acc 78.21000000000001\n",
      "\tBatch 125 of 390 training acc 81.34599999999999 val acc 80.45\n",
      "\tBatch 126 of 390 training acc 83.884 val acc 83.44\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 5\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_fashion = SVM(n_class_fashion, lr, n_epochs, reg_const)\n",
    "svm_fashion.train(X_train_fashion, y_train_fashion,X_val_fashion,y_val_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 83.884000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 4 6 3 2 7 2 5 5 0 9 5 7 7 9 1 0 2 4 3 1 4 8 2 3 0 2 4 4 5 3 6]\n",
      "[9 0 0 3 0 2 7 2 5 5 0 9 5 5 7 9 1 0 6 4 3 1 4 8 4 3 0 2 4 4 5 3 6]\n"
     ]
    }
   ],
   "source": [
    "print(pred_svm[0:33])\n",
    "print(y_train_fashion[0:33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 83.440000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SVM on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 81.990000\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 2 8 0 0 7 7 7 1 2 6 3 9 3 8 8 3]\n",
      "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3]\n"
     ]
    }
   ],
   "source": [
    "print(pred_svm[0:33])\n",
    "print(y_test_fashion[0:33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/svm_submission_fashion.csv', svm_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\tBatch 0 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 1 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 2 of 38 training acc 48.317603610997125 val acc 49.16923076923077\n",
      "\tBatch 3 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 4 of 38 training acc 48.317603610997125 val acc 49.16923076923077\n",
      "\tBatch 5 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 6 of 38 training acc 60.99712761592121 val acc 58.27692307692308\n",
      "\tBatch 7 of 38 training acc 53.610997127615924 val acc 52.61538461538462\n",
      "\tBatch 8 of 38 training acc 63.828477636438244 val acc 61.23076923076923\n",
      "\tBatch 9 of 38 training acc 74.86663931062782 val acc 73.53846153846155\n",
      "\tBatch 10 of 38 training acc 70.94788674599918 val acc 68.55384615384615\n",
      "\tBatch 11 of 38 training acc 79.4009027492819 val acc 77.78461538461539\n",
      "\tBatch 12 of 38 training acc 65.08001641362331 val acc 62.76923076923077\n",
      "\tBatch 13 of 38 training acc 74.12802626179729 val acc 72.67692307692307\n",
      "\tBatch 14 of 38 training acc 60.40213377102995 val acc 58.89230769230769\n",
      "\tBatch 15 of 38 training acc 53.36479277800574 val acc 52.307692307692314\n",
      "\tBatch 16 of 38 training acc 48.35863766926549 val acc 49.16923076923077\n",
      "\tBatch 17 of 38 training acc 52.25687320475995 val acc 51.38461538461539\n",
      "\tBatch 18 of 38 training acc 76.20024620434961 val acc 74.46153846153845\n",
      "\tBatch 19 of 38 training acc 82.41690603200657 val acc 80.98461538461538\n",
      "\tBatch 20 of 38 training acc 74.06647517439475 val acc 72.8\n",
      "\tBatch 21 of 38 training acc 83.31965531391054 val acc 82.21538461538461\n",
      "\tBatch 22 of 38 training acc 81.00123102174805 val acc 78.70769230769231\n",
      "\tBatch 23 of 38 training acc 84.30447271235126 val acc 82.89230769230768\n",
      "\tBatch 24 of 38 training acc 75.40008206811653 val acc 74.64615384615385\n",
      "\tBatch 25 of 38 training acc 83.89413212966763 val acc 82.33846153846154\n",
      "\tBatch 26 of 38 training acc 74.94870742716455 val acc 74.64615384615385\n",
      "\tBatch 27 of 38 training acc 83.85309807139926 val acc 81.35384615384615\n",
      "\tBatch 28 of 38 training acc 78.23143208863357 val acc 77.35384615384615\n",
      "\tBatch 29 of 38 training acc 83.46327451784981 val acc 80.92307692307692\n",
      "\tBatch 30 of 38 training acc 60.27903159622486 val acc 60.36923076923076\n",
      "\tBatch 31 of 38 training acc 52.29790726302831 val acc 51.44615384615384\n",
      "\tBatch 32 of 38 training acc 48.58432498974148 val acc 49.41538461538462\n",
      "\tBatch 33 of 38 training acc 58.74025441116126 val acc 56.92307692307692\n",
      "\tBatch 34 of 38 training acc 70.5990972507181 val acc 69.35384615384615\n",
      "\tBatch 35 of 38 training acc 77.3081657775954 val acc 76.0\n",
      "\tBatch 36 of 38 training acc 85.22773902338942 val acc 83.63076923076923\n",
      "\tBatch 37 of 38 training acc 78.86745999179318 val acc 77.29230769230769\n",
      "epoch 1\n",
      "\tBatch 0 of 38 training acc 82.76569552728765 val acc 80.3076923076923\n",
      "\tBatch 1 of 38 training acc 84.26343865408289 val acc 83.26153846153846\n",
      "\tBatch 2 of 38 training acc 84.32498974148544 val acc 83.50769230769231\n",
      "\tBatch 3 of 38 training acc 85.22773902338942 val acc 84.12307692307692\n",
      "\tBatch 4 of 38 training acc 86.0073861304883 val acc 85.29230769230769\n",
      "\tBatch 5 of 38 training acc 82.12966762412802 val acc 81.23076923076923\n",
      "\tBatch 6 of 38 training acc 86.74599917931883 val acc 86.21538461538462\n",
      "\tBatch 7 of 38 training acc 76.81575707837504 val acc 76.8\n",
      "\tBatch 8 of 38 training acc 79.91382847763644 val acc 77.04615384615384\n",
      "\tBatch 9 of 38 training acc 54.92408699220353 val acc 55.87692307692308\n",
      "\tBatch 10 of 38 training acc 52.585145670906854 val acc 51.69230769230769\n",
      "\tBatch 11 of 38 training acc 60.56627000410341 val acc 60.676923076923075\n",
      "\tBatch 12 of 38 training acc 60.21748050882232 val acc 57.53846153846154\n",
      "\tBatch 13 of 38 training acc 64.77226097661058 val acc 64.86153846153846\n",
      "\tBatch 14 of 38 training acc 69.94255231842429 val acc 68.36923076923077\n",
      "\tBatch 15 of 38 training acc 72.52769798933114 val acc 71.38461538461539\n",
      "\tBatch 16 of 38 training acc 85.49446040213378 val acc 83.56923076923077\n",
      "\tBatch 17 of 38 training acc 79.1957324579401 val acc 77.29230769230769\n",
      "\tBatch 18 of 38 training acc 86.33565859663521 val acc 84.55384615384615\n",
      "\tBatch 19 of 38 training acc 72.73286828067296 val acc 71.6923076923077\n",
      "\tBatch 20 of 38 training acc 85.28929011079197 val acc 83.32307692307693\n",
      "\tBatch 21 of 38 training acc 82.4989741485433 val acc 82.15384615384616\n",
      "\tBatch 22 of 38 training acc 87.21789084940501 val acc 85.23076923076923\n",
      "\tBatch 23 of 38 training acc 76.75420599097251 val acc 76.8\n",
      "\tBatch 24 of 38 training acc 81.63725892490767 val acc 78.83076923076922\n",
      "\tBatch 25 of 38 training acc 75.13336068937218 val acc 74.33846153846154\n",
      "\tBatch 26 of 38 training acc 77.57488715633977 val acc 75.56923076923077\n",
      "\tBatch 27 of 38 training acc 74.02544111612639 val acc 73.84615384615385\n",
      "\tBatch 28 of 38 training acc 87.40254411161263 val acc 85.78461538461538\n",
      "\tBatch 29 of 38 training acc 70.90685268773082 val acc 69.78461538461539\n",
      "\tBatch 30 of 38 training acc 73.69716864997949 val acc 71.50769230769231\n",
      "\tBatch 31 of 38 training acc 51.5387771850636 val acc 52.0\n",
      "\tBatch 32 of 38 training acc 62.8846942962659 val acc 60.0\n",
      "\tBatch 33 of 38 training acc 54.47271235125154 val acc 53.784615384615385\n",
      "\tBatch 34 of 38 training acc 54.34961017644645 val acc 53.35384615384615\n",
      "\tBatch 35 of 38 training acc 67.93188346327452 val acc 66.70769230769231\n",
      "\tBatch 36 of 38 training acc 80.22158391464916 val acc 78.64615384615384\n",
      "\tBatch 37 of 38 training acc 85.28929011079197 val acc 83.75384615384615\n",
      "epoch 2\n",
      "\tBatch 0 of 38 training acc 80.98071399261387 val acc 78.8923076923077\n",
      "\tBatch 1 of 38 training acc 85.61756257693885 val acc 83.87692307692308\n",
      "\tBatch 2 of 38 training acc 76.83627410750923 val acc 75.6923076923077\n",
      "\tBatch 3 of 38 training acc 72.42511284366023 val acc 69.72307692307692\n",
      "\tBatch 4 of 38 training acc 84.40705785802216 val acc 83.50769230769231\n",
      "\tBatch 5 of 38 training acc 85.41239228559705 val acc 84.61538461538461\n",
      "\tBatch 6 of 38 training acc 85.6791136643414 val acc 84.61538461538461\n",
      "\tBatch 7 of 38 training acc 85.84324989741485 val acc 84.98461538461538\n",
      "\tBatch 8 of 38 training acc 83.75051292572836 val acc 83.13846153846154\n",
      "\tBatch 9 of 38 training acc 83.44275748871564 val acc 82.89230769230768\n",
      "\tBatch 10 of 38 training acc 88.2027082478457 val acc 86.27692307692307\n",
      "\tBatch 11 of 38 training acc 72.3635617562577 val acc 72.06153846153846\n",
      "\tBatch 12 of 38 training acc 83.27862125564218 val acc 81.2923076923077\n",
      "\tBatch 13 of 38 training acc 69.61427985227739 val acc 69.6\n",
      "\tBatch 14 of 38 training acc 70.94788674599918 val acc 68.8\n",
      "\tBatch 15 of 38 training acc 66.22897004513746 val acc 66.76923076923077\n",
      "\tBatch 16 of 38 training acc 80.67295855560116 val acc 78.83076923076922\n",
      "\tBatch 17 of 38 training acc 86.15100533442758 val acc 85.23076923076923\n",
      "\tBatch 18 of 38 training acc 84.75584735330324 val acc 84.67692307692307\n",
      "\tBatch 19 of 38 training acc 86.58186294624538 val acc 85.72307692307692\n",
      "\tBatch 20 of 38 training acc 79.17521542880591 val acc 78.58461538461539\n",
      "\tBatch 21 of 38 training acc 88.59253180139515 val acc 87.01538461538462\n",
      "\tBatch 22 of 38 training acc 84.07878539187526 val acc 84.06153846153846\n",
      "\tBatch 23 of 38 training acc 73.34837915469839 val acc 72.8\n",
      "\tBatch 24 of 38 training acc 74.23061140746819 val acc 71.44615384615385\n",
      "\tBatch 25 of 38 training acc 54.22650800164136 val acc 55.69230769230769\n",
      "\tBatch 26 of 38 training acc 51.86704965121051 val acc 51.07692307692307\n",
      "\tBatch 27 of 38 training acc 73.36889618383258 val acc 72.0\n",
      "\tBatch 28 of 38 training acc 86.74599917931883 val acc 85.23076923076923\n",
      "\tBatch 29 of 38 training acc 79.524004924087 val acc 78.0923076923077\n",
      "\tBatch 30 of 38 training acc 85.63807960607303 val acc 83.93846153846154\n",
      "\tBatch 31 of 38 training acc 65.05949938448913 val acc 66.21538461538462\n",
      "\tBatch 32 of 38 training acc 84.34550677061962 val acc 81.6\n",
      "\tBatch 33 of 38 training acc 87.52564628641773 val acc 86.15384615384616\n",
      "\tBatch 34 of 38 training acc 88.03857201477227 val acc 86.64615384615385\n",
      "\tBatch 35 of 38 training acc 81.51415675010259 val acc 81.1076923076923\n",
      "\tBatch 36 of 38 training acc 88.6540828887977 val acc 86.83076923076923\n",
      "\tBatch 37 of 38 training acc 81.2679524004924 val acc 80.98461538461538\n",
      "epoch 3\n",
      "\tBatch 0 of 38 training acc 75.83093967993435 val acc 73.35384615384616\n",
      "\tBatch 1 of 38 training acc 84.07878539187526 val acc 83.87692307692308\n",
      "\tBatch 2 of 38 training acc 88.79770209273697 val acc 87.93846153846154\n",
      "\tBatch 3 of 38 training acc 72.93803857201478 val acc 72.73846153846154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 4 of 38 training acc 66.53672548215019 val acc 63.87692307692308\n",
      "\tBatch 5 of 38 training acc 62.51538777185064 val acc 63.38461538461539\n",
      "\tBatch 6 of 38 training acc 66.88551497743127 val acc 64.49230769230769\n",
      "\tBatch 7 of 38 training acc 74.02544111612639 val acc 72.36923076923077\n",
      "\tBatch 8 of 38 training acc 84.38654082888797 val acc 81.78461538461539\n",
      "\tBatch 9 of 38 training acc 83.54534263438654 val acc 83.01538461538462\n",
      "\tBatch 10 of 38 training acc 88.79770209273697 val acc 87.87692307692308\n",
      "\tBatch 11 of 38 training acc 67.00861715223635 val acc 68.18461538461538\n",
      "\tBatch 12 of 38 training acc 67.11120229790725 val acc 64.73846153846154\n",
      "\tBatch 13 of 38 training acc 62.37176856791137 val acc 63.38461538461539\n",
      "\tBatch 14 of 38 training acc 61.61263848994666 val acc 59.815384615384616\n",
      "\tBatch 15 of 38 training acc 66.86499794829709 val acc 67.50769230769231\n",
      "\tBatch 16 of 38 training acc 85.61756257693885 val acc 83.13846153846154\n",
      "\tBatch 17 of 38 training acc 86.39720968403776 val acc 85.66153846153847\n",
      "\tBatch 18 of 38 training acc 85.16618793598687 val acc 85.1076923076923\n",
      "\tBatch 19 of 38 training acc 85.82273286828067 val acc 85.72307692307692\n",
      "\tBatch 20 of 38 training acc 84.22240459581452 val acc 83.75384615384615\n",
      "\tBatch 21 of 38 training acc 88.94132129667625 val acc 87.44615384615385\n",
      "\tBatch 22 of 38 training acc 88.32581042265079 val acc 87.6923076923077\n",
      "\tBatch 23 of 38 training acc 71.56339762002462 val acc 71.32307692307693\n",
      "\tBatch 24 of 38 training acc 66.741895773492 val acc 63.938461538461546\n",
      "\tBatch 25 of 38 training acc 52.44152646696758 val acc 53.04615384615384\n",
      "\tBatch 26 of 38 training acc 52.07221994255232 val acc 51.50769230769231\n",
      "\tBatch 27 of 38 training acc 74.96922445629873 val acc 73.47692307692307\n",
      "\tBatch 28 of 38 training acc 86.58186294624538 val acc 85.04615384615384\n",
      "\tBatch 29 of 38 training acc 80.01641362330734 val acc 78.46153846153847\n",
      "\tBatch 30 of 38 training acc 86.60237997537956 val acc 84.73846153846154\n",
      "\tBatch 31 of 38 training acc 72.30201066885516 val acc 70.58461538461539\n",
      "\tBatch 32 of 38 training acc 85.28929011079197 val acc 83.07692307692308\n",
      "\tBatch 33 of 38 training acc 86.06893721789085 val acc 85.35384615384616\n",
      "\tBatch 34 of 38 training acc 87.83340172343046 val acc 85.96923076923076\n",
      "\tBatch 35 of 38 training acc 85.2482560525236 val acc 84.61538461538461\n",
      "\tBatch 36 of 38 training acc 88.22322527697989 val acc 87.63076923076923\n",
      "\tBatch 37 of 38 training acc 86.4587607714403 val acc 86.03076923076924\n",
      "epoch 4\n",
      "\tBatch 0 of 38 training acc 88.36684448091916 val acc 86.58461538461538\n",
      "\tBatch 1 of 38 training acc 87.71029954862536 val acc 87.07692307692308\n",
      "\tBatch 2 of 38 training acc 87.34099302421009 val acc 86.76923076923076\n",
      "\tBatch 3 of 38 training acc 89.78251949117768 val acc 89.29230769230769\n",
      "\tBatch 4 of 38 training acc 79.524004924087 val acc 79.07692307692308\n",
      "\tBatch 5 of 38 training acc 86.7870332375872 val acc 84.98461538461538\n",
      "\tBatch 6 of 38 training acc 88.03857201477227 val acc 87.81538461538462\n",
      "\tBatch 7 of 38 training acc 88.05908904390645 val acc 87.75384615384615\n",
      "\tBatch 8 of 38 training acc 83.64792778005746 val acc 83.50769230769231\n",
      "\tBatch 9 of 38 training acc 90.4185473943373 val acc 89.41538461538462\n",
      "\tBatch 10 of 38 training acc 87.71029954862536 val acc 86.83076923076923\n",
      "\tBatch 11 of 38 training acc 88.07960607304062 val acc 87.07692307692308\n",
      "\tBatch 12 of 38 training acc 90.43906442347148 val acc 89.96923076923076\n",
      "\tBatch 13 of 38 training acc 65.83914649158802 val acc 65.96923076923076\n",
      "\tBatch 14 of 38 training acc 61.48953631514157 val acc 58.769230769230774\n",
      "\tBatch 15 of 38 training acc 54.49322938038572 val acc 56.246153846153845\n",
      "\tBatch 16 of 38 training acc 59.21214608124743 val acc 57.29230769230769\n",
      "\tBatch 17 of 38 training acc 74.84612228149365 val acc 73.16923076923077\n",
      "\tBatch 18 of 38 training acc 81.41157160443167 val acc 80.0\n",
      "\tBatch 19 of 38 training acc 78.60073861304883 val acc 78.03076923076922\n",
      "\tBatch 20 of 38 training acc 88.22322527697989 val acc 86.33846153846154\n",
      "\tBatch 21 of 38 training acc 87.50512925728354 val acc 86.76923076923076\n",
      "\tBatch 22 of 38 training acc 88.8797702092737 val acc 88.12307692307692\n",
      "\tBatch 23 of 38 training acc 75.42059909725072 val acc 74.27692307692307\n",
      "\tBatch 24 of 38 training acc 85.63807960607303 val acc 82.83076923076923\n",
      "\tBatch 25 of 38 training acc 88.96183832581043 val acc 88.36923076923077\n",
      "\tBatch 26 of 38 training acc 75.52318424292163 val acc 74.33846153846154\n",
      "\tBatch 27 of 38 training acc 79.48297086581863 val acc 77.53846153846153\n",
      "\tBatch 28 of 38 training acc 89.39269593762823 val acc 88.55384615384615\n",
      "\tBatch 29 of 38 training acc 76.9798933114485 val acc 76.12307692307692\n",
      "\tBatch 30 of 38 training acc 83.09396799343455 val acc 80.67692307692307\n",
      "\tBatch 31 of 38 training acc 61.59212146081248 val acc 62.03076923076923\n",
      "\tBatch 32 of 38 training acc 75.6668034468609 val acc 73.35384615384616\n",
      "\tBatch 33 of 38 training acc 70.94788674599918 val acc 70.58461538461539\n",
      "\tBatch 34 of 38 training acc 57.57078375051292 val acc 55.630769230769225\n",
      "\tBatch 35 of 38 training acc 60.771440295445224 val acc 61.784615384615385\n",
      "\tBatch 36 of 38 training acc 73.63561756257694 val acc 72.12307692307692\n",
      "\tBatch 37 of 38 training acc 88.22322527697989 val acc 86.95384615384616\n",
      "epoch 5\n",
      "\tBatch 0 of 38 training acc 86.74599917931883 val acc 86.15384615384616\n",
      "\tBatch 1 of 38 training acc 87.75133360689372 val acc 86.4\n",
      "\tBatch 2 of 38 training acc 86.4587607714403 val acc 85.35384615384616\n",
      "\tBatch 3 of 38 training acc 89.22855970455478 val acc 87.50769230769231\n",
      "\tBatch 4 of 38 training acc 84.8994665572425 val acc 84.18461538461538\n",
      "\tBatch 5 of 38 training acc 89.10545752974969 val acc 87.32307692307693\n",
      "\tBatch 6 of 38 training acc 85.22773902338942 val acc 84.8\n",
      "\tBatch 7 of 38 training acc 90.0902749281904 val acc 89.23076923076924\n",
      "\tBatch 8 of 38 training acc 88.30529339351662 val acc 87.56923076923077\n",
      "\tBatch 9 of 38 training acc 88.18219121871152 val acc 87.44615384615385\n",
      "\tBatch 10 of 38 training acc 83.17603610997128 val acc 82.76923076923077\n",
      "\tBatch 11 of 38 training acc 90.62371768567911 val acc 89.90769230769232\n",
      "\tBatch 12 of 38 training acc 73.65613459171112 val acc 73.41538461538461\n",
      "\tBatch 13 of 38 training acc 81.98604842018877 val acc 79.63076923076923\n",
      "\tBatch 14 of 38 training acc 65.98276569552729 val acc 66.33846153846153\n",
      "\tBatch 15 of 38 training acc 54.12392285597045 val acc 52.738461538461536\n",
      "\tBatch 16 of 38 training acc 49.958965941731634 val acc 50.03076923076924\n",
      "\tBatch 17 of 38 training acc 53.65203118588428 val acc 52.738461538461536\n",
      "\tBatch 18 of 38 training acc 85.5560114895363 val acc 85.6\n",
      "\tBatch 19 of 38 training acc 87.64874846122281 val acc 86.95384615384616\n",
      "\tBatch 20 of 38 training acc 84.7968814115716 val acc 84.49230769230769\n",
      "\tBatch 21 of 38 training acc 88.73615100533443 val acc 87.87692307692308\n",
      "\tBatch 22 of 38 training acc 88.28477636438244 val acc 87.56923076923077\n",
      "\tBatch 23 of 38 training acc 73.49199835863767 val acc 72.98461538461538\n",
      "\tBatch 24 of 38 training acc 81.10381616741897 val acc 78.76923076923077\n",
      "\tBatch 25 of 38 training acc 88.16167418957734 val acc 87.50769230769231\n",
      "\tBatch 26 of 38 training acc 85.59704554780467 val acc 85.35384615384616\n",
      "\tBatch 27 of 38 training acc 89.45424702503078 val acc 88.43076923076923\n",
      "\tBatch 28 of 38 training acc 85.16618793598687 val acc 84.73846153846154\n",
      "\tBatch 29 of 38 training acc 89.33114485022568 val acc 88.0\n",
      "\tBatch 30 of 38 training acc 74.84612228149365 val acc 74.21538461538462\n",
      "\tBatch 31 of 38 training acc 74.02544111612639 val acc 71.63076923076923\n",
      "\tBatch 32 of 38 training acc 70.18875666803447 val acc 70.09230769230768\n",
      "\tBatch 33 of 38 training acc 76.83627410750923 val acc 75.13846153846154\n",
      "\tBatch 34 of 38 training acc 84.42757488715634 val acc 83.75384615384615\n",
      "\tBatch 35 of 38 training acc 88.75666803446862 val acc 87.2\n",
      "\tBatch 36 of 38 training acc 88.40787853918752 val acc 87.87692307692308\n",
      "\tBatch 37 of 38 training acc 89.29011079195732 val acc 88.86153846153846\n",
      "epoch 6\n",
      "\tBatch 0 of 38 training acc 90.0902749281904 val acc 89.60000000000001\n",
      "\tBatch 1 of 38 training acc 89.9671727533853 val acc 89.53846153846153\n",
      "\tBatch 2 of 38 training acc 86.17152236356176 val acc 86.09230769230768\n",
      "\tBatch 3 of 38 training acc 81.22691834222404 val acc 78.76923076923077\n",
      "\tBatch 4 of 38 training acc 86.80755026672138 val acc 86.03076923076924\n",
      "\tBatch 5 of 38 training acc 89.7620024620435 val acc 88.67692307692307\n",
      "\tBatch 6 of 38 training acc 87.25892490767338 val acc 86.33846153846154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 7 of 38 training acc 90.21337710299548 val acc 89.78461538461538\n",
      "\tBatch 8 of 38 training acc 82.29380385720148 val acc 82.46153846153847\n",
      "\tBatch 9 of 38 training acc 89.02338941321297 val acc 87.2\n",
      "\tBatch 10 of 38 training acc 91.21871153057037 val acc 90.64615384615384\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "reg_const = 0.05\n",
    "\n",
    "svm_MR = SVM(n_class_MR, lr, n_epochs, reg_const)\n",
    "svm_MR.train(X_train_MR, y_train_MR, X_val_MR, y_val_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 91.218712\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_MR.predict(X_train_MR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_svm, y_train_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SVM on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 90.646154\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_MR.predict(X_val_MR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_svm, y_val_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test SVM on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 90.523077\n"
     ]
    }
   ],
   "source": [
    "pred_svm = svm_MR.predict(X_test_MR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_svm, y_test_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Classifier (with SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, you will train a Softmax classifier. This classifier consists of a linear function of the input data followed by a softmax function which outputs a vector of dimension C (number of classes) for each data point. Each entry of the softmax output vector corresponds to a confidence in one of the C classes, and like a probability distribution, the entries of the output vector sum to 1. We use a cross-entropy loss on this sotmax output to train the model. \n",
    "\n",
    "Check the following link as an additional resource on softmax classification: http://cs231n.github.io/linear-classify/#softmax\n",
    "\n",
    "Once again we will train the classifier with SGD. This means you need to compute the gradients of the softmax cross-entropy loss function according to the weights and update the weights using this gradient. Check the following link to help with implementing the gradient updates: https://deepnotes.io/softmax-crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax classifier has 3 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - As above, this controls how much the model weights are updated with respect to their gradient.\n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Regularization constant** - Hyperparameter to determine the strength of regularization. In this case, we minimize the L2 norm of the model weights as regularization, so the regularization constant is a coefficient on the L2 norm in the combined cross-entropy and regularization objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement a softmax classifier using SGD in the **models/softmax.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Softmax classifier class \n",
    "- The train function of the Softmax class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Softmax model.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self, n_class: int, lr: float, epochs: int, reg_const: float):\n",
    "        \"\"\"Initialize a new classifier.\n",
    "\n",
    "        Parameters:\n",
    "            n_class: the number of classes\n",
    "            lr: the learning rate\n",
    "            epochs: the number of epochs to train for\n",
    "            reg_const: the regularization constant\n",
    "        \"\"\"\n",
    "        self.w = None  # TODO: change this\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.reg_const = reg_const\n",
    "        self.n_class = n_class\n",
    "\n",
    "    def calc_gradient(self, X_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate gradient of the softmax loss.\n",
    "\n",
    "        Inputs have dimension D, there are C classes, and we operate on\n",
    "        mini-batches of N examples.\n",
    "\n",
    "        Parameters:\n",
    "            X_train: a numpy array of shape (N, D) containing a mini-batch\n",
    "                of data\n",
    "            y_train: a numpy array of shape (N,) containing training labels;\n",
    "                y[i] = c means that X[i] has label c, where 0 <= c < C\n",
    "\n",
    "        Returns:\n",
    "            gradient with respect to weights w; an array of same shape as w\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "\n",
    "        N,D = X_train.shape\n",
    "        grad_w = np.zeros((self.n_class,D))\n",
    "        \n",
    "        scores = softmax((self.w@X_train.T).T,axis = 1)\n",
    "        for i in range(N): # for each of the data\n",
    "            for j in range(self.n_class):\n",
    "                if j == y_train[i]:\n",
    "                    grad_w[j] += (scores[i][j] - 1)*X_train[i]\n",
    "                else:\n",
    "                    grad_w[j] += scores[i][j]*X_train[i]\n",
    "        return grad_w\n",
    "    \n",
    "        \n",
    "\n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray):\n",
    "        \"\"\"Train the classifier.\n",
    "\n",
    "        Hint: operate on mini-batches of data for SGD.\n",
    "\n",
    "        Parameters:\n",
    "            X_train: a numpy array of shape (N, D) containing training data;\n",
    "                N examples with D dimensions\n",
    "            y_train: a numpy array of shape (N,) containing training labels\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "                # TODO: implement me\n",
    "        BATCH_SIZE = 128\n",
    "        \n",
    "        # start with random weights\n",
    "        random.seed(666)\n",
    "        b_up = np.min(X_train)\n",
    "        b_low = np.max(X_train)\n",
    "        self.w = np.array([[random.uniform(b_low,b_up) for j in range(X_train.shape[1])] for i in range(self.n_class)])\n",
    "        \n",
    "        N,D = X_train.shape\n",
    "        it = N//BATCH_SIZE\n",
    "        \n",
    "        pred_svm_t = self.predict(X_train)\n",
    "        t_acc = self.get_acc(pred_svm_t, y_train)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"epoch\",epoch)\n",
    "            for i in range(N//BATCH_SIZE): # feed in training data batch-wise\n",
    "                    \n",
    "                X_train_batch = X_train[BATCH_SIZE*i:BATCH_SIZE*(i+1)]\n",
    "                y_train_batch = y_train[BATCH_SIZE*i:BATCH_SIZE*(i+1)]\n",
    "        \n",
    "                grad_w = self.calc_gradient(X_train_batch, y_train_batch)\n",
    "\n",
    "                for c in range(len(self.w)):\n",
    "                    self.w[c] = self.w[c] - self.lr*grad_w[c]\n",
    "#                 return\n",
    "            \n",
    "                ret = self.predict(X_train)\n",
    "                t_cur_acc = self.get_acc(ret, y_train)\n",
    "                pred_svm_v = self.predict(X_val)\n",
    "                cur_v_acc = self.get_acc(pred_svm_v, y_val)\n",
    "                if i%1 == 0:\n",
    "                    print(\"\\tBatch\",i,\"of\",it,\"training acc\",t_cur_acc,\"val acc\",cur_v_acc)\n",
    "                    \n",
    "                # early stop\n",
    "                if cur_v_acc >= 90: # found 83\n",
    "                        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_acc(self, pred, y_test):\n",
    "        return np.sum(y_test == pred) / len(y_test) * 100\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use the trained weights to predict labels for test data points.\n",
    "\n",
    "        Parameters:\n",
    "            X_test: a numpy array of shape (N, D) containing testing data;\n",
    "                N examples with D dimensions\n",
    "\n",
    "        Returns:\n",
    "            predicted labels for the data in X_test; a 1-dimensional array of\n",
    "                length N, where each element is an integer giving the predicted\n",
    "                class.\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "        ret = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            scores = np.dot(self.w, X_test[i])\n",
    "#             print(scores)\n",
    "            max_score = float(\"-inf\")\n",
    "            max_class = -1\n",
    "            for j in range(len(scores)):\n",
    "                if scores[j] > max_score:\n",
    "                    max_score = scores[j]\n",
    "                    max_class = j\n",
    "            ret.append(max_class)\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\tBatch 0 of 390 training acc 42.918 val acc 42.89\n",
      "\tBatch 1 of 390 training acc 50.334 val acc 50.370000000000005\n",
      "\tBatch 2 of 390 training acc 54.790000000000006 val acc 54.53\n",
      "\tBatch 3 of 390 training acc 56.716 val acc 56.58\n",
      "\tBatch 4 of 390 training acc 59.5 val acc 58.160000000000004\n",
      "\tBatch 5 of 390 training acc 63.376 val acc 62.81\n",
      "\tBatch 6 of 390 training acc 68.95599999999999 val acc 68.89\n",
      "\tBatch 7 of 390 training acc 68.49199999999999 val acc 68.44\n",
      "\tBatch 8 of 390 training acc 71.718 val acc 71.32\n",
      "\tBatch 9 of 390 training acc 68.274 val acc 67.25999999999999\n",
      "\tBatch 10 of 390 training acc 65.56 val acc 65.77\n",
      "\tBatch 11 of 390 training acc 61.842 val acc 61.47\n",
      "\tBatch 12 of 390 training acc 65.95400000000001 val acc 65.56\n",
      "\tBatch 13 of 390 training acc 62.49400000000001 val acc 62.11\n",
      "\tBatch 14 of 390 training acc 69.85 val acc 69.59\n",
      "\tBatch 15 of 390 training acc 61.022 val acc 60.38\n",
      "\tBatch 16 of 390 training acc 65.172 val acc 64.1\n",
      "\tBatch 17 of 390 training acc 72.762 val acc 71.89\n",
      "\tBatch 18 of 390 training acc 71.598 val acc 71.17\n",
      "\tBatch 19 of 390 training acc 60.894000000000005 val acc 61.339999999999996\n",
      "\tBatch 20 of 390 training acc 61.754 val acc 60.72\n",
      "\tBatch 21 of 390 training acc 67.714 val acc 67.84\n",
      "\tBatch 22 of 390 training acc 66.788 val acc 65.16999999999999\n",
      "\tBatch 23 of 390 training acc 65.864 val acc 65.67\n",
      "\tBatch 24 of 390 training acc 74.614 val acc 74.4\n",
      "\tBatch 25 of 390 training acc 75.298 val acc 74.45\n",
      "\tBatch 26 of 390 training acc 74.53999999999999 val acc 73.41\n",
      "\tBatch 27 of 390 training acc 72.658 val acc 72.1\n",
      "\tBatch 28 of 390 training acc 68.226 val acc 67.30000000000001\n",
      "\tBatch 29 of 390 training acc 69.574 val acc 68.22\n",
      "\tBatch 30 of 390 training acc 71.702 val acc 71.58\n",
      "\tBatch 31 of 390 training acc 68.842 val acc 68.57\n",
      "\tBatch 32 of 390 training acc 71.352 val acc 70.37\n",
      "\tBatch 33 of 390 training acc 75.136 val acc 74.21\n",
      "\tBatch 34 of 390 training acc 74.164 val acc 73.42999999999999\n",
      "\tBatch 35 of 390 training acc 75.936 val acc 74.72999999999999\n",
      "\tBatch 36 of 390 training acc 78.508 val acc 77.9\n",
      "\tBatch 37 of 390 training acc 77.378 val acc 76.66\n",
      "\tBatch 38 of 390 training acc 72.26599999999999 val acc 71.39\n",
      "\tBatch 39 of 390 training acc 75.73 val acc 75.03\n",
      "\tBatch 40 of 390 training acc 69.718 val acc 68.91000000000001\n",
      "\tBatch 41 of 390 training acc 57.804 val acc 57.95\n",
      "\tBatch 42 of 390 training acc 69.586 val acc 69.24\n",
      "\tBatch 43 of 390 training acc 71.98400000000001 val acc 71.46000000000001\n",
      "\tBatch 44 of 390 training acc 71.636 val acc 70.77\n",
      "\tBatch 45 of 390 training acc 75.776 val acc 75.53999999999999\n",
      "\tBatch 46 of 390 training acc 69.366 val acc 68.97999999999999\n",
      "\tBatch 47 of 390 training acc 70.256 val acc 69.56\n",
      "\tBatch 48 of 390 training acc 77.44 val acc 76.8\n",
      "\tBatch 49 of 390 training acc 77.13 val acc 76.67\n",
      "\tBatch 50 of 390 training acc 72.032 val acc 71.43\n",
      "\tBatch 51 of 390 training acc 70.81 val acc 70.59\n",
      "\tBatch 52 of 390 training acc 66.082 val acc 66.09\n",
      "\tBatch 53 of 390 training acc 73.938 val acc 73.42999999999999\n",
      "\tBatch 54 of 390 training acc 76.424 val acc 75.92\n",
      "\tBatch 55 of 390 training acc 80.266 val acc 79.67\n",
      "\tBatch 56 of 390 training acc 71.96000000000001 val acc 71.44\n",
      "\tBatch 57 of 390 training acc 69.572 val acc 68.58999999999999\n",
      "\tBatch 58 of 390 training acc 78.166 val acc 77.39\n",
      "\tBatch 59 of 390 training acc 77.554 val acc 77.09\n",
      "\tBatch 60 of 390 training acc 75.846 val acc 75.32\n",
      "\tBatch 61 of 390 training acc 72.934 val acc 72.00999999999999\n",
      "\tBatch 62 of 390 training acc 73.64 val acc 73.2\n",
      "\tBatch 63 of 390 training acc 78.63799999999999 val acc 78.14999999999999\n",
      "\tBatch 64 of 390 training acc 75.022 val acc 74.37\n",
      "\tBatch 65 of 390 training acc 77.548 val acc 77.41\n",
      "\tBatch 66 of 390 training acc 79.25 val acc 78.58000000000001\n",
      "\tBatch 67 of 390 training acc 76.366 val acc 76.05\n",
      "\tBatch 68 of 390 training acc 75.91799999999999 val acc 75.59\n",
      "\tBatch 69 of 390 training acc 74.036 val acc 73.28\n",
      "\tBatch 70 of 390 training acc 75.13 val acc 74.41\n",
      "\tBatch 71 of 390 training acc 79.17 val acc 78.77\n",
      "\tBatch 72 of 390 training acc 78.68 val acc 78.17\n",
      "\tBatch 73 of 390 training acc 77.75999999999999 val acc 76.92\n",
      "\tBatch 74 of 390 training acc 71.99600000000001 val acc 71.02000000000001\n",
      "\tBatch 75 of 390 training acc 65.358 val acc 64.51\n",
      "\tBatch 76 of 390 training acc 72.336 val acc 72.39\n",
      "\tBatch 77 of 390 training acc 74.888 val acc 73.99\n",
      "\tBatch 78 of 390 training acc 79.19800000000001 val acc 78.42\n",
      "\tBatch 79 of 390 training acc 80.498 val acc 79.67\n",
      "\tBatch 80 of 390 training acc 80.208 val acc 79.61\n",
      "\tBatch 81 of 390 training acc 80.068 val acc 79.52\n",
      "\tBatch 82 of 390 training acc 80.22399999999999 val acc 79.25\n",
      "\tBatch 83 of 390 training acc 79.88 val acc 79.03999999999999\n",
      "\tBatch 84 of 390 training acc 76.68199999999999 val acc 75.97\n",
      "\tBatch 85 of 390 training acc 79.074 val acc 78.5\n",
      "\tBatch 86 of 390 training acc 73.81400000000001 val acc 72.46000000000001\n",
      "\tBatch 87 of 390 training acc 69.502 val acc 68.85\n",
      "\tBatch 88 of 390 training acc 77.286 val acc 76.14\n",
      "\tBatch 89 of 390 training acc 73.032 val acc 72.36\n",
      "\tBatch 90 of 390 training acc 79.036 val acc 78.55\n",
      "\tBatch 91 of 390 training acc 72.418 val acc 71.08\n",
      "\tBatch 92 of 390 training acc 66.646 val acc 66.13\n",
      "\tBatch 93 of 390 training acc 64.67 val acc 63.849999999999994\n",
      "\tBatch 94 of 390 training acc 68.634 val acc 67.97\n",
      "\tBatch 95 of 390 training acc 72.562 val acc 72.44\n",
      "\tBatch 96 of 390 training acc 70.664 val acc 70.03\n",
      "\tBatch 97 of 390 training acc 77.736 val acc 77.41\n",
      "\tBatch 98 of 390 training acc 78.664 val acc 77.86\n",
      "\tBatch 99 of 390 training acc 75.25 val acc 74.76\n",
      "\tBatch 100 of 390 training acc 78.986 val acc 78.75999999999999\n",
      "\tBatch 101 of 390 training acc 78.774 val acc 78.13\n",
      "\tBatch 102 of 390 training acc 81.262 val acc 80.57\n",
      "\tBatch 103 of 390 training acc 79.54 val acc 78.77\n",
      "\tBatch 104 of 390 training acc 71.37599999999999 val acc 70.78999999999999\n",
      "\tBatch 105 of 390 training acc 80.61 val acc 79.47\n",
      "\tBatch 106 of 390 training acc 80.716 val acc 80.01\n",
      "\tBatch 107 of 390 training acc 78.644 val acc 77.85\n",
      "\tBatch 108 of 390 training acc 76.568 val acc 76.03\n",
      "\tBatch 109 of 390 training acc 76.38000000000001 val acc 76.13\n",
      "\tBatch 110 of 390 training acc 75.29 val acc 75.13\n",
      "\tBatch 111 of 390 training acc 70.89999999999999 val acc 70.12\n",
      "\tBatch 112 of 390 training acc 71.41999999999999 val acc 71.67999999999999\n",
      "\tBatch 113 of 390 training acc 76.172 val acc 75.59\n",
      "\tBatch 114 of 390 training acc 74.06 val acc 73.72\n",
      "\tBatch 115 of 390 training acc 76.578 val acc 75.88000000000001\n",
      "\tBatch 116 of 390 training acc 79.34 val acc 78.77\n",
      "\tBatch 117 of 390 training acc 79.362 val acc 78.45\n",
      "\tBatch 118 of 390 training acc 81.124 val acc 80.86\n",
      "\tBatch 119 of 390 training acc 78.244 val acc 77.25\n",
      "\tBatch 120 of 390 training acc 76.444 val acc 75.92\n",
      "\tBatch 121 of 390 training acc 73.202 val acc 72.81\n",
      "\tBatch 122 of 390 training acc 80.962 val acc 80.12\n",
      "\tBatch 123 of 390 training acc 81.962 val acc 81.31\n",
      "\tBatch 124 of 390 training acc 77.88000000000001 val acc 77.66999999999999\n",
      "\tBatch 125 of 390 training acc 78.758 val acc 77.94\n",
      "\tBatch 126 of 390 training acc 80.714 val acc 80.11\n",
      "\tBatch 127 of 390 training acc 80.778 val acc 79.86\n",
      "\tBatch 128 of 390 training acc 80.382 val acc 79.62\n",
      "\tBatch 129 of 390 training acc 77.412 val acc 76.95\n",
      "\tBatch 130 of 390 training acc 76.322 val acc 75.88000000000001\n",
      "\tBatch 131 of 390 training acc 79.582 val acc 79.10000000000001\n",
      "\tBatch 132 of 390 training acc 75.008 val acc 74.28\n",
      "\tBatch 133 of 390 training acc 78.66199999999999 val acc 78.38000000000001\n",
      "\tBatch 134 of 390 training acc 79.906 val acc 79.44\n",
      "\tBatch 135 of 390 training acc 74.62 val acc 74.33999999999999\n",
      "\tBatch 136 of 390 training acc 71.932 val acc 72.03\n",
      "\tBatch 137 of 390 training acc 71.67999999999999 val acc 70.87\n",
      "\tBatch 138 of 390 training acc 77.57 val acc 77.64999999999999\n",
      "\tBatch 139 of 390 training acc 75.022 val acc 74.52\n",
      "\tBatch 140 of 390 training acc 74.664 val acc 74.26\n",
      "\tBatch 141 of 390 training acc 80.074 val acc 79.66\n",
      "\tBatch 142 of 390 training acc 80.268 val acc 79.82000000000001\n",
      "\tBatch 143 of 390 training acc 80.626 val acc 79.96\n",
      "\tBatch 144 of 390 training acc 78.604 val acc 78.3\n",
      "\tBatch 145 of 390 training acc 72.752 val acc 71.89\n",
      "\tBatch 146 of 390 training acc 71.15 val acc 70.89999999999999\n",
      "\tBatch 147 of 390 training acc 73.47200000000001 val acc 72.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 148 of 390 training acc 75.53999999999999 val acc 74.94\n",
      "\tBatch 149 of 390 training acc 74.388 val acc 73.83999999999999\n",
      "\tBatch 150 of 390 training acc 79.82000000000001 val acc 79.67999999999999\n",
      "\tBatch 151 of 390 training acc 79.022 val acc 78.67\n",
      "\tBatch 152 of 390 training acc 73.698 val acc 73.3\n",
      "\tBatch 153 of 390 training acc 75.888 val acc 75.7\n",
      "\tBatch 154 of 390 training acc 78.12 val acc 77.49000000000001\n",
      "\tBatch 155 of 390 training acc 77.41 val acc 77.05\n",
      "\tBatch 156 of 390 training acc 75.21600000000001 val acc 74.19\n",
      "\tBatch 157 of 390 training acc 77.95 val acc 77.42999999999999\n",
      "\tBatch 158 of 390 training acc 75.76 val acc 75.22\n",
      "\tBatch 159 of 390 training acc 77.58 val acc 77.37\n",
      "\tBatch 160 of 390 training acc 75.726 val acc 74.6\n",
      "\tBatch 161 of 390 training acc 74.966 val acc 74.55000000000001\n",
      "\tBatch 162 of 390 training acc 71.936 val acc 70.89\n",
      "\tBatch 163 of 390 training acc 74.05199999999999 val acc 73.75\n",
      "\tBatch 164 of 390 training acc 81.33200000000001 val acc 80.66\n",
      "\tBatch 165 of 390 training acc 81.136 val acc 80.12\n",
      "\tBatch 166 of 390 training acc 73.98400000000001 val acc 73.22999999999999\n",
      "\tBatch 167 of 390 training acc 65.084 val acc 64.61\n",
      "\tBatch 168 of 390 training acc 80.2 val acc 79.92\n",
      "\tBatch 169 of 390 training acc 76.52600000000001 val acc 75.66000000000001\n",
      "\tBatch 170 of 390 training acc 75.348 val acc 75.13\n",
      "\tBatch 171 of 390 training acc 80.25999999999999 val acc 79.73\n",
      "\tBatch 172 of 390 training acc 79.328 val acc 79.10000000000001\n",
      "\tBatch 173 of 390 training acc 78.62 val acc 78.0\n",
      "\tBatch 174 of 390 training acc 75.214 val acc 74.35000000000001\n",
      "\tBatch 175 of 390 training acc 78.566 val acc 77.98\n",
      "\tBatch 176 of 390 training acc 74.746 val acc 73.8\n",
      "\tBatch 177 of 390 training acc 77.018 val acc 76.33\n",
      "\tBatch 178 of 390 training acc 73.302 val acc 72.50999999999999\n",
      "\tBatch 179 of 390 training acc 66.348 val acc 65.95\n",
      "\tBatch 180 of 390 training acc 73.214 val acc 72.66\n",
      "\tBatch 181 of 390 training acc 74.676 val acc 74.21\n",
      "\tBatch 182 of 390 training acc 66.282 val acc 65.84\n",
      "\tBatch 183 of 390 training acc 78.378 val acc 77.42999999999999\n",
      "\tBatch 184 of 390 training acc 80.53399999999999 val acc 80.08\n",
      "\tBatch 185 of 390 training acc 77.464 val acc 76.74\n",
      "\tBatch 186 of 390 training acc 81.21199999999999 val acc 80.54\n",
      "\tBatch 187 of 390 training acc 81.028 val acc 80.45\n",
      "\tBatch 188 of 390 training acc 81.378 val acc 80.85\n",
      "\tBatch 189 of 390 training acc 81.114 val acc 80.28\n",
      "\tBatch 190 of 390 training acc 77.778 val acc 76.75\n",
      "\tBatch 191 of 390 training acc 71.87599999999999 val acc 71.7\n",
      "\tBatch 192 of 390 training acc 79.62 val acc 78.92\n",
      "\tBatch 193 of 390 training acc 80.60199999999999 val acc 79.69000000000001\n",
      "\tBatch 194 of 390 training acc 79.986 val acc 79.25999999999999\n",
      "\tBatch 195 of 390 training acc 77.986 val acc 77.27000000000001\n",
      "\tBatch 196 of 390 training acc 78.656 val acc 78.23\n",
      "\tBatch 197 of 390 training acc 81.07600000000001 val acc 80.34\n",
      "\tBatch 198 of 390 training acc 81.138 val acc 80.39\n",
      "\tBatch 199 of 390 training acc 80.228 val acc 79.34\n",
      "\tBatch 200 of 390 training acc 79.128 val acc 78.21000000000001\n",
      "\tBatch 201 of 390 training acc 78.39399999999999 val acc 77.82\n",
      "\tBatch 202 of 390 training acc 75.322 val acc 74.21\n",
      "\tBatch 203 of 390 training acc 76.068 val acc 75.21\n",
      "\tBatch 204 of 390 training acc 79.32000000000001 val acc 78.62\n",
      "\tBatch 205 of 390 training acc 77.988 val acc 77.19\n",
      "\tBatch 206 of 390 training acc 70.75399999999999 val acc 70.26\n",
      "\tBatch 207 of 390 training acc 77.77199999999999 val acc 77.06\n",
      "\tBatch 208 of 390 training acc 82.38799999999999 val acc 81.49\n",
      "\tBatch 209 of 390 training acc 81.496 val acc 80.58\n",
      "\tBatch 210 of 390 training acc 82.43599999999999 val acc 81.36\n",
      "\tBatch 211 of 390 training acc 80.496 val acc 79.72\n",
      "\tBatch 212 of 390 training acc 69.938 val acc 69.28\n",
      "\tBatch 213 of 390 training acc 71.75200000000001 val acc 71.67999999999999\n",
      "\tBatch 214 of 390 training acc 66.24 val acc 65.33\n",
      "\tBatch 215 of 390 training acc 74.778 val acc 74.15\n",
      "\tBatch 216 of 390 training acc 70.786 val acc 69.65\n",
      "\tBatch 217 of 390 training acc 80.62 val acc 79.86999999999999\n",
      "\tBatch 218 of 390 training acc 76.088 val acc 75.35\n",
      "\tBatch 219 of 390 training acc 72.626 val acc 72.13000000000001\n",
      "\tBatch 220 of 390 training acc 74.058 val acc 73.34\n",
      "\tBatch 221 of 390 training acc 80.32000000000001 val acc 79.22\n",
      "\tBatch 222 of 390 training acc 82.26400000000001 val acc 80.91000000000001\n",
      "\tBatch 223 of 390 training acc 80.838 val acc 79.71000000000001\n",
      "\tBatch 224 of 390 training acc 77.694 val acc 76.51\n",
      "\tBatch 225 of 390 training acc 79.29 val acc 78.35\n",
      "\tBatch 226 of 390 training acc 80.598 val acc 79.94\n",
      "\tBatch 227 of 390 training acc 75.774 val acc 74.31\n",
      "\tBatch 228 of 390 training acc 77.886 val acc 77.01\n",
      "\tBatch 229 of 390 training acc 80.822 val acc 80.24\n",
      "\tBatch 230 of 390 training acc 78.97 val acc 78.32000000000001\n",
      "\tBatch 231 of 390 training acc 72.446 val acc 71.34\n",
      "\tBatch 232 of 390 training acc 79.28 val acc 78.53999999999999\n",
      "\tBatch 233 of 390 training acc 82.104 val acc 81.22\n",
      "\tBatch 234 of 390 training acc 81.864 val acc 81.22\n",
      "\tBatch 235 of 390 training acc 79.952 val acc 79.29\n",
      "\tBatch 236 of 390 training acc 81.024 val acc 80.17\n",
      "\tBatch 237 of 390 training acc 77.31400000000001 val acc 76.69\n",
      "\tBatch 238 of 390 training acc 76.09 val acc 75.59\n",
      "\tBatch 239 of 390 training acc 80.01 val acc 79.35\n",
      "\tBatch 240 of 390 training acc 78.28 val acc 77.66\n",
      "\tBatch 241 of 390 training acc 75.13 val acc 74.44\n",
      "\tBatch 242 of 390 training acc 73.694 val acc 73.02\n",
      "\tBatch 243 of 390 training acc 76.706 val acc 75.69\n",
      "\tBatch 244 of 390 training acc 77.31 val acc 76.74\n",
      "\tBatch 245 of 390 training acc 78.94 val acc 78.85\n",
      "\tBatch 246 of 390 training acc 79.046 val acc 78.34\n",
      "\tBatch 247 of 390 training acc 77.106 val acc 76.3\n",
      "\tBatch 248 of 390 training acc 76.53999999999999 val acc 75.68\n",
      "\tBatch 249 of 390 training acc 75.058 val acc 74.68\n",
      "\tBatch 250 of 390 training acc 77.648 val acc 77.13\n",
      "\tBatch 251 of 390 training acc 80.04 val acc 79.09\n",
      "\tBatch 252 of 390 training acc 83.268 val acc 82.17\n",
      "\tBatch 253 of 390 training acc 76.676 val acc 75.97\n",
      "\tBatch 254 of 390 training acc 73.804 val acc 72.87\n",
      "\tBatch 255 of 390 training acc 75.292 val acc 74.44\n",
      "\tBatch 256 of 390 training acc 78.16199999999999 val acc 77.58\n",
      "\tBatch 257 of 390 training acc 79.204 val acc 77.88000000000001\n",
      "\tBatch 258 of 390 training acc 79.596 val acc 78.8\n",
      "\tBatch 259 of 390 training acc 79.80000000000001 val acc 79.02\n",
      "\tBatch 260 of 390 training acc 83.582 val acc 82.57\n",
      "\tBatch 261 of 390 training acc 80.798 val acc 79.82000000000001\n",
      "\tBatch 262 of 390 training acc 81.048 val acc 79.79\n",
      "\tBatch 263 of 390 training acc 79.93 val acc 78.73\n",
      "\tBatch 264 of 390 training acc 80.762 val acc 80.07\n",
      "\tBatch 265 of 390 training acc 76.222 val acc 75.32\n",
      "\tBatch 266 of 390 training acc 75.67399999999999 val acc 75.26\n",
      "\tBatch 267 of 390 training acc 76.156 val acc 75.6\n",
      "\tBatch 268 of 390 training acc 70.98400000000001 val acc 70.62\n",
      "\tBatch 269 of 390 training acc 73.824 val acc 72.96000000000001\n",
      "\tBatch 270 of 390 training acc 81.732 val acc 81.06\n",
      "\tBatch 271 of 390 training acc 80.202 val acc 79.11\n",
      "\tBatch 272 of 390 training acc 81.148 val acc 80.28999999999999\n",
      "\tBatch 273 of 390 training acc 74.772 val acc 73.95\n",
      "\tBatch 274 of 390 training acc 79.282 val acc 78.64999999999999\n",
      "\tBatch 275 of 390 training acc 79.84 val acc 78.68\n",
      "\tBatch 276 of 390 training acc 82.61800000000001 val acc 82.07\n",
      "\tBatch 277 of 390 training acc 79.47 val acc 78.49000000000001\n",
      "\tBatch 278 of 390 training acc 81.742 val acc 80.46\n",
      "\tBatch 279 of 390 training acc 81.584 val acc 80.86\n",
      "\tBatch 280 of 390 training acc 77.03999999999999 val acc 76.73\n",
      "\tBatch 281 of 390 training acc 76.73 val acc 76.06\n",
      "\tBatch 282 of 390 training acc 75.386 val acc 75.09\n",
      "\tBatch 283 of 390 training acc 78.57 val acc 77.82\n",
      "\tBatch 284 of 390 training acc 73.154 val acc 72.32\n",
      "\tBatch 285 of 390 training acc 65.25999999999999 val acc 64.27000000000001\n",
      "\tBatch 286 of 390 training acc 65.88000000000001 val acc 65.45\n",
      "\tBatch 287 of 390 training acc 81.272 val acc 80.39\n",
      "\tBatch 288 of 390 training acc 82.404 val acc 81.38\n",
      "\tBatch 289 of 390 training acc 82.296 val acc 81.2\n",
      "\tBatch 290 of 390 training acc 79.738 val acc 79.13\n",
      "\tBatch 291 of 390 training acc 83.298 val acc 82.5\n",
      "\tBatch 292 of 390 training acc 81.958 val acc 80.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 293 of 390 training acc 80.644 val acc 79.97999999999999\n",
      "\tBatch 294 of 390 training acc 78.228 val acc 77.24\n",
      "\tBatch 295 of 390 training acc 82.35 val acc 81.38\n",
      "\tBatch 296 of 390 training acc 80.522 val acc 79.63\n",
      "\tBatch 297 of 390 training acc 73.458 val acc 72.48\n",
      "\tBatch 298 of 390 training acc 77.27199999999999 val acc 76.64999999999999\n",
      "\tBatch 299 of 390 training acc 79.292 val acc 78.45\n",
      "\tBatch 300 of 390 training acc 79.252 val acc 78.59\n",
      "\tBatch 301 of 390 training acc 79.174 val acc 78.07\n",
      "\tBatch 302 of 390 training acc 83.204 val acc 82.44\n",
      "\tBatch 303 of 390 training acc 82.272 val acc 81.0\n",
      "\tBatch 304 of 390 training acc 80.11 val acc 78.97999999999999\n",
      "\tBatch 305 of 390 training acc 82.814 val acc 81.52000000000001\n",
      "\tBatch 306 of 390 training acc 77.678 val acc 76.52\n",
      "\tBatch 307 of 390 training acc 81.66799999999999 val acc 80.84\n",
      "\tBatch 308 of 390 training acc 80.182 val acc 79.36\n",
      "\tBatch 309 of 390 training acc 74.532 val acc 74.17\n",
      "\tBatch 310 of 390 training acc 73.13199999999999 val acc 72.39999999999999\n",
      "\tBatch 311 of 390 training acc 71.99 val acc 71.76\n",
      "\tBatch 312 of 390 training acc 78.756 val acc 77.68\n",
      "\tBatch 313 of 390 training acc 79.376 val acc 77.95\n",
      "\tBatch 314 of 390 training acc 74.586 val acc 73.76\n",
      "\tBatch 315 of 390 training acc 77.088 val acc 76.64\n",
      "\tBatch 316 of 390 training acc 73.422 val acc 72.5\n",
      "\tBatch 317 of 390 training acc 70.448 val acc 70.1\n",
      "\tBatch 318 of 390 training acc 70.838 val acc 69.83\n",
      "\tBatch 319 of 390 training acc 79.34400000000001 val acc 78.5\n",
      "\tBatch 320 of 390 training acc 77.956 val acc 76.98\n",
      "\tBatch 321 of 390 training acc 78.982 val acc 78.75999999999999\n",
      "\tBatch 322 of 390 training acc 75.72 val acc 74.53999999999999\n",
      "\tBatch 323 of 390 training acc 82.21000000000001 val acc 81.08\n",
      "\tBatch 324 of 390 training acc 82.48400000000001 val acc 81.35\n",
      "\tBatch 325 of 390 training acc 74.62 val acc 73.59\n",
      "\tBatch 326 of 390 training acc 78.854 val acc 78.27\n",
      "\tBatch 327 of 390 training acc 82.036 val acc 81.0\n",
      "\tBatch 328 of 390 training acc 78.73400000000001 val acc 77.81\n",
      "\tBatch 329 of 390 training acc 78.13799999999999 val acc 77.25999999999999\n",
      "\tBatch 330 of 390 training acc 80.472 val acc 79.99000000000001\n",
      "\tBatch 331 of 390 training acc 82.136 val acc 81.22\n",
      "\tBatch 332 of 390 training acc 83.026 val acc 81.89999999999999\n",
      "\tBatch 333 of 390 training acc 79.828 val acc 78.61\n",
      "\tBatch 334 of 390 training acc 76.82 val acc 76.01\n",
      "\tBatch 335 of 390 training acc 75.926 val acc 74.41\n",
      "\tBatch 336 of 390 training acc 75.44999999999999 val acc 74.89\n",
      "\tBatch 337 of 390 training acc 79.766 val acc 78.32000000000001\n",
      "\tBatch 338 of 390 training acc 80.182 val acc 79.16\n",
      "\tBatch 339 of 390 training acc 73.746 val acc 72.34\n",
      "\tBatch 340 of 390 training acc 77.322 val acc 76.95\n",
      "\tBatch 341 of 390 training acc 80.15 val acc 79.38\n",
      "\tBatch 342 of 390 training acc 80.594 val acc 79.60000000000001\n",
      "\tBatch 343 of 390 training acc 79.484 val acc 78.39\n",
      "\tBatch 344 of 390 training acc 80.398 val acc 78.89\n",
      "\tBatch 345 of 390 training acc 77.634 val acc 76.68\n",
      "\tBatch 346 of 390 training acc 72.398 val acc 71.3\n",
      "\tBatch 347 of 390 training acc 77.94 val acc 77.18\n",
      "\tBatch 348 of 390 training acc 79.276 val acc 78.36999999999999\n",
      "\tBatch 349 of 390 training acc 80.902 val acc 79.96\n",
      "\tBatch 350 of 390 training acc 76.972 val acc 75.68\n",
      "\tBatch 351 of 390 training acc 78.33200000000001 val acc 77.59\n",
      "\tBatch 352 of 390 training acc 78.294 val acc 77.44\n",
      "\tBatch 353 of 390 training acc 76.19 val acc 75.1\n",
      "\tBatch 354 of 390 training acc 72.2 val acc 71.96000000000001\n",
      "\tBatch 355 of 390 training acc 77.658 val acc 77.03\n",
      "\tBatch 356 of 390 training acc 76.006 val acc 74.69\n",
      "\tBatch 357 of 390 training acc 75.476 val acc 74.78\n",
      "\tBatch 358 of 390 training acc 81.404 val acc 80.33\n",
      "\tBatch 359 of 390 training acc 73.212 val acc 71.81\n",
      "\tBatch 360 of 390 training acc 80.904 val acc 80.01\n",
      "\tBatch 361 of 390 training acc 76.27000000000001 val acc 74.95\n",
      "\tBatch 362 of 390 training acc 78.85600000000001 val acc 77.57\n",
      "\tBatch 363 of 390 training acc 77.75800000000001 val acc 76.42\n",
      "\tBatch 364 of 390 training acc 79.84599999999999 val acc 78.97999999999999\n",
      "\tBatch 365 of 390 training acc 80.67 val acc 79.51\n",
      "\tBatch 366 of 390 training acc 82.66799999999999 val acc 81.85\n",
      "\tBatch 367 of 390 training acc 81.69999999999999 val acc 80.52\n",
      "\tBatch 368 of 390 training acc 82.138 val acc 81.15\n",
      "\tBatch 369 of 390 training acc 80.54400000000001 val acc 80.08\n",
      "\tBatch 370 of 390 training acc 81.984 val acc 81.01\n",
      "\tBatch 371 of 390 training acc 79.752 val acc 78.46\n",
      "\tBatch 372 of 390 training acc 76.57000000000001 val acc 75.74\n",
      "\tBatch 373 of 390 training acc 75.078 val acc 74.22999999999999\n",
      "\tBatch 374 of 390 training acc 80.554 val acc 79.08\n",
      "\tBatch 375 of 390 training acc 81.902 val acc 81.15\n",
      "\tBatch 376 of 390 training acc 83.42 val acc 82.52000000000001\n",
      "\tBatch 377 of 390 training acc 79.652 val acc 78.93\n",
      "\tBatch 378 of 390 training acc 79.422 val acc 78.63\n",
      "\tBatch 379 of 390 training acc 77.59 val acc 76.71\n",
      "\tBatch 380 of 390 training acc 79.23599999999999 val acc 78.56\n",
      "\tBatch 381 of 390 training acc 76.91799999999999 val acc 76.01\n",
      "\tBatch 382 of 390 training acc 76.408 val acc 75.14999999999999\n",
      "\tBatch 383 of 390 training acc 69.30199999999999 val acc 68.32000000000001\n",
      "\tBatch 384 of 390 training acc 79.178 val acc 78.41\n",
      "\tBatch 385 of 390 training acc 77.3 val acc 76.53999999999999\n",
      "\tBatch 386 of 390 training acc 77.00200000000001 val acc 76.44999999999999\n",
      "\tBatch 387 of 390 training acc 74.658 val acc 73.16\n",
      "\tBatch 388 of 390 training acc 81.06 val acc 79.77\n",
      "\tBatch 389 of 390 training acc 79.286 val acc 78.53\n",
      "epoch 1\n",
      "\tBatch 0 of 390 training acc 81.42 val acc 80.57\n",
      "\tBatch 1 of 390 training acc 81.652 val acc 81.0\n",
      "\tBatch 2 of 390 training acc 78.63799999999999 val acc 77.24\n",
      "\tBatch 3 of 390 training acc 81.298 val acc 80.02\n",
      "\tBatch 4 of 390 training acc 82.426 val acc 81.02000000000001\n",
      "\tBatch 5 of 390 training acc 82.99600000000001 val acc 81.82000000000001\n",
      "\tBatch 6 of 390 training acc 81.226 val acc 80.38\n",
      "\tBatch 7 of 390 training acc 74.08 val acc 72.65\n",
      "\tBatch 8 of 390 training acc 70.514 val acc 69.53\n",
      "\tBatch 9 of 390 training acc 76.778 val acc 76.35\n",
      "\tBatch 10 of 390 training acc 81.27799999999999 val acc 80.36999999999999\n",
      "\tBatch 11 of 390 training acc 81.308 val acc 80.87\n",
      "\tBatch 12 of 390 training acc 82.13000000000001 val acc 81.25\n",
      "\tBatch 13 of 390 training acc 76.4 val acc 75.2\n",
      "\tBatch 14 of 390 training acc 79.554 val acc 78.73\n",
      "\tBatch 15 of 390 training acc 73.69200000000001 val acc 72.41\n",
      "\tBatch 16 of 390 training acc 76.096 val acc 75.55\n",
      "\tBatch 17 of 390 training acc 79.254 val acc 79.16\n",
      "\tBatch 18 of 390 training acc 81.054 val acc 80.24\n",
      "\tBatch 19 of 390 training acc 82.64399999999999 val acc 81.78\n",
      "\tBatch 20 of 390 training acc 75.452 val acc 74.28\n",
      "\tBatch 21 of 390 training acc 73.55199999999999 val acc 73.33\n",
      "\tBatch 22 of 390 training acc 72.468 val acc 71.58\n",
      "\tBatch 23 of 390 training acc 74.702 val acc 74.52\n",
      "\tBatch 24 of 390 training acc 80.136 val acc 79.57\n",
      "\tBatch 25 of 390 training acc 81.71000000000001 val acc 80.49\n",
      "\tBatch 26 of 390 training acc 81.27600000000001 val acc 80.27\n",
      "\tBatch 27 of 390 training acc 78.88199999999999 val acc 77.69\n",
      "\tBatch 28 of 390 training acc 79.47999999999999 val acc 78.64\n",
      "\tBatch 29 of 390 training acc 79.32000000000001 val acc 78.38000000000001\n",
      "\tBatch 30 of 390 training acc 79.838 val acc 78.85\n",
      "\tBatch 31 of 390 training acc 80.85 val acc 79.94\n",
      "\tBatch 32 of 390 training acc 80.876 val acc 79.66\n",
      "\tBatch 33 of 390 training acc 78.18 val acc 76.96\n",
      "\tBatch 34 of 390 training acc 82.50800000000001 val acc 81.63\n",
      "\tBatch 35 of 390 training acc 81.692 val acc 80.54\n",
      "\tBatch 36 of 390 training acc 83.72 val acc 82.39999999999999\n",
      "\tBatch 37 of 390 training acc 83.346 val acc 81.98\n",
      "\tBatch 38 of 390 training acc 83.532 val acc 82.1\n",
      "\tBatch 39 of 390 training acc 82.03 val acc 80.73\n",
      "\tBatch 40 of 390 training acc 79.96 val acc 78.66\n",
      "\tBatch 41 of 390 training acc 71.17 val acc 70.85000000000001\n",
      "\tBatch 42 of 390 training acc 73.568 val acc 72.74000000000001\n",
      "\tBatch 43 of 390 training acc 75.978 val acc 75.31\n",
      "\tBatch 44 of 390 training acc 77.73400000000001 val acc 76.62\n",
      "\tBatch 45 of 390 training acc 80.034 val acc 79.38\n",
      "\tBatch 46 of 390 training acc 74.422 val acc 73.85000000000001\n",
      "\tBatch 47 of 390 training acc 72.886 val acc 72.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 48 of 390 training acc 80.38 val acc 79.21000000000001\n",
      "\tBatch 49 of 390 training acc 82.65599999999999 val acc 81.81\n",
      "\tBatch 50 of 390 training acc 78.61399999999999 val acc 77.01\n",
      "\tBatch 51 of 390 training acc 77.718 val acc 76.71\n",
      "\tBatch 52 of 390 training acc 76.16000000000001 val acc 75.68\n",
      "\tBatch 53 of 390 training acc 76.25800000000001 val acc 75.3\n",
      "\tBatch 54 of 390 training acc 75.484 val acc 74.82\n",
      "\tBatch 55 of 390 training acc 74.854 val acc 74.09\n",
      "\tBatch 56 of 390 training acc 78.24 val acc 77.18\n",
      "\tBatch 57 of 390 training acc 78.28 val acc 77.27000000000001\n",
      "\tBatch 58 of 390 training acc 78.264 val acc 77.36\n",
      "\tBatch 59 of 390 training acc 74.24199999999999 val acc 73.53\n",
      "\tBatch 60 of 390 training acc 75.054 val acc 74.22999999999999\n",
      "\tBatch 61 of 390 training acc 76.606 val acc 75.76\n",
      "\tBatch 62 of 390 training acc 78.604 val acc 77.66\n",
      "\tBatch 63 of 390 training acc 83.46000000000001 val acc 82.39999999999999\n",
      "\tBatch 64 of 390 training acc 79.566 val acc 78.96\n",
      "\tBatch 65 of 390 training acc 80.766 val acc 80.34\n",
      "\tBatch 66 of 390 training acc 80.56 val acc 79.99000000000001\n",
      "\tBatch 67 of 390 training acc 78.12599999999999 val acc 76.89\n",
      "\tBatch 68 of 390 training acc 77.432 val acc 76.79\n",
      "\tBatch 69 of 390 training acc 82.292 val acc 80.67999999999999\n",
      "\tBatch 70 of 390 training acc 80.582 val acc 79.56\n",
      "\tBatch 71 of 390 training acc 80.396 val acc 79.47\n",
      "\tBatch 72 of 390 training acc 84.19200000000001 val acc 82.74000000000001\n",
      "\tBatch 73 of 390 training acc 81.83200000000001 val acc 80.63\n",
      "\tBatch 74 of 390 training acc 71.936 val acc 71.32\n",
      "\tBatch 75 of 390 training acc 74.004 val acc 72.92\n",
      "\tBatch 76 of 390 training acc 77.908 val acc 76.7\n",
      "\tBatch 77 of 390 training acc 76.08200000000001 val acc 74.97\n",
      "\tBatch 78 of 390 training acc 80.872 val acc 79.54\n",
      "\tBatch 79 of 390 training acc 82.572 val acc 81.2\n",
      "\tBatch 80 of 390 training acc 79.468 val acc 78.21000000000001\n",
      "\tBatch 81 of 390 training acc 78.594 val acc 77.79\n",
      "\tBatch 82 of 390 training acc 81.64200000000001 val acc 80.86\n",
      "\tBatch 83 of 390 training acc 82.504 val acc 81.73\n",
      "\tBatch 84 of 390 training acc 81.848 val acc 80.82000000000001\n",
      "\tBatch 85 of 390 training acc 81.958 val acc 81.08999999999999\n",
      "\tBatch 86 of 390 training acc 80.36 val acc 79.71000000000001\n",
      "\tBatch 87 of 390 training acc 79.634 val acc 78.43\n",
      "\tBatch 88 of 390 training acc 80.33200000000001 val acc 79.41\n",
      "\tBatch 89 of 390 training acc 77.184 val acc 76.49000000000001\n",
      "\tBatch 90 of 390 training acc 80.934 val acc 80.02\n",
      "\tBatch 91 of 390 training acc 76.402 val acc 74.86\n",
      "\tBatch 92 of 390 training acc 68.34 val acc 68.42\n",
      "\tBatch 93 of 390 training acc 61.48400000000001 val acc 60.629999999999995\n",
      "\tBatch 94 of 390 training acc 72.672 val acc 71.92\n",
      "\tBatch 95 of 390 training acc 76.00200000000001 val acc 75.92\n",
      "\tBatch 96 of 390 training acc 73.054 val acc 72.88\n",
      "\tBatch 97 of 390 training acc 75.09599999999999 val acc 74.75\n",
      "\tBatch 98 of 390 training acc 80.774 val acc 79.53\n",
      "\tBatch 99 of 390 training acc 80.428 val acc 79.39\n",
      "\tBatch 100 of 390 training acc 82.446 val acc 81.52000000000001\n",
      "\tBatch 101 of 390 training acc 81.342 val acc 80.36\n",
      "\tBatch 102 of 390 training acc 83.464 val acc 82.44\n",
      "\tBatch 103 of 390 training acc 81.596 val acc 80.46\n",
      "\tBatch 104 of 390 training acc 79.14 val acc 77.96\n",
      "\tBatch 105 of 390 training acc 82.732 val acc 81.6\n",
      "\tBatch 106 of 390 training acc 81.164 val acc 80.25999999999999\n",
      "\tBatch 107 of 390 training acc 76.436 val acc 75.22\n",
      "\tBatch 108 of 390 training acc 81.47999999999999 val acc 80.57\n",
      "\tBatch 109 of 390 training acc 79.69800000000001 val acc 78.53\n",
      "\tBatch 110 of 390 training acc 81.28999999999999 val acc 80.57\n",
      "\tBatch 111 of 390 training acc 76.424 val acc 76.06\n",
      "\tBatch 112 of 390 training acc 80.728 val acc 80.07\n",
      "\tBatch 113 of 390 training acc 82.152 val acc 81.28\n",
      "\tBatch 114 of 390 training acc 81.88600000000001 val acc 81.21000000000001\n",
      "\tBatch 115 of 390 training acc 76.266 val acc 75.14999999999999\n",
      "\tBatch 116 of 390 training acc 82.284 val acc 81.61\n",
      "\tBatch 117 of 390 training acc 81.172 val acc 79.86\n",
      "\tBatch 118 of 390 training acc 82.708 val acc 82.0\n",
      "\tBatch 119 of 390 training acc 82.202 val acc 81.26\n",
      "\tBatch 120 of 390 training acc 81.87 val acc 80.76\n",
      "\tBatch 121 of 390 training acc 78.44200000000001 val acc 77.9\n",
      "\tBatch 122 of 390 training acc 79.892 val acc 78.66\n",
      "\tBatch 123 of 390 training acc 80.988 val acc 80.54\n",
      "\tBatch 124 of 390 training acc 78.97800000000001 val acc 78.08\n",
      "\tBatch 125 of 390 training acc 81.77 val acc 80.96\n",
      "\tBatch 126 of 390 training acc 76.63 val acc 75.72\n",
      "\tBatch 127 of 390 training acc 72.812 val acc 72.13000000000001\n",
      "\tBatch 128 of 390 training acc 74.122 val acc 73.44000000000001\n",
      "\tBatch 129 of 390 training acc 75.468 val acc 74.42999999999999\n",
      "\tBatch 130 of 390 training acc 82.56599999999999 val acc 81.84\n",
      "\tBatch 131 of 390 training acc 77.28399999999999 val acc 76.62\n",
      "\tBatch 132 of 390 training acc 72.782 val acc 72.26\n",
      "\tBatch 133 of 390 training acc 79.718 val acc 79.13\n",
      "\tBatch 134 of 390 training acc 81.692 val acc 80.88\n",
      "\tBatch 135 of 390 training acc 82.804 val acc 81.65\n",
      "\tBatch 136 of 390 training acc 81.27 val acc 80.28\n",
      "\tBatch 137 of 390 training acc 77.264 val acc 76.09\n",
      "\tBatch 138 of 390 training acc 79.28 val acc 78.11\n",
      "\tBatch 139 of 390 training acc 76.802 val acc 75.94\n",
      "\tBatch 140 of 390 training acc 74.24199999999999 val acc 73.65\n",
      "\tBatch 141 of 390 training acc 80.926 val acc 79.78\n",
      "\tBatch 142 of 390 training acc 80.944 val acc 79.79\n",
      "\tBatch 143 of 390 training acc 77.154 val acc 76.25999999999999\n",
      "\tBatch 144 of 390 training acc 78.754 val acc 78.10000000000001\n",
      "\tBatch 145 of 390 training acc 79.484 val acc 78.48\n",
      "\tBatch 146 of 390 training acc 81.324 val acc 80.25\n",
      "\tBatch 147 of 390 training acc 78.762 val acc 77.68\n",
      "\tBatch 148 of 390 training acc 73.502 val acc 72.37\n",
      "\tBatch 149 of 390 training acc 70.718 val acc 70.06\n",
      "\tBatch 150 of 390 training acc 79.728 val acc 79.38\n",
      "\tBatch 151 of 390 training acc 82.828 val acc 82.31\n",
      "\tBatch 152 of 390 training acc 80.514 val acc 79.75\n",
      "\tBatch 153 of 390 training acc 82.86200000000001 val acc 82.04\n",
      "\tBatch 154 of 390 training acc 81.818 val acc 80.89\n",
      "\tBatch 155 of 390 training acc 80.228 val acc 79.27\n",
      "\tBatch 156 of 390 training acc 81.158 val acc 79.82000000000001\n",
      "\tBatch 157 of 390 training acc 80.648 val acc 79.99000000000001\n",
      "\tBatch 158 of 390 training acc 82.582 val acc 81.42\n",
      "\tBatch 159 of 390 training acc 82.216 val acc 80.73\n",
      "\tBatch 160 of 390 training acc 74.202 val acc 73.00999999999999\n",
      "\tBatch 161 of 390 training acc 72.27 val acc 72.03\n",
      "\tBatch 162 of 390 training acc 76.37 val acc 75.29\n",
      "\tBatch 163 of 390 training acc 76.494 val acc 75.42999999999999\n",
      "\tBatch 164 of 390 training acc 76.126 val acc 75.28\n",
      "\tBatch 165 of 390 training acc 80.43400000000001 val acc 79.59\n",
      "\tBatch 166 of 390 training acc 76.652 val acc 75.89\n",
      "\tBatch 167 of 390 training acc 70.048 val acc 69.19\n",
      "\tBatch 168 of 390 training acc 80.128 val acc 79.16\n",
      "\tBatch 169 of 390 training acc 76.828 val acc 76.03\n",
      "\tBatch 170 of 390 training acc 77.776 val acc 76.98\n",
      "\tBatch 171 of 390 training acc 80.9 val acc 79.71000000000001\n",
      "\tBatch 172 of 390 training acc 80.56400000000001 val acc 79.91\n",
      "\tBatch 173 of 390 training acc 77.072 val acc 76.09\n",
      "\tBatch 174 of 390 training acc 82.274 val acc 81.27\n",
      "\tBatch 175 of 390 training acc 81.282 val acc 80.23\n",
      "\tBatch 176 of 390 training acc 75.318 val acc 74.42\n",
      "\tBatch 177 of 390 training acc 76.058 val acc 74.74\n",
      "\tBatch 178 of 390 training acc 77.96600000000001 val acc 77.2\n",
      "\tBatch 179 of 390 training acc 73.35000000000001 val acc 72.81\n",
      "\tBatch 180 of 390 training acc 78.62400000000001 val acc 77.92999999999999\n",
      "\tBatch 181 of 390 training acc 81.108 val acc 80.08\n",
      "\tBatch 182 of 390 training acc 75.154 val acc 74.14\n",
      "\tBatch 183 of 390 training acc 79.35600000000001 val acc 78.12\n",
      "\tBatch 184 of 390 training acc 77.31 val acc 76.19\n",
      "\tBatch 185 of 390 training acc 80.92399999999999 val acc 79.84\n",
      "\tBatch 186 of 390 training acc 83.67 val acc 82.55\n",
      "\tBatch 187 of 390 training acc 81.782 val acc 80.72\n",
      "\tBatch 188 of 390 training acc 80.278 val acc 79.5\n",
      "\tBatch 189 of 390 training acc 81.65400000000001 val acc 80.52\n",
      "\tBatch 190 of 390 training acc 72.992 val acc 71.7\n",
      "\tBatch 191 of 390 training acc 72.328 val acc 71.89999999999999\n",
      "\tBatch 192 of 390 training acc 82.288 val acc 81.34\n",
      "\tBatch 193 of 390 training acc 81.92399999999999 val acc 81.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 194 of 390 training acc 83.206 val acc 82.45\n",
      "\tBatch 195 of 390 training acc 81.626 val acc 80.63\n",
      "\tBatch 196 of 390 training acc 83.428 val acc 82.57\n",
      "\tBatch 197 of 390 training acc 82.428 val acc 81.17999999999999\n",
      "\tBatch 198 of 390 training acc 82.284 val acc 80.96\n",
      "\tBatch 199 of 390 training acc 74.574 val acc 74.14\n",
      "\tBatch 200 of 390 training acc 79.278 val acc 78.48\n",
      "\tBatch 201 of 390 training acc 74.09 val acc 73.38\n",
      "\tBatch 202 of 390 training acc 78.656 val acc 77.82\n",
      "\tBatch 203 of 390 training acc 81.95599999999999 val acc 81.28999999999999\n",
      "\tBatch 204 of 390 training acc 82.72800000000001 val acc 81.5\n",
      "\tBatch 205 of 390 training acc 82.16799999999999 val acc 81.16\n",
      "\tBatch 206 of 390 training acc 81.744 val acc 80.25\n",
      "\tBatch 207 of 390 training acc 79.998 val acc 78.89\n",
      "\tBatch 208 of 390 training acc 75.91 val acc 74.83999999999999\n",
      "\tBatch 209 of 390 training acc 82.17999999999999 val acc 81.15\n",
      "\tBatch 210 of 390 training acc 81.194 val acc 79.86\n",
      "\tBatch 211 of 390 training acc 80.006 val acc 79.41\n",
      "\tBatch 212 of 390 training acc 81.786 val acc 80.96\n",
      "\tBatch 213 of 390 training acc 83.75200000000001 val acc 82.5\n",
      "\tBatch 214 of 390 training acc 81.77 val acc 80.85\n",
      "\tBatch 215 of 390 training acc 78.14999999999999 val acc 76.82\n",
      "\tBatch 216 of 390 training acc 74.756 val acc 74.29\n",
      "\tBatch 217 of 390 training acc 70.124 val acc 69.67999999999999\n",
      "\tBatch 218 of 390 training acc 67.43599999999999 val acc 66.10000000000001\n",
      "\tBatch 219 of 390 training acc 72.502 val acc 72.35000000000001\n",
      "\tBatch 220 of 390 training acc 77.408 val acc 76.38000000000001\n",
      "\tBatch 221 of 390 training acc 81.868 val acc 80.78\n",
      "\tBatch 222 of 390 training acc 83.75399999999999 val acc 82.62\n",
      "\tBatch 223 of 390 training acc 79.506 val acc 78.28\n",
      "\tBatch 224 of 390 training acc 81.854 val acc 80.87\n",
      "\tBatch 225 of 390 training acc 81.338 val acc 80.39\n",
      "\tBatch 226 of 390 training acc 81.12 val acc 80.04\n",
      "\tBatch 227 of 390 training acc 83.66799999999999 val acc 82.61\n",
      "\tBatch 228 of 390 training acc 82.148 val acc 81.43\n",
      "\tBatch 229 of 390 training acc 78.88199999999999 val acc 78.13\n",
      "\tBatch 230 of 390 training acc 77.006 val acc 75.92999999999999\n",
      "\tBatch 231 of 390 training acc 73.268 val acc 71.96000000000001\n",
      "\tBatch 232 of 390 training acc 80.768 val acc 79.61\n",
      "\tBatch 233 of 390 training acc 82.652 val acc 81.88\n",
      "\tBatch 234 of 390 training acc 83.394 val acc 82.26\n",
      "\tBatch 235 of 390 training acc 81.754 val acc 80.69\n",
      "\tBatch 236 of 390 training acc 81.584 val acc 80.32000000000001\n",
      "\tBatch 237 of 390 training acc 79.176 val acc 78.42\n",
      "\tBatch 238 of 390 training acc 77.668 val acc 76.29\n",
      "\tBatch 239 of 390 training acc 79.514 val acc 78.92\n",
      "\tBatch 240 of 390 training acc 82.43 val acc 81.15\n",
      "\tBatch 241 of 390 training acc 77.75800000000001 val acc 76.18\n",
      "\tBatch 242 of 390 training acc 72.02 val acc 71.31\n",
      "\tBatch 243 of 390 training acc 78.032 val acc 77.28\n",
      "\tBatch 244 of 390 training acc 78.304 val acc 77.46\n",
      "\tBatch 245 of 390 training acc 80.76 val acc 79.89\n",
      "\tBatch 246 of 390 training acc 79.71000000000001 val acc 78.47\n",
      "\tBatch 247 of 390 training acc 79.228 val acc 78.53999999999999\n",
      "\tBatch 248 of 390 training acc 81.41199999999999 val acc 80.06\n",
      "\tBatch 249 of 390 training acc 78.52 val acc 77.61\n",
      "\tBatch 250 of 390 training acc 78.178 val acc 77.16\n",
      "\tBatch 251 of 390 training acc 83.71 val acc 82.80999999999999\n",
      "\tBatch 252 of 390 training acc 83.12 val acc 81.99\n",
      "\tBatch 253 of 390 training acc 82.62 val acc 81.32000000000001\n",
      "\tBatch 254 of 390 training acc 83.706 val acc 82.77\n",
      "\tBatch 255 of 390 training acc 82.282 val acc 81.28\n",
      "\tBatch 256 of 390 training acc 81.984 val acc 81.04\n",
      "\tBatch 257 of 390 training acc 81.21199999999999 val acc 80.17\n",
      "\tBatch 258 of 390 training acc 74.2 val acc 72.72999999999999\n",
      "\tBatch 259 of 390 training acc 73.55000000000001 val acc 73.29\n",
      "\tBatch 260 of 390 training acc 81.052 val acc 80.25999999999999\n",
      "\tBatch 261 of 390 training acc 82.308 val acc 81.49\n",
      "\tBatch 262 of 390 training acc 80.83 val acc 79.44\n",
      "\tBatch 263 of 390 training acc 79.3 val acc 78.27\n",
      "\tBatch 264 of 390 training acc 81.17 val acc 80.16\n",
      "\tBatch 265 of 390 training acc 82.904 val acc 82.0\n",
      "\tBatch 266 of 390 training acc 80.164 val acc 79.17999999999999\n",
      "\tBatch 267 of 390 training acc 79.5 val acc 78.61\n",
      "\tBatch 268 of 390 training acc 80.56400000000001 val acc 79.61\n",
      "\tBatch 269 of 390 training acc 82.056 val acc 81.34\n",
      "\tBatch 270 of 390 training acc 83.648 val acc 82.8\n",
      "\tBatch 271 of 390 training acc 78.43 val acc 77.14\n",
      "\tBatch 272 of 390 training acc 78.018 val acc 77.24\n",
      "\tBatch 273 of 390 training acc 71.954 val acc 71.09\n",
      "\tBatch 274 of 390 training acc 77.39399999999999 val acc 76.75\n",
      "\tBatch 275 of 390 training acc 78.75999999999999 val acc 77.69\n",
      "\tBatch 276 of 390 training acc 82.744 val acc 81.69999999999999\n",
      "\tBatch 277 of 390 training acc 79.448 val acc 77.91\n",
      "\tBatch 278 of 390 training acc 79.596 val acc 78.32000000000001\n",
      "\tBatch 279 of 390 training acc 79.196 val acc 77.89\n",
      "\tBatch 280 of 390 training acc 84.066 val acc 82.73\n",
      "\tBatch 281 of 390 training acc 82.12 val acc 80.69\n",
      "\tBatch 282 of 390 training acc 80.84400000000001 val acc 79.86\n",
      "\tBatch 283 of 390 training acc 79.43599999999999 val acc 78.33\n",
      "\tBatch 284 of 390 training acc 77.928 val acc 76.97\n",
      "\tBatch 285 of 390 training acc 73.488 val acc 72.8\n",
      "\tBatch 286 of 390 training acc 71.39 val acc 70.37\n",
      "\tBatch 287 of 390 training acc 76.842 val acc 75.56\n",
      "\tBatch 288 of 390 training acc 81.61 val acc 80.56\n",
      "\tBatch 289 of 390 training acc 82.738 val acc 81.99\n",
      "\tBatch 290 of 390 training acc 80.43 val acc 79.60000000000001\n",
      "\tBatch 291 of 390 training acc 82.824 val acc 81.78999999999999\n",
      "\tBatch 292 of 390 training acc 82.782 val acc 81.61\n",
      "\tBatch 293 of 390 training acc 81.39999999999999 val acc 80.43\n",
      "\tBatch 294 of 390 training acc 78.78399999999999 val acc 77.29\n",
      "\tBatch 295 of 390 training acc 82.19800000000001 val acc 81.23\n",
      "\tBatch 296 of 390 training acc 78.50399999999999 val acc 77.22\n",
      "\tBatch 297 of 390 training acc 77.498 val acc 76.62\n",
      "\tBatch 298 of 390 training acc 77.99000000000001 val acc 76.61\n",
      "\tBatch 299 of 390 training acc 76.63 val acc 75.57000000000001\n",
      "\tBatch 300 of 390 training acc 82.248 val acc 81.04\n",
      "\tBatch 301 of 390 training acc 81.26400000000001 val acc 80.17\n",
      "\tBatch 302 of 390 training acc 80.618 val acc 79.58\n",
      "\tBatch 303 of 390 training acc 83.35000000000001 val acc 81.97\n",
      "\tBatch 304 of 390 training acc 81.616 val acc 80.52\n",
      "\tBatch 305 of 390 training acc 80.32000000000001 val acc 79.34\n",
      "\tBatch 306 of 390 training acc 76.202 val acc 75.22\n",
      "\tBatch 307 of 390 training acc 79.3 val acc 78.35\n",
      "\tBatch 308 of 390 training acc 81.57600000000001 val acc 80.17\n",
      "\tBatch 309 of 390 training acc 79.202 val acc 78.36\n",
      "\tBatch 310 of 390 training acc 82.124 val acc 80.78999999999999\n",
      "\tBatch 311 of 390 training acc 82.126 val acc 80.65\n",
      "\tBatch 312 of 390 training acc 81.19 val acc 79.94\n",
      "\tBatch 313 of 390 training acc 79.838 val acc 78.72\n",
      "\tBatch 314 of 390 training acc 72.426 val acc 71.50999999999999\n",
      "\tBatch 315 of 390 training acc 65.32 val acc 65.03\n",
      "\tBatch 316 of 390 training acc 74.676 val acc 73.95\n",
      "\tBatch 317 of 390 training acc 77.22 val acc 76.57000000000001\n",
      "\tBatch 318 of 390 training acc 75.864 val acc 74.67\n",
      "\tBatch 319 of 390 training acc 80.568 val acc 79.65\n",
      "\tBatch 320 of 390 training acc 80.628 val acc 79.79\n",
      "\tBatch 321 of 390 training acc 81.922 val acc 81.11\n",
      "\tBatch 322 of 390 training acc 76.208 val acc 75.06\n",
      "\tBatch 323 of 390 training acc 81.734 val acc 80.58999999999999\n",
      "\tBatch 324 of 390 training acc 83.066 val acc 82.01\n",
      "\tBatch 325 of 390 training acc 78.456 val acc 77.13\n",
      "\tBatch 326 of 390 training acc 80.974 val acc 80.11\n",
      "\tBatch 327 of 390 training acc 83.612 val acc 82.37\n",
      "\tBatch 328 of 390 training acc 79.894 val acc 78.36999999999999\n",
      "\tBatch 329 of 390 training acc 80.31 val acc 79.12\n",
      "\tBatch 330 of 390 training acc 81.482 val acc 80.27\n",
      "\tBatch 331 of 390 training acc 81.286 val acc 80.15\n",
      "\tBatch 332 of 390 training acc 80.946 val acc 79.36\n",
      "\tBatch 333 of 390 training acc 84.012 val acc 82.38\n",
      "\tBatch 334 of 390 training acc 81.538 val acc 80.31\n",
      "\tBatch 335 of 390 training acc 77.91 val acc 76.55999999999999\n",
      "\tBatch 336 of 390 training acc 77.69200000000001 val acc 76.98\n",
      "\tBatch 337 of 390 training acc 81.148 val acc 79.77\n",
      "\tBatch 338 of 390 training acc 79.336 val acc 78.69\n",
      "\tBatch 339 of 390 training acc 75.056 val acc 73.83999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 340 of 390 training acc 77.178 val acc 77.10000000000001\n",
      "\tBatch 341 of 390 training acc 79.554 val acc 78.67\n",
      "\tBatch 342 of 390 training acc 79.294 val acc 77.95\n",
      "\tBatch 343 of 390 training acc 79.892 val acc 78.73\n",
      "\tBatch 344 of 390 training acc 78.392 val acc 77.18\n",
      "\tBatch 345 of 390 training acc 81.322 val acc 80.30000000000001\n",
      "\tBatch 346 of 390 training acc 74.59400000000001 val acc 73.22999999999999\n",
      "\tBatch 347 of 390 training acc 79.366 val acc 78.35\n",
      "\tBatch 348 of 390 training acc 80.608 val acc 79.73\n",
      "\tBatch 349 of 390 training acc 83.684 val acc 82.25\n",
      "\tBatch 350 of 390 training acc 83.148 val acc 81.46\n",
      "\tBatch 351 of 390 training acc 77.99199999999999 val acc 76.41\n",
      "\tBatch 352 of 390 training acc 77.456 val acc 76.55999999999999\n",
      "\tBatch 353 of 390 training acc 73.24000000000001 val acc 71.81\n",
      "\tBatch 354 of 390 training acc 75.424 val acc 74.57000000000001\n",
      "\tBatch 355 of 390 training acc 75.81599999999999 val acc 74.68\n",
      "\tBatch 356 of 390 training acc 72.1 val acc 71.25\n",
      "\tBatch 357 of 390 training acc 79.462 val acc 78.41\n",
      "\tBatch 358 of 390 training acc 81.95599999999999 val acc 80.5\n",
      "\tBatch 359 of 390 training acc 82.6 val acc 81.22\n",
      "\tBatch 360 of 390 training acc 79.54599999999999 val acc 78.2\n",
      "\tBatch 361 of 390 training acc 77.554 val acc 76.21\n",
      "\tBatch 362 of 390 training acc 82.11 val acc 80.69\n",
      "\tBatch 363 of 390 training acc 80.684 val acc 79.33\n",
      "\tBatch 364 of 390 training acc 80.484 val acc 79.28\n",
      "\tBatch 365 of 390 training acc 79.544 val acc 78.52\n",
      "\tBatch 366 of 390 training acc 80.816 val acc 79.64\n",
      "\tBatch 367 of 390 training acc 81.414 val acc 80.36999999999999\n",
      "\tBatch 368 of 390 training acc 80.638 val acc 79.14\n",
      "\tBatch 369 of 390 training acc 72.554 val acc 72.16\n",
      "\tBatch 370 of 390 training acc 76.332 val acc 75.59\n",
      "\tBatch 371 of 390 training acc 78.018 val acc 76.99000000000001\n",
      "\tBatch 372 of 390 training acc 73.76 val acc 72.84\n",
      "\tBatch 373 of 390 training acc 80.476 val acc 79.36\n",
      "\tBatch 374 of 390 training acc 81.65599999999999 val acc 80.35\n",
      "\tBatch 375 of 390 training acc 82.38799999999999 val acc 81.36\n",
      "\tBatch 376 of 390 training acc 81.89999999999999 val acc 81.01\n",
      "\tBatch 377 of 390 training acc 79.25999999999999 val acc 78.10000000000001\n",
      "\tBatch 378 of 390 training acc 82.772 val acc 81.76\n",
      "\tBatch 379 of 390 training acc 82.548 val acc 81.14\n",
      "\tBatch 380 of 390 training acc 80.306 val acc 79.09\n",
      "\tBatch 381 of 390 training acc 79.026 val acc 77.45\n",
      "\tBatch 382 of 390 training acc 76.97 val acc 75.92999999999999\n",
      "\tBatch 383 of 390 training acc 70.254 val acc 69.15\n",
      "\tBatch 384 of 390 training acc 77.446 val acc 76.36\n",
      "\tBatch 385 of 390 training acc 79.692 val acc 78.29\n",
      "\tBatch 386 of 390 training acc 75.47 val acc 74.4\n",
      "\tBatch 387 of 390 training acc 74.272 val acc 73.29\n",
      "\tBatch 388 of 390 training acc 81.004 val acc 79.80000000000001\n",
      "\tBatch 389 of 390 training acc 81.842 val acc 80.87\n",
      "epoch 2\n",
      "\tBatch 0 of 390 training acc 83.52000000000001 val acc 82.36\n",
      "\tBatch 1 of 390 training acc 82.50999999999999 val acc 81.13\n",
      "\tBatch 2 of 390 training acc 83.776 val acc 82.57\n",
      "\tBatch 3 of 390 training acc 78.298 val acc 76.69\n",
      "\tBatch 4 of 390 training acc 75.4 val acc 74.33\n",
      "\tBatch 5 of 390 training acc 81.326 val acc 80.31\n",
      "\tBatch 6 of 390 training acc 80.742 val acc 79.83\n",
      "\tBatch 7 of 390 training acc 80.062 val acc 78.9\n",
      "\tBatch 8 of 390 training acc 79.212 val acc 78.01\n",
      "\tBatch 9 of 390 training acc 81.202 val acc 80.27\n",
      "\tBatch 10 of 390 training acc 73.804 val acc 72.32\n",
      "\tBatch 11 of 390 training acc 81.928 val acc 80.95\n",
      "\tBatch 12 of 390 training acc 81.64200000000001 val acc 80.89\n",
      "\tBatch 13 of 390 training acc 81.286 val acc 80.13\n",
      "\tBatch 14 of 390 training acc 77.034 val acc 75.28\n",
      "\tBatch 15 of 390 training acc 78.886 val acc 77.92\n",
      "\tBatch 16 of 390 training acc 79.192 val acc 77.98\n",
      "\tBatch 17 of 390 training acc 79.372 val acc 78.53\n",
      "\tBatch 18 of 390 training acc 83.04 val acc 81.73\n",
      "\tBatch 19 of 390 training acc 80.392 val acc 79.41\n",
      "\tBatch 20 of 390 training acc 75.008 val acc 73.89\n",
      "\tBatch 21 of 390 training acc 73.426 val acc 72.45\n",
      "\tBatch 22 of 390 training acc 73.50999999999999 val acc 72.41\n",
      "\tBatch 23 of 390 training acc 73.09400000000001 val acc 72.59\n",
      "\tBatch 24 of 390 training acc 80.674 val acc 79.86\n",
      "\tBatch 25 of 390 training acc 82.258 val acc 80.99\n",
      "\tBatch 26 of 390 training acc 81.438 val acc 80.04\n",
      "\tBatch 27 of 390 training acc 83.14399999999999 val acc 81.81\n",
      "\tBatch 28 of 390 training acc 80.854 val acc 79.45\n",
      "\tBatch 29 of 390 training acc 77.28 val acc 76.07000000000001\n",
      "\tBatch 30 of 390 training acc 76.076 val acc 74.46000000000001\n",
      "\tBatch 31 of 390 training acc 80.644 val acc 79.39\n",
      "\tBatch 32 of 390 training acc 81.528 val acc 80.57\n",
      "\tBatch 33 of 390 training acc 80.25 val acc 78.86\n",
      "\tBatch 34 of 390 training acc 84.112 val acc 82.89999999999999\n",
      "\tBatch 35 of 390 training acc 82.864 val acc 81.93\n",
      "\tBatch 36 of 390 training acc 83.256 val acc 82.25\n",
      "\tBatch 37 of 390 training acc 84.95 val acc 83.41\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "reg_const = 0.5\n",
    "\n",
    "softmax_fashion = Softmax(n_class_fashion, lr, n_epochs, reg_const)\n",
    "softmax_fashion.train(X_train_fashion, y_train_fashion,X_val_fashion,y_val_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 84.950000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_train_fashion)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 83.410000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_val_fashion)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 82.850000\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_fashion.predict(X_test_fashion)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_fashion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax_Fashion-MNIST Kaggle Submission\n",
    "\n",
    "Once you are satisfied with your solution and test accuracy output a file to submit your test set predictions to the Kaggle for Assignment 1 Fashion-MNIST. Use the following code to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submission_csv('kaggle/softmax_submission_fashion.csv', softmax_fashion.predict(X_test_fashion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Softmax on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "\tBatch 0 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 1 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 2 of 38 training acc 48.317603610997125 val acc 49.16923076923077\n",
      "\tBatch 3 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 4 of 38 training acc 48.317603610997125 val acc 49.16923076923077\n",
      "\tBatch 5 of 38 training acc 51.682396389002875 val acc 50.830769230769235\n",
      "\tBatch 6 of 38 training acc 61.05867870332376 val acc 58.4\n",
      "\tBatch 7 of 38 training acc 53.959786622897 val acc 52.86153846153846\n",
      "\tBatch 8 of 38 training acc 63.8695116947066 val acc 61.41538461538462\n",
      "\tBatch 9 of 38 training acc 74.82560525235947 val acc 73.47692307692307\n",
      "\tBatch 10 of 38 training acc 71.00943783340172 val acc 68.73846153846154\n",
      "\tBatch 11 of 38 training acc 79.38038572014773 val acc 77.72307692307693\n",
      "\tBatch 12 of 38 training acc 65.12105047189168 val acc 63.01538461538462\n",
      "\tBatch 13 of 38 training acc 74.12802626179729 val acc 72.67692307692307\n",
      "\tBatch 14 of 38 training acc 60.62782109150595 val acc 59.44615384615385\n",
      "\tBatch 15 of 38 training acc 55.78580221583914 val acc 54.15384615384615\n",
      "\tBatch 16 of 38 training acc 48.35863766926549 val acc 49.16923076923077\n",
      "\tBatch 17 of 38 training acc 52.21583914649158 val acc 51.2\n",
      "\tBatch 18 of 38 training acc 76.26179729175216 val acc 74.4\n",
      "\tBatch 19 of 38 training acc 82.43742306114075 val acc 80.61538461538461\n",
      "\tBatch 20 of 38 training acc 74.04595814526057 val acc 72.8\n",
      "\tBatch 21 of 38 training acc 83.258104226508 val acc 82.33846153846154\n",
      "\tBatch 22 of 38 training acc 81.0627821091506 val acc 78.83076923076922\n",
      "\tBatch 23 of 38 training acc 84.75584735330324 val acc 83.07692307692308\n",
      "\tBatch 24 of 38 training acc 73.94337299958966 val acc 73.47692307692307\n",
      "\tBatch 25 of 38 training acc 82.7246614690193 val acc 80.3076923076923\n",
      "\tBatch 26 of 38 training acc 77.14402954452196 val acc 76.06153846153846\n",
      "\tBatch 27 of 38 training acc 85.63807960607303 val acc 83.6923076923077\n",
      "\tBatch 28 of 38 training acc 75.15387771850635 val acc 74.95384615384614\n",
      "\tBatch 29 of 38 training acc 76.07714402954451 val acc 73.41538461538461\n",
      "\tBatch 30 of 38 training acc 62.24866639310628 val acc 62.153846153846146\n",
      "\tBatch 31 of 38 training acc 52.54411161263849 val acc 51.69230769230769\n",
      "\tBatch 32 of 38 training acc 48.50225687320476 val acc 49.29230769230769\n",
      "\tBatch 33 of 38 training acc 63.70537546163315 val acc 61.53846153846154\n",
      "\tBatch 34 of 38 training acc 74.70250307755437 val acc 72.8\n",
      "\tBatch 35 of 38 training acc 81.69881001231022 val acc 79.44615384615385\n",
      "\tBatch 36 of 38 training acc 82.95034878949528 val acc 82.27692307692308\n",
      "\tBatch 37 of 38 training acc 82.29380385720148 val acc 81.78461538461539\n",
      "epoch 1\n",
      "\tBatch 0 of 38 training acc 84.22240459581452 val acc 82.46153846153847\n",
      "\tBatch 1 of 38 training acc 82.8272466146902 val acc 82.27692307692308\n",
      "\tBatch 2 of 38 training acc 84.11981945014362 val acc 83.6923076923077\n",
      "\tBatch 3 of 38 training acc 85.00205170291342 val acc 84.61538461538461\n",
      "\tBatch 4 of 38 training acc 86.10997127615921 val acc 85.23076923076923\n",
      "\tBatch 5 of 38 training acc 79.524004924087 val acc 79.44615384615385\n",
      "\tBatch 6 of 38 training acc 83.56585966352073 val acc 81.1076923076923\n",
      "\tBatch 7 of 38 training acc 71.89167008617152 val acc 71.07692307692308\n",
      "\tBatch 8 of 38 training acc 64.42347148132951 val acc 61.353846153846156\n",
      "\tBatch 9 of 38 training acc 51.9901518260156 val acc 52.49230769230769\n",
      "\tBatch 10 of 38 training acc 52.21583914649158 val acc 51.44615384615384\n",
      "\tBatch 11 of 38 training acc 68.58842839556833 val acc 68.0\n",
      "\tBatch 12 of 38 training acc 81.12433319655314 val acc 79.01538461538462\n",
      "\tBatch 13 of 38 training acc 70.00410340582684 val acc 68.73846153846154\n",
      "\tBatch 14 of 38 training acc 82.45794009027493 val acc 79.93846153846154\n",
      "\tBatch 15 of 38 training acc 83.19655313910546 val acc 82.52307692307693\n",
      "\tBatch 16 of 38 training acc 69.81945014361919 val acc 68.8\n",
      "\tBatch 17 of 38 training acc 68.07550266721378 val acc 65.60000000000001\n",
      "\tBatch 18 of 38 training acc 67.8498153467378 val acc 67.32307692307693\n",
      "\tBatch 19 of 38 training acc 62.92572835453426 val acc 60.12307692307692\n",
      "\tBatch 20 of 38 training acc 58.535084119819444 val acc 58.64615384615385\n",
      "\tBatch 21 of 38 training acc 75.52318424292163 val acc 73.29230769230769\n",
      "\tBatch 22 of 38 training acc 75.58473533032416 val acc 74.70769230769231\n",
      "\tBatch 23 of 38 training acc 84.69429626590069 val acc 82.83076923076923\n",
      "\tBatch 24 of 38 training acc 77.71850636027902 val acc 76.49230769230769\n",
      "\tBatch 25 of 38 training acc 86.82806729585556 val acc 85.1076923076923\n",
      "\tBatch 26 of 38 training acc 78.5186704965121 val acc 77.1076923076923\n",
      "\tBatch 27 of 38 training acc 86.31514156750103 val acc 84.36923076923077\n",
      "\tBatch 28 of 38 training acc 83.483791546984 val acc 83.01538461538462\n",
      "\tBatch 29 of 38 training acc 87.58719737382027 val acc 86.21538461538462\n",
      "\tBatch 30 of 38 training acc 71.00943783340172 val acc 70.21538461538461\n",
      "\tBatch 31 of 38 training acc 63.74640951990151 val acc 60.676923076923075\n",
      "\tBatch 32 of 38 training acc 50.471891670086166 val acc 50.4\n",
      "\tBatch 33 of 38 training acc 61.42798522773902 val acc 58.95384615384616\n",
      "\tBatch 34 of 38 training acc 78.72384078785392 val acc 76.73846153846154\n",
      "\tBatch 35 of 38 training acc 84.55067706196144 val acc 82.58461538461539\n",
      "\tBatch 36 of 38 training acc 85.39187525646287 val acc 84.61538461538461\n",
      "\tBatch 37 of 38 training acc 81.32950348789495 val acc 80.12307692307692\n",
      "epoch 2\n",
      "\tBatch 0 of 38 training acc 85.26877308165778 val acc 83.13846153846154\n",
      "\tBatch 1 of 38 training acc 85.4739433729996 val acc 84.8\n",
      "\tBatch 2 of 38 training acc 84.85843249897414 val acc 84.3076923076923\n",
      "\tBatch 3 of 38 training acc 88.01805498563809 val acc 86.58461538461538\n",
      "\tBatch 4 of 38 training acc 79.79072630283135 val acc 79.26153846153846\n",
      "\tBatch 5 of 38 training acc 86.82806729585556 val acc 84.18461538461538\n",
      "\tBatch 6 of 38 training acc 80.96019696347969 val acc 80.18461538461538\n",
      "\tBatch 7 of 38 training acc 87.97702092736972 val acc 86.21538461538462\n",
      "\tBatch 8 of 38 training acc 83.66844480919163 val acc 83.32307692307693\n",
      "\tBatch 9 of 38 training acc 88.12064013130899 val acc 87.56923076923077\n",
      "\tBatch 10 of 38 training acc 84.98153467377924 val acc 84.86153846153847\n",
      "\tBatch 11 of 38 training acc 86.95116947066064 val acc 86.83076923076923\n",
      "\tBatch 12 of 38 training acc 73.73820270824784 val acc 73.41538461538461\n",
      "\tBatch 13 of 38 training acc 76.52851867049651 val acc 74.03076923076924\n",
      "\tBatch 14 of 38 training acc 54.78046778826426 val acc 56.43076923076923\n",
      "\tBatch 15 of 38 training acc 52.236356175625765 val acc 51.323076923076925\n",
      "\tBatch 16 of 38 training acc 51.908083709478866 val acc 52.12307692307693\n",
      "\tBatch 17 of 38 training acc 52.749281903980304 val acc 51.93846153846153\n",
      "\tBatch 18 of 38 training acc 84.44809191629052 val acc 83.81538461538462\n",
      "\tBatch 19 of 38 training acc 83.97620024620434 val acc 83.63076923076923\n",
      "\tBatch 20 of 38 training acc 83.31965531391054 val acc 82.64615384615385\n",
      "\tBatch 21 of 38 training acc 87.89495281083299 val acc 86.46153846153845\n",
      "\tBatch 22 of 38 training acc 87.42306114074681 val acc 87.01538461538462\n",
      "\tBatch 23 of 38 training acc 73.08165777595404 val acc 72.43076923076923\n",
      "\tBatch 24 of 38 training acc 82.06811653672548 val acc 79.6923076923077\n",
      "\tBatch 25 of 38 training acc 83.52482560525236 val acc 82.95384615384616\n",
      "\tBatch 26 of 38 training acc 87.62823143208863 val acc 87.2\n",
      "\tBatch 27 of 38 training acc 83.83258104226508 val acc 84.06153846153846\n",
      "\tBatch 28 of 38 training acc 84.28395568321707 val acc 84.06153846153846\n",
      "\tBatch 29 of 38 training acc 88.30529339351662 val acc 87.26153846153846\n",
      "\tBatch 30 of 38 training acc 65.57242511284366 val acc 66.76923076923077\n",
      "\tBatch 31 of 38 training acc 55.929421419778414 val acc 54.46153846153846\n",
      "\tBatch 32 of 38 training acc 50.820681165367255 val acc 50.830769230769235\n",
      "\tBatch 33 of 38 training acc 65.51087402544111 val acc 63.323076923076925\n",
      "\tBatch 34 of 38 training acc 82.41690603200657 val acc 80.80000000000001\n",
      "\tBatch 35 of 38 training acc 86.54082888797701 val acc 84.86153846153847\n",
      "\tBatch 36 of 38 training acc 84.96101764464505 val acc 84.55384615384615\n",
      "\tBatch 37 of 38 training acc 86.06893721789085 val acc 85.66153846153847\n",
      "epoch 3\n",
      "\tBatch 0 of 38 training acc 87.23840787853919 val acc 85.6\n",
      "\tBatch 1 of 38 training acc 86.10997127615921 val acc 85.29230769230769\n",
      "\tBatch 2 of 38 training acc 85.26877308165778 val acc 85.16923076923077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch 3 of 38 training acc 87.79236766516209 val acc 86.09230769230768\n",
      "\tBatch 4 of 38 training acc 83.42224045958146 val acc 83.50769230769231\n",
      "\tBatch 5 of 38 training acc 87.81288469429627 val acc 86.21538461538462\n",
      "\tBatch 6 of 38 training acc 82.86828067295856 val acc 82.7076923076923\n",
      "\tBatch 7 of 38 training acc 88.63356585966352 val acc 86.64615384615385\n",
      "\tBatch 8 of 38 training acc 87.89495281083299 val acc 87.6923076923077\n",
      "\tBatch 9 of 38 training acc 83.09396799343455 val acc 83.2\n",
      "\tBatch 10 of 38 training acc 89.4337299958966 val acc 88.0\n",
      "\tBatch 11 of 38 training acc 75.42059909725072 val acc 74.95384615384614\n",
      "\tBatch 12 of 38 training acc 77.55437012720559 val acc 75.07692307692308\n",
      "\tBatch 13 of 38 training acc 68.97825194911776 val acc 69.9076923076923\n",
      "\tBatch 14 of 38 training acc 66.68034468608946 val acc 63.87692307692308\n",
      "\tBatch 15 of 38 training acc 59.3557652851867 val acc 60.184615384615384\n",
      "\tBatch 16 of 38 training acc 68.46532622076323 val acc 66.21538461538462\n",
      "\tBatch 17 of 38 training acc 82.2732868280673 val acc 81.41538461538461\n",
      "\tBatch 18 of 38 training acc 87.93598686910136 val acc 86.4\n",
      "\tBatch 19 of 38 training acc 80.05744768157571 val acc 79.44615384615385\n",
      "\tBatch 20 of 38 training acc 88.61304883052934 val acc 86.46153846153845\n",
      "\tBatch 21 of 38 training acc 86.41772671317193 val acc 86.27692307692307\n",
      "\tBatch 22 of 38 training acc 88.81821912187115 val acc 87.07692307692308\n",
      "\tBatch 23 of 38 training acc 79.03159622486665 val acc 77.96923076923076\n",
      "\tBatch 24 of 38 training acc 88.57201477226097 val acc 86.76923076923076\n",
      "\tBatch 25 of 38 training acc 87.91546983996717 val acc 87.50769230769231\n",
      "\tBatch 26 of 38 training acc 85.6791136643414 val acc 85.16923076923077\n",
      "\tBatch 27 of 38 training acc 89.78251949117768 val acc 88.61538461538461\n",
      "\tBatch 28 of 38 training acc 84.48912597455889 val acc 84.3076923076923\n",
      "\tBatch 29 of 38 training acc 89.67993434550678 val acc 88.67692307692307\n",
      "\tBatch 30 of 38 training acc 65.81862946245384 val acc 67.2\n",
      "\tBatch 31 of 38 training acc 56.401313089864594 val acc 54.70769230769231\n",
      "\tBatch 32 of 38 training acc 49.07673368896184 val acc 49.353846153846156\n",
      "\tBatch 33 of 38 training acc 63.68485843249897 val acc 61.846153846153854\n",
      "\tBatch 34 of 38 training acc 79.31883463274518 val acc 78.27692307692308\n",
      "\tBatch 35 of 38 training acc 83.60689372178909 val acc 81.9076923076923\n",
      "\tBatch 36 of 38 training acc 87.97702092736972 val acc 86.52307692307693\n",
      "\tBatch 37 of 38 training acc 83.62741075092327 val acc 82.95384615384616\n",
      "epoch 4\n",
      "\tBatch 0 of 38 training acc 85.26877308165778 val acc 82.58461538461539\n",
      "\tBatch 1 of 38 training acc 88.51046368485844 val acc 87.63076923076923\n",
      "\tBatch 2 of 38 training acc 86.29462453836685 val acc 86.03076923076924\n",
      "\tBatch 3 of 38 training acc 89.16700861715223 val acc 88.06153846153846\n",
      "\tBatch 4 of 38 training acc 82.17070168239638 val acc 81.47692307692309\n",
      "\tBatch 5 of 38 training acc 87.83340172343046 val acc 86.15384615384616\n",
      "\tBatch 6 of 38 training acc 87.03323758719738 val acc 86.70769230769231\n",
      "\tBatch 7 of 38 training acc 86.93065244152646 val acc 86.46153846153845\n",
      "\tBatch 8 of 38 training acc 89.26959376282313 val acc 88.67692307692307\n",
      "\tBatch 9 of 38 training acc 85.00205170291342 val acc 84.55384615384615\n",
      "\tBatch 10 of 38 training acc 90.35699630693476 val acc 89.47692307692307\n",
      "\tBatch 11 of 38 training acc 72.05580631924498 val acc 72.49230769230769\n",
      "\tBatch 12 of 38 training acc 70.74271645465736 val acc 68.36923076923077\n",
      "\tBatch 13 of 38 training acc 61.05867870332376 val acc 61.90769230769231\n",
      "\tBatch 14 of 38 training acc 59.78662289700451 val acc 57.66153846153846\n",
      "\tBatch 15 of 38 training acc 62.187115305703735 val acc 63.13846153846154\n",
      "\tBatch 16 of 38 training acc 72.75338530980714 val acc 70.46153846153847\n",
      "\tBatch 17 of 38 training acc 86.97168649979483 val acc 86.4\n",
      "\tBatch 18 of 38 training acc 86.47927780057447 val acc 86.03076923076924\n",
      "\tBatch 19 of 38 training acc 86.9101354123923 val acc 86.64615384615385\n",
      "\tBatch 20 of 38 training acc 88.05908904390645 val acc 87.2\n",
      "\tBatch 21 of 38 training acc 86.72548215018465 val acc 86.46153846153845\n",
      "\tBatch 22 of 38 training acc 89.57734919983587 val acc 88.49230769230769\n",
      "\tBatch 23 of 38 training acc 78.47763643824375 val acc 77.53846153846153\n",
      "\tBatch 24 of 38 training acc 88.2027082478457 val acc 86.21538461538462\n",
      "\tBatch 25 of 38 training acc 89.04390644234714 val acc 88.49230769230769\n",
      "\tBatch 26 of 38 training acc 81.47312269183422 val acc 81.16923076923077\n",
      "\tBatch 27 of 38 training acc 88.63356585966352 val acc 86.8923076923077\n",
      "\tBatch 28 of 38 training acc 89.5363151415675 val acc 88.73846153846155\n",
      "\tBatch 29 of 38 training acc 78.58022158391465 val acc 77.60000000000001\n",
      "\tBatch 30 of 38 training acc 85.53549446040213 val acc 83.44615384615385\n",
      "\tBatch 31 of 38 training acc 62.10504718916701 val acc 62.338461538461544\n",
      "\tBatch 32 of 38 training acc 75.4411161263849 val acc 72.98461538461538\n",
      "\tBatch 33 of 38 training acc 64.40295445219533 val acc 65.41538461538462\n",
      "\tBatch 34 of 38 training acc 51.908083709478866 val acc 51.26153846153846\n",
      "\tBatch 35 of 38 training acc 64.99794829708658 val acc 65.78461538461539\n",
      "\tBatch 36 of 38 training acc 80.44727123512516 val acc 78.52307692307691\n",
      "\tBatch 37 of 38 training acc 87.68978251949117 val acc 86.09230769230768\n",
      "epoch 5\n",
      "\tBatch 0 of 38 training acc 85.92531801395158 val acc 84.92307692307692\n",
      "\tBatch 1 of 38 training acc 87.8744357816988 val acc 86.4\n",
      "\tBatch 2 of 38 training acc 85.94583504308576 val acc 85.23076923076923\n",
      "\tBatch 3 of 38 training acc 88.53098071399262 val acc 86.70769230769231\n",
      "\tBatch 4 of 38 training acc 86.02790315962248 val acc 85.35384615384616\n",
      "\tBatch 5 of 38 training acc 89.00287238407878 val acc 87.13846153846154\n",
      "\tBatch 6 of 38 training acc 86.25359048009848 val acc 85.6\n",
      "\tBatch 7 of 38 training acc 89.35166187935987 val acc 88.3076923076923\n",
      "\tBatch 8 of 38 training acc 84.73533032416906 val acc 84.3076923076923\n",
      "\tBatch 9 of 38 training acc 90.3159622486664 val acc 89.35384615384615\n",
      "\tBatch 10 of 38 training acc 87.71029954862536 val acc 86.95384615384616\n",
      "\tBatch 11 of 38 training acc 82.84776364382438 val acc 82.89230769230768\n",
      "\tBatch 12 of 38 training acc 86.74599917931883 val acc 84.86153846153847\n",
      "\tBatch 13 of 38 training acc 77.65695527287649 val acc 76.92307692307693\n",
      "\tBatch 14 of 38 training acc 88.83873615100534 val acc 87.2\n",
      "\tBatch 15 of 38 training acc 88.1001231021748 val acc 87.32307692307693\n",
      "\tBatch 16 of 38 training acc 86.29462453836685 val acc 85.96923076923076\n",
      "\tBatch 17 of 38 training acc 90.74681986048421 val acc 89.96923076923076\n",
      "\tBatch 18 of 38 training acc 87.17685679113664 val acc 86.64615384615385\n",
      "\tBatch 19 of 38 training acc 85.72014772260977 val acc 85.6\n",
      "\tBatch 20 of 38 training acc 90.6442347148133 val acc 89.66153846153846\n",
      "\tBatch 21 of 38 training acc 83.1555190808371 val acc 82.83076923076923\n",
      "\tBatch 22 of 38 training acc 85.63807960607303 val acc 83.93846153846154\n",
      "\tBatch 23 of 38 training acc 74.53836684448092 val acc 74.33846153846154\n",
      "\tBatch 24 of 38 training acc 73.88182191218712 val acc 70.83076923076923\n",
      "\tBatch 25 of 38 training acc 54.10340582683627 val acc 55.753846153846155\n",
      "\tBatch 26 of 38 training acc 51.723430447271234 val acc 50.95384615384615\n",
      "\tBatch 27 of 38 training acc 76.2207632334838 val acc 74.15384615384616\n",
      "\tBatch 28 of 38 training acc 85.72014772260977 val acc 84.12307692307692\n",
      "\tBatch 29 of 38 training acc 79.66762412802626 val acc 78.03076923076922\n",
      "\tBatch 30 of 38 training acc 86.15100533442758 val acc 84.3076923076923\n",
      "\tBatch 31 of 38 training acc 70.84530160032827 val acc 70.46153846153847\n",
      "\tBatch 32 of 38 training acc 84.09930242100944 val acc 81.96923076923078\n",
      "\tBatch 33 of 38 training acc 88.83873615100534 val acc 87.50769230769231\n",
      "\tBatch 34 of 38 training acc 89.14649158801805 val acc 88.36923076923077\n",
      "\tBatch 35 of 38 training acc 85.41239228559705 val acc 84.61538461538461\n",
      "\tBatch 36 of 38 training acc 89.6594173163726 val acc 88.43076923076923\n",
      "\tBatch 37 of 38 training acc 84.63274517849815 val acc 84.0\n",
      "epoch 6\n",
      "\tBatch 0 of 38 training acc 80.07796471070989 val acc 78.58461538461539\n",
      "\tBatch 1 of 38 training acc 88.2027082478457 val acc 87.81538461538462\n",
      "\tBatch 2 of 38 training acc 89.74148543290931 val acc 89.60000000000001\n",
      "\tBatch 3 of 38 training acc 90.4185473943373 val acc 90.33846153846153\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "n_epochs = 10\n",
    "reg_const = 0.05\n",
    "\n",
    "softmax_MR = Softmax(n_class_MR, lr, n_epochs, reg_const)\n",
    "softmax_MR.train(X_train_MR, y_train_MR,X_val_MR,y_val_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 90.418547\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_MR.predict(X_train_MR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_softmax, y_train_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Softmax on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 90.338462\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_MR.predict(X_val_MR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_softmax, y_val_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Softmax on Mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 89.723077\n"
     ]
    }
   ],
   "source": [
    "pred_softmax = softmax_MR.predict(X_test_MR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_softmax, y_test_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Classifier has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - similar to as defined above in Perceptron, this parameter scales by how much the weights are changed according to the calculated gradient update. \n",
    "- **Number of Epochs** - As described for perceptron.\n",
    "- **Threshold** - The decision boundary of the classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will implement the Logistic Classifier in the **models/logistic.py**\n",
    "\n",
    "The following code: \n",
    "- Creates an instance of the Logistic classifier class \n",
    "- The train function of the Logistic class is trained on the training data\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codes for logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Logistic regression model.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Logistic:\n",
    "    def __init__(self, lr: float, epochs: int, threshold: float):\n",
    "        \"\"\"Initialize a new classifier.\n",
    "\n",
    "        Parameters:\n",
    "            lr: the learning rate\n",
    "            epochs: the number of epochs to train for\n",
    "        \"\"\"\n",
    "        self.w = None  # TODO: change this\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid function.\n",
    "\n",
    "        Parameters:\n",
    "            z: the input\n",
    "\n",
    "        Returns:\n",
    "            the sigmoid of the input\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "        return 1/(1+ np.exp(-z))\n",
    "\n",
    "    def train(self, X_train: np.ndarray, y_train: np.ndarray):\n",
    "        \"\"\"Train the classifier.\n",
    "\n",
    "        Use the logistic regression update rule as introduced in lecture.\n",
    "\n",
    "        Parameters:\n",
    "            X_train: a numpy array of shape (N, D) containing training data;\n",
    "                N examples with D dimensions\n",
    "            y_train: a numpy array of shape (N,) containing training labels\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "        print(X_train.shape)\n",
    "        random.seed(5)\n",
    "        upper_b = np.min(X_train)\n",
    "        lower_b = np.max(X_train)\n",
    "        self.w = np.zeros(X_train.shape[1])\n",
    "        print(\"w\",self.w)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            cnt = 0\n",
    "            # for each of the training data\n",
    "            for i in range(X_train.shape[0]):\n",
    "                  grad_w = X_train[i] * (y_train[i] - self.sigmoid(np.dot(self.w, X_train[i])))\n",
    "                  self.w += self.lr*grad_w\n",
    "            print(\"\\t\",\"epoch\",epoch,\"training\")\n",
    "        print(self.w)\n",
    "            \n",
    "    def predict(self, X_test: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Use the trained weights to predict labels for test data points.\n",
    "\n",
    "        Parameters:\n",
    "            X_test: a numpy array of shape (N, D) containing testing data;\n",
    "                N examples with D dimensions\n",
    "\n",
    "        Returns:\n",
    "            predicted labels for the data in X_test; a 1-dimensional array of\n",
    "                length N, where each element is an integer giving the predicted\n",
    "                class.\n",
    "        \"\"\"\n",
    "        # TODO: implement me\n",
    "        ret = []\n",
    "        for i in range(len(X_test)):\n",
    "            score = np.dot(self.w,X_test[i])\n",
    "#             print(\"!!!\",score,)\n",
    "#             print(X_test[i])\n",
    "#             print(\"score\",score)\n",
    "#             print(self.sigmoid(score))\n",
    "            if self.sigmoid(score) >= threshold:\n",
    "                ret.append(1)\n",
    "            else:\n",
    "                ret.append(0)\n",
    "#         print(ret)\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4874, 22)\n",
      "w [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\t epoch 0 training\n",
      "\t epoch 1 training\n",
      "\t epoch 2 training\n",
      "\t epoch 3 training\n",
      "\t epoch 4 training\n",
      "\t epoch 5 training\n",
      "\t epoch 6 training\n",
      "\t epoch 7 training\n",
      "\t epoch 8 training\n",
      "\t epoch 9 training\n",
      "[-0.05059437  0.6329352  -0.04606689 -1.01571977 -0.28967443  1.26200838\n",
      " -3.26412716  5.22235985 -0.23821752 -1.0674978  -1.40697891 -2.70207919\n",
      " -0.59391416 -0.12607478 -0.09474378  0.          3.25956399 -0.59241467\n",
      "  0.21116122 -0.45914512  0.26218896  0.20340367]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_epochs = 10\n",
    "threshold = 0.5\n",
    "\n",
    "lr = Logistic(learning_rate, n_epochs, threshold)\n",
    "lr.train(X_train_MR, y_train_MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is given by: 90.951990\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_train_MR)\n",
    "print('The training accuracy is given by: %f' % (get_acc(pred_lr, y_train_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Logistic Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy is given by: 89.784615\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_val_MR)\n",
    "print('The validation accuracy is given by: %f' % (get_acc(pred_lr, y_val_MR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy is given by: 90.646154\n"
     ]
    }
   ],
   "source": [
    "pred_lr = lr.predict(X_test_MR)\n",
    "print('The testing accuracy is given by: %f' % (get_acc(pred_lr, y_test_MR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
